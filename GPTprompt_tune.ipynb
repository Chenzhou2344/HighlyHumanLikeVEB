{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from tool import videoreader\n",
    "# 创建一个OpenAI客户端实例\n",
    "client = OpenAI(\n",
    "    api_key=\"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\",\n",
    "    base_url=\"https://gateway.ai.cloudflare.com/v1/627f1b1f372e3a198dc32573bbc6f720/openai-gpt/openai\"  # 替换为你的自定义API域\n",
    ")\n",
    "\n",
    "## Set the API key and model name\n",
    "MODEL=\"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 'color'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "# data_prepath = r'D:\\Astudying\\VideoEval\\Rating4color\\app\\data4dimensions'\n",
    "data_prepath = \"../../data4dimensions/\"\n",
    "with open(\"./Human_anno/{}.json\".format(dimension)) as f:\n",
    "    human_anno = json.load(f)\n",
    "\n",
    "file_path =\"./GPT4o_eval_results/{}/{}_919_all_part1.json\".format(dimension,dimension)\n",
    "\n",
    "with open(file_path,'r') as f:\n",
    "    s = json.load(f)\n",
    "\n",
    "from PromptTemplate4GPTeval import Prompt4Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 = list(range(109, len(human_anno),3))\n",
    "# l2 = list(range(110, len(human_anno),3))\n",
    "# l = l1+l2\n",
    "# l = list(range(181,len(human_anno)))\n",
    "l = [233,234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Scores:\n",
      "\n",
      "- Videocrafter2: 4, because the vases are consistently green and well-rendered, but the presence of multiple vases slightly deviates from the prompt of \"a green vase.\"\n",
      "\n",
      "- Pika: 5, because the vase is consistently green with intricate detailing, maintaining excellent color consistency and providing a vibrant viewing experience.\n",
      "\n",
      "- Show1: 5, because the vase is consistently green throughout, with no abrupt color changes, and the simplicity enhances the focus on the color.\n",
      "\n",
      "- Lavie: 4, because the vase is consistently green, but the framing shows only a part of the vase, which slightly limits the viewing experience.\n",
      "Final Scores:\n",
      "\n",
      "- Videocrafter2: 5, because the vase is consistently blue throughout the video, with no abrupt color changes or inconsistencies. The color distribution is precise and matches the prompt perfectly.\n",
      "\n",
      "- Pika: 4, because the vase is blue, but there are additional colors and decorations that slightly distract from the prompt. The color is stable, but the focus on the blue vase is not as clear.\n",
      "\n",
      "- Show1: 5, because the vase is consistently blue, with no abrupt changes or inconsistencies. The color distribution is correct, and the video provides a clear and accurate representation of the prompt.\n",
      "\n",
      "- Lavie: 3, because the vase is blue, but the shape is abstract and differs from a typical vase. The color is consistent, but the appearance is not realistic, which affects the overall consistency with the prompt.\n"
     ]
    }
   ],
   "source": [
    "# skip_index = list(range(0, len(human_anno),5))\n",
    "for i in l:             \n",
    "    # if i in skip_index:\n",
    "    #     continue\n",
    "    # # frames = videoreader.process_video(data_dir,human_anno[i]['videos'],4 )\n",
    "    # else:\n",
    "        frames = videoreader.process_video(data_prepath,human_anno[i]['videos'],2 ,resize_fx=1,resize_fy=1)\n",
    "\n",
    "        prompten = human_anno[i]['prompt_en']\n",
    "        # question = human_anno[i]['question_en']\n",
    "        # subject = human_anno[i]['subject_en']\n",
    "        # scene = human_anno[i]['scene_en']\n",
    "        # objet = human_anno[i]['object']\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "            model=MODEL, \n",
    "            messages=[\n",
    "            {\n",
    "            \"role\": \"system\", \"content\":\n",
    "             Prompt4Color\n",
    "             }\n",
    "             ,\n",
    "            {\n",
    "                \"role\": \"user\", \"content\": [\n",
    "                \"These are the frames from the video.The prompt is '{}'.\".format(prompten),\n",
    " \n",
    "                # \"12 frames from cogvideox5b \\n \", \n",
    "                # *map(lambda x: {\"type\": \"image_url\", \n",
    "                #                 \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['cogvideox5b']),\n",
    "                # \"10 frames from kling \\n \", \n",
    "                # *map(lambda x: {\"type\": \"image_url\", \n",
    "                #                 \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['kling']),\n",
    "                # \"10 frames from gen3 \\n \", \n",
    "                # *map(lambda x: {\"type\": \"image_url\", \n",
    "                #                 \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['gen3']),\n",
    "                \"\\n 4 frames from videocrafter2 \\n \",\n",
    "                *map(lambda x: {\"type\": \"image_url\", \n",
    "                                \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['videocrafter2']),   \n",
    "                \"\\n 7 frames from pika \\n\",\n",
    "                *map(lambda x: {\"type\": \"image_url\", \n",
    "                                \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['pika']),\n",
    "                \"\\n 8 frames from show1\\n \",\n",
    "                *map(lambda x: {\"type\": \"image_url\", \n",
    "                                \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['show1']),                             \n",
    "                \"\\n5 frames from lavie\\n \",\n",
    "                *map(lambda x: {\"type\": \"image_url\", \n",
    "                                \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}},frames['lavie']),\n",
    "                                                          ],\n",
    "                }\n",
    "            ],\n",
    "            temperature=0,\n",
    "            )\n",
    "            print(response.choices[0].message.content) \n",
    "            s[i] = response.choices[0].message.content.replace('\\n\\n','\\n')\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            s[i] = 'Error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# 使用 json 保存字典\n",
    "with open(file_path, \"w\") as f:\n",
    "    json.dump(s, f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(file_path, \"r\") as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "# video_path = './Human_anno/object_class.json'\n",
    "# with open(video_path, \"r\") as file:\n",
    "#     annotations = json.load(file)\n",
    "\n",
    "# for index,key in enumerate(data.keys()):       \n",
    "#     for line in data[key].split('\\n'):\n",
    "#         if line == '' or line[0] != '-':\n",
    "#             continue\n",
    "#         model_name = line.split(',')[0].split(' ')[1].split(':')[0].lower()\n",
    "#         score = int(line.split(',')[0].split(' ')[2])\n",
    "#         annotations[index]['gpt4o_eval'][model_name] = score\n",
    "    \n",
    "# with open(video_path, \"w\") as f:\n",
    "#     json.dump(annotations, f,indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
