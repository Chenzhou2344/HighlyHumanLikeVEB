{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from tool import videoreader\n",
    "# 创建一个OpenAI客户端实例\n",
    "client = OpenAI(\n",
    "    api_key=\"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\",\n",
    "    base_url=\"https://gateway.ai.cloudflare.com/v1/627f1b1f372e3a198dc32573bbc6f720/openai-gpt/openai\"  # 替换为你的自定义API域\n",
    ")\n",
    "\n",
    "## Set the API key and model name\n",
    "MODEL=\"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 'temporal_consistency'\n",
    "from PromptTemplate4GPTeval import Prompt4TemperalConsistency\n",
    "prompt_template = Prompt4TemperalConsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data_prepath = '../data4dimensions/'\n",
    "# data_prepath = \"../../data4dimensions/\"\n",
    "with open(\"./Human_anno/{}.json\".format(dimension)) as f:\n",
    "    human_anno = json.load(f)\n",
    "\n",
    "batch_stpath = '../batch_api/{}'.format(dimension)\n",
    "if not os.path.exists(batch_stpath):\n",
    "    os.makedirs(batch_stpath)\n",
    "\n",
    "batch_unique_ids = []\n",
    "batch_split_ids = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_batch(index_list,batch_id):\n",
    "#     requests = []\n",
    "#     for i in index_list:     \n",
    "#         request ={\"custom_id\": \"request-{}\".format(i), \n",
    "#                 \"method\": \"POST\", \n",
    "#                 \"url\": \"/v1/chat/completions\",\n",
    "#                 \"body\": {\"model\": MODEL,\n",
    "#                             \"messages\": [],\n",
    "#                             \"temperature\": 0}}\n",
    "\n",
    "#         frames = videoreader.process_video(data_prepath,human_anno[i]['videos'],2 ,resize_fx=1,resize_fy=1)\n",
    "\n",
    "#         prompten = human_anno[i]['prompt_en']\n",
    "#         # question = human_anno[i]['question_en']\n",
    "#         # subject = human_anno[i]['subject_en']\n",
    "#         # scene = human_anno[i]['scene_en']\n",
    "#         # objet = human_anno[i]['object']\n",
    "#         messages=[\n",
    "#         {\n",
    "#         \"role\": \"system\", \"content\":\n",
    "#             prompt_template\n",
    "#             }\n",
    "#             ,\n",
    "#         {\n",
    "#             \"role\": \"user\", \"content\": [\n",
    "#             \"These are the frames from the videos.\",\n",
    "#             \"12 frames from cogvideox5b \\n \", \n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['cogvideox5b']),\n",
    "#             \"10 frames from kling \\n \", \n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['kling']),\n",
    "#             \"10 frames from gen3 \\n \", \n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['gen3']),\n",
    "#             \" 4 frames from videocrafter2 \\n \",\n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['videocrafter2']),   \n",
    "#             \"\\n 7 frames from pika \\n\",\n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['pika']),\n",
    "#             \"\\n 8 frames from show1\\n \",\n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\":    f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['show1']),                             \n",
    "#             \"\\n5 frames from lavie\\n \",\n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}},frames['lavie']),\n",
    "#                                                         ],\n",
    "#             }\n",
    "#         ]\n",
    "\n",
    "#         request['body']['messages'] = messages\n",
    "\n",
    "#         requests.append(request)\n",
    "\n",
    "#     with open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"w\") as f:\n",
    "#         for entry in requests:\n",
    "#             json_line = json.dumps(entry)\n",
    "#             f.write(json_line + '\\n')\n",
    "    \n",
    "#     batch_input_file = client.files.create(\n",
    "#              file=open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"rb\"),\n",
    "#               purpose=\"batch\"\n",
    "#              )\n",
    "\n",
    "#     batch_input_file_id = batch_input_file.id    \n",
    "\n",
    "#     batch_object = client.batches.create(\n",
    "#             input_file_id=batch_input_file_id,\n",
    "#             endpoint=\"/v1/chat/completions\",\n",
    "#             completion_window=\"24h\",\n",
    "#             metadata={\n",
    "#             \"description\": \"nightly group1 {} eval job batch {}\".format(dimension,batch_id)\n",
    "#             }\n",
    "#                                         )\n",
    "\n",
    "#     batch_unique_ids.append(batch_object.id)\n",
    "#     batch_split_ids.append(batch_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_batch_onebyone(index_list,batch_id):\n",
    "    print(\"Thread {} is running\".format(batch_id))\n",
    "    model2message = {\n",
    "    'cogvideox5b':\"12 frames from cogvideox5b\\n\",\n",
    "    'kling':\"10 frames from kling \\n \", \n",
    "    'gen3': \"10 frames from gen3 \\n\",\n",
    "    'videocrafter2':\"4 frames from videocrafter2\",\n",
    "    'pika':\"7 frames from pika \",\n",
    "    'show1':\"8 frames from show1 \",\n",
    "    'lavie':\"5 frames from lavie \",\n",
    "    }\n",
    "    requests = []\n",
    "    for key, value in model2message.items():\n",
    "        modelname = key\n",
    "        modelmessage = value\n",
    "   \n",
    "        for i in index_list:     \n",
    "            request ={\"custom_id\": \"request-{}-{}\".format(i,modelname), \n",
    "                    \"method\": \"POST\", \n",
    "                    \"url\": \"/v1/chat/completions\",\n",
    "                    \"body\": {\"model\": MODEL,\n",
    "                                \"messages\": [],\n",
    "                                \"temperature\": 0}}\n",
    "\n",
    "            frames = videoreader.process_video2gridview(data_prepath,human_anno[i]['videos'],8)\n",
    "            \n",
    "            prompten = human_anno[i]['prompt_en']\n",
    "            # question = human_anno[i]['question_en']\n",
    "            # subject = human_anno[i]['subject_en']\n",
    "            # scene = human_anno[i]['scene_en']\n",
    "            # objet = human_anno[i]['object']\n",
    "            messages=[\n",
    "            {\n",
    "            \"role\": \"system\", \"content\":\n",
    "                prompt_template\n",
    "                }\n",
    "                ,\n",
    "            {\n",
    "                \"role\": \"user\", \"content\": [\n",
    "                \" The following images are concatenated by the key frames of the video.And one of the following images arranges 8 key frames per second from a video in a 1*8 grid view.\" ,\n",
    "                *map(lambda x: {\"type\": \"image_url\", \n",
    "                                \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}},frames['kling']),                                                         \n",
    "                \"The video most likely has some unnatural changes.Try your to analyse unnatural changes and evaluate the temporal consistency of the video based on your analysis and system message.\",\n",
    "                \"Assuming there are a video scoring 'x',provide your analysis and explanation in the output format as follows:\\n\"\n",
    "                \"- Video: x ,because ...\"\n",
    "              ],\n",
    "                }\n",
    "            ]\n",
    "            request['body']['messages'] = messages\n",
    "            requests.append(request)\n",
    "\n",
    "    with open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"w\") as f:\n",
    "        for entry in requests:\n",
    "            json_line = json.dumps(entry)\n",
    "            f.write(json_line + '\\n')\n",
    "    \n",
    "    batch_input_file = client.files.create(\n",
    "             file=open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"rb\"),\n",
    "              purpose=\"batch\"\n",
    "             )\n",
    "\n",
    "    batch_input_file_id = batch_input_file.id    \n",
    "\n",
    "    batch_object = client.batches.create(\n",
    "            input_file_id=batch_input_file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "            metadata={\n",
    "            \"description\": \"nightly group1 {} eval job batch {}\".format(dimension,batch_id)\n",
    "            }\n",
    "                                        )\n",
    "    \n",
    "    batch_split_ids.append(batch_id)\n",
    "    batch_unique_ids.append(batch_object.id)\n",
    "\n",
    "    print(\"Thread {} is done\".format(batch_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 = list(range(1,len(human_anno),3))\n",
    "# l2 = list(range(2,len(human_anno),3))\n",
    "l3 = list(range(0,len(human_anno),3))\n",
    "ls = l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 0 is runningThread 1 is running\n",
      "\n",
      "Thread 2 is running\n",
      "Thread 3 is running\n",
      "Thread 4 is running\n",
      "Thread 5 is running\n",
      "Thread 6 is running\n",
      "Thread 7 is running\n",
      "Thread 8 is running\n",
      "Thread 9 is running\n",
      "Thread 10 is running\n",
      "Thread 11 is running\n",
      "Thread 12 is running\n",
      "Thread 13 is running\n",
      "Thread 14 is running\n",
      "Thread 15 is running\n",
      "Thread 16 is running\n",
      "Thread 17 is running\n",
      "Thread 18 is running\n",
      "Thread 19 is running\n",
      "Thread 20 is running\n",
      "Thread 21 is running\n",
      "Thread 22 is running\n",
      "Thread 23 is running\n",
      "Thread 24 is running\n",
      "Thread 25 is running\n",
      "All threads started\n",
      "Thread 13 is done\n",
      "Thread 10 is done\n",
      "Thread 5 is done\n",
      "Thread 3 is done\n",
      "Thread 1 is done\n",
      "Thread 16 is done\n",
      "Thread 9 is done\n",
      "Thread 2 is done\n",
      "Thread 20 is done\n",
      "Thread 0 is done\n",
      "Thread 7 is done\n",
      "Thread 18 is done\n",
      "Thread 12 is done\n",
      "Thread 11 is done\n",
      "Thread 24 is done\n",
      "Thread 21 is done\n",
      "Thread 4 is done\n",
      "Thread 8 is done\n",
      "Thread 25 is done\n",
      "Thread 15 is done\n",
      "Thread 14 is done\n",
      "Thread 22 is done\n",
      "Thread 19 is done\n",
      "Thread 17 is done\n",
      "Thread 6 is done\n",
      "Thread 23 is done\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "batch_size = 3\n",
    "batches = [ls[i:i + batch_size] for i in range(0, len(ls), batch_size)]\n",
    "\n",
    "# with open(\"./batch_infos/batch_info_{}.json\".format(dimension), \"r\") as f:\n",
    "#     batch_info = json.load(f)\n",
    "\n",
    "# batch_split_ids = batch_info['batch_split_ids']\n",
    "# batches = batch_info['videos_in_batch']\n",
    "\n",
    "threads = []\n",
    "for i, batch in enumerate(batches):\n",
    "    thread = threading.Thread(target=eval_batch_onebyone, args=(batch, i))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "print(\"All threads started\")\n",
    "# 等待所有线程完成\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "#保存batch信息\n",
    "with open(\"./batch_infos/batch_info_{}.json\".format(dimension), \"w\") as f:\n",
    "    json.dump({\"batch_unique_ids\": batch_unique_ids, \"batch_split_ids\": batch_split_ids,\"videos_in_batch\":batches}, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id:batch_672bafddbd788190b80600e866a877e8 status:in_progress descrepition:nightly group1 temporal_consistency eval job batch 13\n",
      "id:batch_672bb00953e8819083ba966e093180ab status:failed descrepition:nightly group1 temporal_consistency eval job batch 10\n",
      "id:batch_672bb01ba1c88190839d917585311732 status:failed descrepition:nightly group1 temporal_consistency eval job batch 5\n",
      "id:batch_672bb1b0cf9c8190beb39e2ea3458cdf status:failed descrepition:nightly group1 temporal_consistency eval job batch 3\n",
      "id:batch_672bb2c446348190b238a8c1adbba679 status:in_progress descrepition:nightly group1 temporal_consistency eval job batch 1\n",
      "id:batch_672bb304a9d88190ba259596419e5d7a status:failed descrepition:nightly group1 temporal_consistency eval job batch 16\n",
      "id:batch_672bb36232208190a7fd0f9658688c35 status:failed descrepition:nightly group1 temporal_consistency eval job batch 9\n",
      "id:batch_672bb362855881909673062a9e7f306d status:failed descrepition:nightly group1 temporal_consistency eval job batch 2\n",
      "id:batch_672bb37bb6a8819092755f56ec0d6531 status:failed descrepition:nightly group1 temporal_consistency eval job batch 20\n",
      "id:batch_672bb3ce77248190a568c7d82323b1c6 status:failed descrepition:nightly group1 temporal_consistency eval job batch 0\n",
      "id:batch_672bb41340488190b8bef654a40ceab4 status:failed descrepition:nightly group1 temporal_consistency eval job batch 7\n",
      "id:batch_672bb473d6a8819084fd71901ec3b46c status:failed descrepition:nightly group1 temporal_consistency eval job batch 18\n",
      "id:batch_672bb48d4ce88190bc3e22fe8ff323a3 status:failed descrepition:nightly group1 temporal_consistency eval job batch 12\n",
      "id:batch_672bb4a93fa4819098d04eac59ff452f status:failed descrepition:nightly group1 temporal_consistency eval job batch 11\n",
      "id:batch_672bb4c72a5c8190984d994de181994f status:failed descrepition:nightly group1 temporal_consistency eval job batch 24\n",
      "id:batch_672bb50f168481909b999a44faa4a74f status:failed descrepition:nightly group1 temporal_consistency eval job batch 21\n",
      "id:batch_672bb524739481909edeb0b8e57d89c9 status:in_progress descrepition:nightly group1 temporal_consistency eval job batch 4\n",
      "id:batch_672bb5355f248190969b039a57040868 status:in_progress descrepition:nightly group1 temporal_consistency eval job batch 8\n",
      "id:batch_672bb556bf508190894cd9618d9003da status:failed descrepition:nightly group1 temporal_consistency eval job batch 25\n",
      "id:batch_672bb56509e0819087f6cd254f1e291a status:failed descrepition:nightly group1 temporal_consistency eval job batch 15\n",
      "id:batch_672bb5786f8081908449ca3fc83bf3fa status:failed descrepition:nightly group1 temporal_consistency eval job batch 14\n",
      "id:batch_672bb5a2783c819081b1c1bf0a3c5ed6 status:failed descrepition:nightly group1 temporal_consistency eval job batch 22\n",
      "id:batch_672bb5da09ac8190b8b5cfbac3c9a73c status:failed descrepition:nightly group1 temporal_consistency eval job batch 19\n",
      "id:batch_672bb63d90fc81909adeb2cfd9922e61 status:failed descrepition:nightly group1 temporal_consistency eval job batch 17\n",
      "id:batch_672bb653502481908ed9434c12dc9133 status:failed descrepition:nightly group1 temporal_consistency eval job batch 6\n",
      "id:batch_672bb664d90c81909bb95a6cda4b1afd status:failed descrepition:nightly group1 temporal_consistency eval job batch 23\n"
     ]
    }
   ],
   "source": [
    "with open(\"./batch_infos/batch_info_{}.json\".format(dimension), \"r\") as f:\n",
    "    batch_info = json.load(f)\n",
    "\n",
    "    \n",
    "batchids = batch_info[\"batch_unique_ids\"]\n",
    "llmeval_path = \"./GPT4o_eval_results/{}/{}_llmeval_gridview2.json\".format(dimension,dimension)\n",
    "\n",
    "with open(llmeval_path, \"r\") as f:\n",
    "    llmeval = json.load(f)\n",
    "for i in ls:\n",
    "    llmeval[str(i)] = {}\n",
    "\n",
    "for id in batchids:\n",
    "    batch_object = client.batches.retrieve(id)\n",
    "    print(\"id:{} status:{} descrepition:{}\".format(id,batch_object.status,batch_object.metadata['description']))\n",
    "\n",
    "    # if batch_object.status != \"completed\":\n",
    "    #     print(\"batch {} is not completed\".format(id))\n",
    "    #     continue    \n",
    "\n",
    "    # file_response = client.files.content(batch_object.output_file_id)\n",
    "    # for line in file_response.text.splitlines():\n",
    "    #     index = json.loads(line)[\"custom_id\"].split(\"-\")[-2]\n",
    "    #     model = json.loads(line)[\"custom_id\"].split(\"-\")[-1]\n",
    "    #     eval_res = json.loads(line)[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"].replace('\\n\\n','\\n')\n",
    "    #     llmeval[index][model] = eval_res\n",
    "    # with open(llmeval_path, \"w\") as f:\n",
    "    #     json.dump(llmeval, f, indent=4)\n",
    "\n",
    "    # print(\"batch {} done,end index {}\".format(id,index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
