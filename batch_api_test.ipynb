{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from tool import videoreader\n",
    "# 创建一个OpenAI客户端实例\n",
    "client = OpenAI(\n",
    "    api_key=\"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\",\n",
    "    base_url=\"https://gateway.ai.cloudflare.com/v1/627f1b1f372e3a198dc32573bbc6f720/openai-gpt/openai\"  # 替换为你的自定义API域\n",
    ")\n",
    "\n",
    "## Set the API key and model name\n",
    "MODEL=\"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 'temporal_consistency'\n",
    "from PromptTemplate4GPTeval import Prompt4TemperalConsistency\n",
    "prompt_template = Prompt4TemperalConsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data_prepath = r'D:\\Astudying\\VideoEval\\data4dimensions'\n",
    "# data_prepath = \"../../data4dimensions/\"\n",
    "with open(\"./Human_anno/{}.json\".format(dimension)) as f:\n",
    "    human_anno = json.load(f)\n",
    "\n",
    "batch_stpath = '../batch_api/{}'.format(dimension)\n",
    "if not os.path.exists(batch_stpath):\n",
    "    os.makedirs(batch_stpath)\n",
    "\n",
    "batch_unique_ids = []\n",
    "batch_split_ids = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_batch(index_list,batch_id):\n",
    "#     requests = []\n",
    "#     for i in index_list:     \n",
    "#         request ={\"custom_id\": \"request-{}\".format(i), \n",
    "#                 \"method\": \"POST\", \n",
    "#                 \"url\": \"/v1/chat/completions\",\n",
    "#                 \"body\": {\"model\": MODEL,\n",
    "#                             \"messages\": [],\n",
    "#                             \"temperature\": 0}}\n",
    "\n",
    "#         frames = videoreader.process_video2gridview(data_prepath,human_anno[i]['videos'],4)\n",
    "\n",
    "#         prompten = human_anno[i]['prompt_en']\n",
    "#         # question = human_anno[i]['question_en']\n",
    "#         # subject = human_anno[i]['subject_en']\n",
    "#         # scene = human_anno[i]['scene_en']\n",
    "#         # objet = human_anno[i]['object']\n",
    "#         messages=[\n",
    "#         {\n",
    "#         \"role\": \"system\", \"content\":\n",
    "#             prompt_template\n",
    "#             }\n",
    "#             ,\n",
    "#         {\n",
    "#             \"role\": \"user\", \"content\": [\n",
    "            \n",
    "#             \" The following images arrange 4 key frames from 1 second video clip from videos in a 1*4 grid view.\" ,\n",
    "\n",
    "#             \"The grid view images from model1 \\n \", \n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['cogvideox5b']),\n",
    "#             \"The grid view images from model2 \\n \", \n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['kling']),\n",
    "#             \"The grid view images from model3 \\n \", \n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['gen3']),\n",
    "#             \" The grid view images from model4 \\n \",\n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['videocrafter2']),   \n",
    "#             \"\\nThe grid view images from model5 \\n\",\n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['pika']),\n",
    "#             \"\\n The grid view images from model6\\n \",\n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\":    f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['show1']),                             \n",
    "#             \"\\nThe grid view images from  model7\\n \",\n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}},frames['lavie']),\n",
    "\n",
    "#            \"Assuming there are  videos scoring 'x,y,z..',provide your analysis and explanation in the output format as follows:\\n\"\n",
    "#             \"- model1: x ,because ...\\n \"\n",
    "#             \"- model2: y ,because ...\\n \"\n",
    "#             \"- model3: z ,because ...\\n \"\n",
    "#                                                         ],\n",
    " \n",
    "#             }\n",
    "#         ]\n",
    "\n",
    "#         request['body']['messages'] = messages\n",
    "\n",
    "#         requests.append(request)\n",
    "\n",
    "#     with open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"w\") as f:\n",
    "#         for entry in requests:\n",
    "#             json_line = json.dumps(entry)\n",
    "#             f.write(json_line + '\\n')\n",
    "    \n",
    "#     batch_input_file = client.files.create(\n",
    "#              file=open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"rb\"),\n",
    "#               purpose=\"batch\"\n",
    "#              )\n",
    "\n",
    "#     batch_input_file_id = batch_input_file.id    \n",
    "\n",
    "#     batch_object = client.batches.create(\n",
    "#             input_file_id=batch_input_file_id,\n",
    "#             endpoint=\"/v1/chat/completions\",\n",
    "#             completion_window=\"24h\",\n",
    "#             metadata={\n",
    "#             \"description\": \"nightly group1 {} eval job batch {}\".format(dimension,batch_id)\n",
    "#             }\n",
    "#                                         )\n",
    "\n",
    "#     batch_unique_ids.append(batch_object.id)\n",
    "#     batch_split_ids.append(batch_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_batch_onebyone(index_list,batch_id):\n",
    "    print(\"Thread {} is running\".format(batch_id))\n",
    "    model2message = {\n",
    "    'cogvideox5b':\"12 frames from cogvideox5b,which you need to evaluate \\n\",\n",
    "    'kling':\"10 frames from kling ,which you need to evaluate\\n \", \n",
    "    'gen3': \"10 frames from gen3 ,which you need to evaluate\\n\",\n",
    "    'videocrafter2':\"4 frames from videocrafter2,which you need to evaluate\",\n",
    "    'pika':\"7 frames from pika ,which you need to evaluate\",\n",
    "    'show1':\"8 frames from show1,which you need to evaluate \",\n",
    "    'lavie':\"5 frames from lavie ,which you need to evaluate\",\n",
    "    }\n",
    "    requests = []\n",
    "    for i in index_list:     \n",
    "        frames = videoreader.process_video2gridview(data_prepath,human_anno[i]['videos'],4)\n",
    "        for key, value in model2message.items():\n",
    "            modelname = key\n",
    "            modelmessage = value\n",
    "    \n",
    "            request ={\"custom_id\": \"request-{}-{}\".format(i,modelname), \n",
    "                    \"method\": \"POST\", \n",
    "                    \"url\": \"/v1/chat/completions\",\n",
    "                    \"body\": {\"model\": MODEL,\n",
    "                                \"messages\": [],\n",
    "                                \"temperature\": 0}}\n",
    "\n",
    "            examplemodels = [x for x in model2message.keys() if x != modelname]\n",
    "\n",
    "\n",
    "            prompten = human_anno[i]['prompt_en']\n",
    "            # question = human_anno[i]['question_en']\n",
    "            # subject = human_anno[i]['subject_en']\n",
    "            # scene = human_anno[i]['scene_en']\n",
    "            # objet = human_anno[i]['object']\n",
    "            messages=[\n",
    "            {\n",
    "            \"role\": \"system\", \"content\":\n",
    "                prompt_template\n",
    "                }\n",
    "                ,\n",
    "            {\n",
    "                \"role\": \"user\", \"content\":[\n",
    "\n",
    "            \" The following images arrange the key frames of the video with one displaying the 4 frames extracted from each second in a in a 1*4 grid view.\" ,\n",
    "            *map(lambda x: {\"type\": \"image_url\", \n",
    "                \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}},frames[modelname]),    \n",
    "\n",
    "            \"The video most likely has some unnatural changes,texture flikering or color jitter.Try your to analyse and evaluate the temporal consistency of the video based on your analysis and system message.\",\n",
    "            \"Assuming there are a video scoring 'x',provide your analysis and explanation in the output format as follows:\\n\"\n",
    "            \"- video: x ,because ...\"\n",
    "              ],\n",
    "                }\n",
    "            ]\n",
    "            request['body']['messages'] = messages\n",
    "            requests.append(request)\n",
    "\n",
    "    with open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"w\") as f:\n",
    "        for entry in requests:\n",
    "            json_line = json.dumps(entry)\n",
    "            f.write(json_line + '\\n')\n",
    "    \n",
    "    batch_input_file = client.files.create(\n",
    "             file=open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"rb\"),\n",
    "              purpose=\"batch\"\n",
    "             )\n",
    "\n",
    "    batch_input_file_id = batch_input_file.id    \n",
    "\n",
    "    batch_object = client.batches.create(\n",
    "            input_file_id=batch_input_file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "            metadata={\n",
    "            \"description\": \"nightly group1 {} eval job batch {}\".format(dimension,batch_id)\n",
    "            }\n",
    "                                        )\n",
    "    \n",
    "    batch_split_ids.append(batch_id)\n",
    "    batch_unique_ids.append(batch_object.id)\n",
    "\n",
    "    print(\"Thread {} is done\".format(batch_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = list(range(1,len(human_anno),3))\n",
    "# l2 = list(range(2,len(human_anno),3))\n",
    "# l3 = list(range(0,len(human_anno),3))\n",
    "\n",
    "# l = [int(x) for x in['204', '207', '210', '213', '216', '219', '222', '225', '228', '231']]\n",
    "\n",
    "\n",
    "ls = l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 0 is running\n",
      "Thread 1 is running\n",
      "Thread 2 is running\n",
      "Thread 3 is running\n",
      "Thread 4 is running\n",
      "Thread 5 is running\n",
      "Thread 6 is running\n",
      "Thread 7 is running\n",
      "Thread 8 is running\n",
      "Thread 9 is running\n",
      "Thread 10 is running\n",
      "Thread 11 is running\n",
      "Thread 12 is running\n",
      "Thread 13 is running\n",
      "Thread 14 is running\n",
      "Thread 15 is running\n",
      "Thread 16 is running\n",
      "Thread 17 is running\n",
      "Thread 18 is running\n",
      "Thread 19 is running\n",
      "Thread 20 is running\n",
      "Thread 21 is running\n",
      "Thread 22 is running\n",
      "Thread 23 is running\n",
      "Thread 24 is running\n",
      "Thread 25 is running\n",
      "All threads started\n",
      "Thread 25 is done\n",
      "Thread 5 is done\n",
      "Thread 13 is done\n",
      "Thread 24 is done\n",
      "Thread 16 is done\n",
      "Thread 4 is done\n",
      "Thread 1 is done\n",
      "Thread 10 is done\n",
      "Thread 0 is done\n",
      "Thread 12 is done\n",
      "Thread 6 is done\n",
      "Thread 19 is done\n",
      "Thread 15 is done\n",
      "Thread 14 is done\n",
      "Thread 9 is done\n",
      "Thread 20 is done\n",
      "Thread 7 is done\n",
      "Thread 3 is done\n",
      "Thread 11 is done\n",
      "Thread 2 is done\n",
      "Thread 8 is done\n",
      "Thread 21 is done\n",
      "Thread 23 is done\n",
      "Thread 22 is done\n",
      "Thread 18 is done\n",
      "Thread 17 is done\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "batch_size = 5\n",
    "batches = [ls[i:i + batch_size] for i in range(0, len(ls), batch_size)]\n",
    "# with open(\"./batch_infos/batch_info_{}.json\".format(dimension), \"r\") as f:\n",
    "#     batch_info = json.load(f)\n",
    "\n",
    "# batch_split_ids = batch_info['batch_split_ids']\n",
    "# batches = batch_info['videos_in_batch']\n",
    "\n",
    "threads = []\n",
    "for i, batch in enumerate(batches):\n",
    "    thread = threading.Thread(target=eval_batch_onebyone, args=(batch, i))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "print(\"All threads started\")\n",
    "# 等待所有线程完成\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "#保存batch信息\n",
    "with open(\"./batch_infos/batch_info_{}_gridstress_group2.json\".format(dimension), \"w\") as f:\n",
    "    json.dump({\"batch_unique_ids\": batch_unique_ids, \"batch_split_ids\": batch_split_ids,\"videos_in_batch\":batches}, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id:batch_67318d67194c81908e118c1e10c496eb status:completed descrepition:nightly group1 temporal_consistency eval job batch 25\n",
      "batch batch_67318d67194c81908e118c1e10c496eb done,end index 232\n",
      "id:batch_67318d89272c81909fce6d5c6eea4674 status:completed descrepition:nightly group1 temporal_consistency eval job batch 5\n",
      "batch batch_67318d89272c81909fce6d5c6eea4674 done,end index 52\n",
      "id:batch_67318d8ac44c8190b0fa4875f495a3c0 status:completed descrepition:nightly group1 temporal_consistency eval job batch 13\n",
      "batch batch_67318d8ac44c8190b0fa4875f495a3c0 done,end index 124\n",
      "id:batch_67318d8e46e481909f2eaa66719692dc status:completed descrepition:nightly group1 temporal_consistency eval job batch 24\n",
      "batch batch_67318d8e46e481909f2eaa66719692dc done,end index 223\n",
      "id:batch_67318d8ecd4081909dad0d363fa2e2fe status:completed descrepition:nightly group1 temporal_consistency eval job batch 16\n",
      "batch batch_67318d8ecd4081909dad0d363fa2e2fe done,end index 151\n",
      "id:batch_67318d8f68e88190ac806990556edad7 status:completed descrepition:nightly group1 temporal_consistency eval job batch 4\n",
      "batch batch_67318d8f68e88190ac806990556edad7 done,end index 43\n",
      "id:batch_67318d93c5808190afa87754ea038181 status:completed descrepition:nightly group1 temporal_consistency eval job batch 1\n",
      "batch batch_67318d93c5808190afa87754ea038181 done,end index 16\n",
      "id:batch_67318d9a9c2c8190a486700a1313781a status:completed descrepition:nightly group1 temporal_consistency eval job batch 10\n",
      "batch batch_67318d9a9c2c8190a486700a1313781a done,end index 97\n",
      "id:batch_67318da47ac88190b025639bb443cd86 status:completed descrepition:nightly group1 temporal_consistency eval job batch 0\n",
      "batch batch_67318da47ac88190b025639bb443cd86 done,end index 7\n",
      "id:batch_67318da7a81c81908376d1e2e039e536 status:completed descrepition:nightly group1 temporal_consistency eval job batch 12\n",
      "batch batch_67318da7a81c81908376d1e2e039e536 done,end index 115\n",
      "id:batch_67318daafa8481908237a0dd3b923371 status:completed descrepition:nightly group1 temporal_consistency eval job batch 6\n",
      "batch batch_67318daafa8481908237a0dd3b923371 done,end index 61\n",
      "id:batch_67318dad78708190b01519bef42a16ea status:completed descrepition:nightly group1 temporal_consistency eval job batch 19\n",
      "batch batch_67318dad78708190b01519bef42a16ea done,end index 178\n",
      "id:batch_67318dadfd3c8190b93224a3dbe7349f status:completed descrepition:nightly group1 temporal_consistency eval job batch 15\n",
      "batch batch_67318dadfd3c8190b93224a3dbe7349f done,end index 142\n",
      "id:batch_67318db0dcec8190bd632c02bad884b8 status:completed descrepition:nightly group1 temporal_consistency eval job batch 14\n",
      "batch batch_67318db0dcec8190bd632c02bad884b8 done,end index 133\n",
      "id:batch_67318db1613c8190b981f1c26e412934 status:completed descrepition:nightly group1 temporal_consistency eval job batch 9\n",
      "batch batch_67318db1613c8190b981f1c26e412934 done,end index 88\n",
      "id:batch_67318db2592c81909c18da257cee6588 status:completed descrepition:nightly group1 temporal_consistency eval job batch 20\n",
      "batch batch_67318db2592c81909c18da257cee6588 done,end index 187\n",
      "id:batch_67318db3384c8190941546f131fe6aa0 status:completed descrepition:nightly group1 temporal_consistency eval job batch 7\n",
      "batch batch_67318db3384c8190941546f131fe6aa0 done,end index 70\n",
      "id:batch_67318db425c88190ba756a110718ac82 status:completed descrepition:nightly group1 temporal_consistency eval job batch 3\n",
      "batch batch_67318db425c88190ba756a110718ac82 done,end index 34\n",
      "id:batch_67318db677dc819083e353d57e2ccc89 status:completed descrepition:nightly group1 temporal_consistency eval job batch 11\n",
      "batch batch_67318db677dc819083e353d57e2ccc89 done,end index 106\n",
      "id:batch_67318dbb62048190a9f07583d4c1bb08 status:completed descrepition:nightly group1 temporal_consistency eval job batch 2\n",
      "batch batch_67318dbb62048190a9f07583d4c1bb08 done,end index 25\n",
      "id:batch_67318dbc19188190970bd4e2eb07af2a status:completed descrepition:nightly group1 temporal_consistency eval job batch 8\n",
      "batch batch_67318dbc19188190970bd4e2eb07af2a done,end index 79\n",
      "id:batch_67318dc16f6081909846207f35ea744c status:completed descrepition:nightly group1 temporal_consistency eval job batch 21\n",
      "batch batch_67318dc16f6081909846207f35ea744c done,end index 196\n",
      "id:batch_67318dc28e508190b24ec52d29e712e7 status:completed descrepition:nightly group1 temporal_consistency eval job batch 23\n",
      "batch batch_67318dc28e508190b24ec52d29e712e7 done,end index 214\n",
      "id:batch_67318dc2ca308190bbf6cc5e5646c198 status:completed descrepition:nightly group1 temporal_consistency eval job batch 22\n",
      "batch batch_67318dc2ca308190bbf6cc5e5646c198 done,end index 205\n",
      "id:batch_67318dcc20f481908e297fcb683106ef status:completed descrepition:nightly group1 temporal_consistency eval job batch 18\n",
      "batch batch_67318dcc20f481908e297fcb683106ef done,end index 169\n",
      "id:batch_67318dd440688190a8dee7926290d55b status:completed descrepition:nightly group1 temporal_consistency eval job batch 17\n",
      "batch batch_67318dd440688190a8dee7926290d55b done,end index 160\n"
     ]
    }
   ],
   "source": [
    "with open(\"./batch_infos/batch_info_{}_gridstress_group2.json\".format(dimension), \"r\") as f:\n",
    "    batch_info = json.load(f)\n",
    "\n",
    "    \n",
    "batchids = batch_info[\"batch_unique_ids\"]\n",
    "llmeval_path = \"./GPT4o_eval_results/{}/{}_llmeval_gridview_usrstress.json\".format(dimension,dimension)\n",
    "\n",
    "with open(llmeval_path, \"r\") as f:\n",
    "    llmeval = json.load(f)\n",
    "    \n",
    "for i in ls:\n",
    "    if str(i) not in llmeval.keys():\n",
    "         llmeval[str(i)] = {}\n",
    "\n",
    "for id in batchids:\n",
    "    batch_object = client.batches.retrieve(id)\n",
    "    print(\"id:{} status:{} descrepition:{}\".format(id,batch_object.status,batch_object.metadata['description']))\n",
    "\n",
    "    if batch_object.status != \"completed\":\n",
    "        print(\"batch {} is not completed\".format(id))\n",
    "        continue    \n",
    "\n",
    "    file_response = client.files.content(batch_object.output_file_id)\n",
    "    for line in file_response.text.splitlines():\n",
    "        index = json.loads(line)[\"custom_id\"].split(\"-\")[-2]\n",
    "        model = json.loads(line)[\"custom_id\"].split(\"-\")[-1]\n",
    "\n",
    "        # index = json.loads(line)[\"custom_id\"].split(\"-\")[-1]\n",
    "\n",
    "        eval_res = json.loads(line)[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"].replace('\\n\\n','\\n')\n",
    "        \n",
    "        llmeval[index][model] = eval_res\n",
    "        # llmeval[index] = eval_res\n",
    "    with open(llmeval_path, \"w\") as f:\n",
    "        json.dump(llmeval, f, indent=4)\n",
    "\n",
    "    print(\"batch {} done,end index {}\".format(id,index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
