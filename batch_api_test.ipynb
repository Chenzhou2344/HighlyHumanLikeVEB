{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from tool import videoreader\n",
    "# 创建一个OpenAI客户端实例\n",
    "client = OpenAI(\n",
    "    api_key=\"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\",\n",
    "    base_url=\"https://gateway.ai.cloudflare.com/v1/627f1b1f372e3a198dc32573bbc6f720/openai-gpt/openai\"  # 替换为你的自定义API域\n",
    ")\n",
    "\n",
    "## Set the API key and model name\n",
    "MODEL=\"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 'motion_effects'\n",
    "from PromptTemplate4GPTeval import Prompt4Motioneffects\n",
    "prompt_template = Prompt4Motioneffects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data_prepath = r'D:\\Astudying\\VideoEval\\data4dimensions'\n",
    "# data_prepath = \"../../data4dimensions/\"\n",
    "with open(\"./Human_anno/{}.json\".format(dimension)) as f:\n",
    "    human_anno = json.load(f)\n",
    "\n",
    "batch_stpath = '../batch_api/{}'.format(dimension)\n",
    "if not os.path.exists(batch_stpath):\n",
    "    os.makedirs(batch_stpath)\n",
    "\n",
    "batch_unique_ids = []\n",
    "batch_split_ids = []\n",
    "\n",
    "# with open(\"./batch_infos/batch_info_{}_gridstress_group3.json\".format(dimension), \"r\") as f:\n",
    "#     batch_info = json.load(f)\n",
    "\n",
    "# batch_split_ids = batch_info['batch_split_ids']\n",
    "# batch_unique_ids = batch_info['batch_unique_ids']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_batch(index_list,batch_id):\n",
    "#     requests = []\n",
    "# #     model2message = {\n",
    "# #     'cogvideox5b':\"12 frames from cogvideox5b,which you need to evaluate \\n\",\n",
    "# #     'kling':\"10 frames from kling ,which you need to evaluate\\n \", \n",
    "# #     'gen3': \"10 frames from gen3 ,which you need to evaluate\\n\",\n",
    "# #     'videocrafter2':\"4 frames from videocrafter2,which you need to evaluate\",\n",
    "# #     'pika':\"7 frames from pika ,which you need to evaluate\",\n",
    "# #     'show1':\"8 frames from show1,which you need to evaluate \",\n",
    "# #     'lavie':\"5 frames from lavie ,which you need to evaluate\",\n",
    "# #     }\n",
    "#     for i in index_list:     \n",
    "#         request ={\"custom_id\": \"request-{}\".format(i), \n",
    "#                 \"method\": \"POST\", \n",
    "#                 \"url\": \"/v1/chat/completions\",\n",
    "#                 \"body\": {\"model\": MODEL,\n",
    "#                             \"messages\": [],\n",
    "#                             \"temperature\": 0}}\n",
    "\n",
    "#         frames = videoreader.process_video(data_prepath,human_anno[i]['videos'],2)\n",
    "\n",
    "#         prompten = human_anno[i]['prompt_en']\n",
    "#         # question = human_anno[i]['question_en']\n",
    "#         # subject = human_anno[i]['subject_en']\n",
    "#         # scene = human_anno[i]['scene_en']\n",
    "#         # objet = human_anno[i]['object']\n",
    "#         messages=[\n",
    "#         {\n",
    "#         \"role\": \"system\", \"content\":\n",
    "#             prompt_template\n",
    "#             }\n",
    "#             ,\n",
    "#         {\n",
    "#             \"role\": \"user\", \"content\": [\n",
    "#                 \"These are the frames from the video.The prompt is '{}'.\".format(prompten),\n",
    "#                 \"12 frames from cogvideox5b \\n \", \n",
    "#                 *map(lambda x: {\"type\": \"image_url\", \n",
    "#                                 \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['cogvideox5b']),\n",
    "#                 \"10 frames from kling \\n \", \n",
    "#                 *map(lambda x: {\"type\": \"image_url\", \n",
    "#                                 \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['kling']),\n",
    "#                 \"10 frames from gen3 \\n \", \n",
    "#                 *map(lambda x: {\"type\": \"image_url\", \n",
    "#                                 \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['gen3']),\n",
    "#                 \" 4 frames from videocrafter2 \\n \",\n",
    "#                 *map(lambda x: {\"type\": \"image_url\", \n",
    "#                                 \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['videocrafter2']),   \n",
    "#                 \"\\n 7 frames from pika \\n\",\n",
    "#                 *map(lambda x: {\"type\": \"image_url\", \n",
    "#                                 \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['pika']),\n",
    "#                 \"\\n 8 frames from show1\\n \",\n",
    "#                 *map(lambda x: {\"type\": \"image_url\", \n",
    "#                                 \"image_url\": {\"url\":    f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['show1']),                             \n",
    "#                 \"\\n5 frames from lavie\\n \",\n",
    "#                 *map(lambda x: {\"type\": \"image_url\", \n",
    "#                                 \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}},frames['lavie']),\n",
    "#                                                           ], \n",
    "#             }\n",
    "#         ]\n",
    "\n",
    "#         request['body']['messages'] = messages\n",
    "\n",
    "#         requests.append(request)\n",
    "\n",
    "#     with open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"w\") as f:\n",
    "#         for entry in requests:\n",
    "#             json_line = json.dumps(entry)\n",
    "#             f.write(json_line + '\\n')\n",
    "    \n",
    "#     batch_input_file = client.files.create(\n",
    "#              file=open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"rb\"),\n",
    "#               purpose=\"batch\"\n",
    "#              )\n",
    "\n",
    "#     batch_input_file_id = batch_input_file.id    \n",
    "\n",
    "#     batch_object = client.batches.create(\n",
    "#             input_file_id=batch_input_file_id,\n",
    "#             endpoint=\"/v1/chat/completions\",\n",
    "#             completion_window=\"24h\",\n",
    "#             metadata={\n",
    "#             \"description\": \"nightly group1 {} eval job batch {}\".format(dimension,batch_id)\n",
    "#             }\n",
    "#                                         )\n",
    "\n",
    "#     batch_unique_ids.append(batch_object.id)\n",
    "#     batch_split_ids.append(batch_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #gridview\n",
    "# def eval_batch_onebyone(index_list,batch_id):\n",
    "#     print(\"Thread {} is running\".format(batch_id))\n",
    "#     model2message = {\n",
    "#     'cogvideox5b':\"12 frames from cogvideox5b,which you need to evaluate \\n\",\n",
    "#     'kling':\"10 frames from kling ,which you need to evaluate\\n \", \n",
    "#     'gen3': \"10 frames from gen3 ,which you need to evaluate\\n\",\n",
    "#     'videocrafter2':\"4 frames from videocrafter2,which you need to evaluate\",\n",
    "#     'pika':\"7 frames from pika ,which you need to evaluate\",\n",
    "#     'show1':\"8 frames from show1,which you need to evaluate \",\n",
    "#     'lavie':\"5 frames from lavie ,which you need to evaluate\",\n",
    "#     }\n",
    "#     requests = []\n",
    "#     for i in index_list:     \n",
    "#         frames = videoreader.process_video(data_prepath,human_anno[i]['videos'],2)\n",
    "#         for key, value in model2message.items():\n",
    "#             modelname = key\n",
    "#             modelmessage = value\n",
    "#             for frameid in range(len(frames[modelname])):\n",
    "#                 request ={\"custom_id\": \"request-{}-{}-{}frames\".format(i,modelname,frameid), \n",
    "#                         \"method\": \"POST\", \n",
    "#                         \"url\": \"/v1/chat/completions\",\n",
    "#                         \"body\": {\"model\": MODEL,\n",
    "#                                     \"messages\": [],\n",
    "#                                     \"temperature\": 0}}\n",
    "\n",
    "#                 examplemodels = [x for x in model2message.keys() if x != modelname]\n",
    "\n",
    "\n",
    "#                 prompten = human_anno[i]['prompt_en']\n",
    "#                 # question = human_anno[i]['question_en']\n",
    "#                 # subject = human_anno[i]['subject_en']\n",
    "#                 # scene = human_anno[i]['scene_en']\n",
    "#                 # objet = human_anno[i]['object']\n",
    "#                 messages=[\n",
    "#                 {\n",
    "#                 \"role\": \"system\", \"content\":\n",
    "#                     prompt_template\n",
    "#                     }\n",
    "#                     ,\n",
    "#                 {\n",
    "#                     \"role\": \"user\", \"content\":[\n",
    "\n",
    "#                 \"The following image is concatenated by the key frames of the video and arrange 8 key frames 1 second video clip in a 1*8 grid view.\\n\" ,\n",
    "#                 *map(lambda x: {\"type\": \"image_url\", \n",
    "#                     \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}},[frames[modelname][frameid]]),    \n",
    "#                  \"The video clip most likely have some unnatural motion.Find unnatural motion and evaluate the motion effects of the video.\\n\",                       \n",
    "#                  \"Assuming there are a video scoring 'x',provide your analysis and explanation in the output format as follows:\\n\"\n",
    "#                  \"- video clip: x ,because ...\"\n",
    "#                 ],\n",
    "#                     }\n",
    "#                 ]\n",
    "#                 request['body']['messages'] = messages\n",
    "#                 requests.append(request)\n",
    "\n",
    "#     with open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"w\") as f:\n",
    "#         for entry in requests:\n",
    "#             json_line = json.dumps(entry)\n",
    "#             f.write(json_line + '\\n')\n",
    "    \n",
    "#     batch_input_file = client.files.create(\n",
    "#              file=open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"rb\"),\n",
    "#               purpose=\"batch\"\n",
    "#              )\n",
    "\n",
    "#     batch_input_file_id = batch_input_file.id    \n",
    "\n",
    "#     batch_object = client.batches.create(\n",
    "#             input_file_id=batch_input_file_id,\n",
    "#             endpoint=\"/v1/chat/completions\",\n",
    "#             completion_window=\"24h\",\n",
    "#             metadata={\n",
    "#             \"description\": \"nightly group1 {} eval job batch {}\".format(dimension,batch_id)\n",
    "#             }\n",
    "#                                         )\n",
    "    \n",
    "#     batch_split_ids.append(batch_id)\n",
    "#     batch_unique_ids.append(batch_object.id)\n",
    "\n",
    "#     print(\"Thread {} is done\".format(batch_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_batch_onebyone(index_list,batch_id):\n",
    "    print(\"Thread {} is running\".format(batch_id))\n",
    "    model2message = {\n",
    "    'cogvideox5b':\"12 frames from cogvideox5b,which you need to evaluate \\n\",\n",
    "    'kling':\"10 frames from kling ,which you need to evaluate\\n \", \n",
    "    'gen3': \"10 frames from gen3 ,which you need to evaluate\\n\",\n",
    "    'videocrafter2':\"4 frames from videocrafter2,which you need to evaluate\",\n",
    "    'pika':\"7 frames from pika ,which you need to evaluate\",\n",
    "    'show1':\"8 frames from show1,which you need to evaluate \",\n",
    "    'lavie':\"5 frames from lavie ,which you need to evaluate\",\n",
    "    }\n",
    "    requests = []\n",
    "    for i in index_list:     \n",
    "        frames = videoreader.process_video(data_prepath,human_anno[i]['videos'],2)\n",
    "        for key, value in model2message.items():\n",
    "            modelname = key\n",
    "            modelmessage = value\n",
    "            request ={\"custom_id\": \"request-{}-{}\".format(i,modelname), \n",
    "                    \"method\": \"POST\", \n",
    "                    \"url\": \"/v1/chat/completions\",\n",
    "                    \"body\": {\"model\": MODEL,\n",
    "                                \"messages\": [],\n",
    "                                \"temperature\": 0}}\n",
    "\n",
    "            prompten = human_anno[i]['prompt_en']\n",
    "            # question = human_anno[i]['question_en']\n",
    "            # subject = human_anno[i]['subject_en']\n",
    "            # scene = human_anno[i]['scene_en']\n",
    "            # objet = human_anno[i]['object']\n",
    "            messages=[\n",
    "            {\n",
    "            \"role\": \"system\", \"content\":\n",
    "                prompt_template\n",
    "                }\n",
    "                ,\n",
    "            {\n",
    "                \"role\": \"user\", \"content\":[\n",
    "\n",
    "            \"These are the frames from the video you need to evaluate.The prompt is '{}'.\".format(prompten),\n",
    "            modelmessage,\n",
    "            *map(lambda x: {\"type\": \"image_url\", \n",
    "                \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}},frames[modelname]),    \n",
    "                \"Assuming there are a video scoring 'x',provide your analysis and explanation in the output format as follows:\\n\"\n",
    "                \"- video: x ,because ...\"\n",
    "            ],\n",
    "                }\n",
    "            ]\n",
    "            request['body']['messages'] = messages\n",
    "            requests.append(request)\n",
    "\n",
    "    with open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"w\") as f:\n",
    "        for entry in requests:\n",
    "            json_line = json.dumps(entry)\n",
    "            f.write(json_line + '\\n')\n",
    "    \n",
    "    batch_input_file = client.files.create(\n",
    "             file=open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"rb\"),\n",
    "              purpose=\"batch\"\n",
    "             )\n",
    "\n",
    "    batch_input_file_id = batch_input_file.id    \n",
    "\n",
    "    batch_object = client.batches.create(\n",
    "            input_file_id=batch_input_file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "            metadata={\n",
    "            \"description\": \"nightly group1 {} eval job batch {}\".format(dimension,batch_id)\n",
    "            }\n",
    "                                        )\n",
    "    \n",
    "    batch_split_ids.append(batch_id)\n",
    "    batch_unique_ids.append(batch_object.id)\n",
    "\n",
    "    print(\"Thread {} is done\".format(batch_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 = list(range(1,len(human_anno),3))\n",
    "# l2 = list(range(2,len(human_anno),3))\n",
    "# l3 = list(range(0,len(human_anno),3))\n",
    "l = list(range(0,len(human_anno)))\n",
    "\n",
    "\n",
    "ls = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 0 is runningThread 1 is running\n",
      "\n",
      "Thread 2 is running\n",
      "Thread 3 is running\n",
      "Thread 4 is running\n",
      "Thread 5 is running\n",
      "Thread 6 is running\n",
      "Thread 7 is running\n",
      "Thread 8 is running\n",
      "Thread 9 is running\n",
      "Thread 10 is running\n",
      "Thread 11 is running\n",
      "Thread 12 is running\n",
      "Thread 13 is running\n",
      "Thread 14 is running\n",
      "Thread 15 is running\n",
      "Thread 16 is running\n",
      "Thread 17 is running\n",
      "Thread 18 is running\n",
      "Thread 19 is running\n",
      "Thread 20 is running\n",
      "Thread 21 is running\n",
      "Thread 22 is running\n",
      "Thread 23 is running\n",
      "Thread 24 is running\n",
      "All threads started\n",
      "Thread 0 is done\n",
      "Thread 10 is done\n",
      "Thread 6 is done\n",
      "Thread 1 is done\n",
      "Thread 24 is done\n",
      "Thread 14 is done\n",
      "Thread 7 is done\n",
      "Thread 2 is done\n",
      "Thread 18 is done\n",
      "Thread 20 is done\n",
      "Thread 22 is done\n",
      "Thread 3 is done\n",
      "Thread 19 is done\n",
      "Thread 9 is done\n",
      "Thread 12 is done\n",
      "Thread 16 is done\n",
      "Thread 11 is done\n",
      "Thread 8 is done\n",
      "Thread 5 is done\n",
      "Thread 21 is done\n",
      "Thread 15 is done\n",
      "Thread 13 is done\n",
      "Thread 4 is done\n",
      "Thread 17 is done\n",
      "Thread 23 is done\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "batch_size = 11\n",
    "batches = [ls[i:i + batch_size] for i in range(0, len(ls), batch_size)]\n",
    "\n",
    "threads = []\n",
    "for i, batch in enumerate(batches):\n",
    "    if i in batch_split_ids:\n",
    "        continue\n",
    "    thread = threading.Thread(target=eval_batch_onebyone, args=(batch, i))\n",
    "    threads.append(thread)      \n",
    "    thread.start()\n",
    "\n",
    "print(\"All threads started\")\n",
    "# 等待所有线程完成\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "#保存batch信息\n",
    "with open(\"./batch_infos/batch_info_{}_onebyone.json\".format(dimension), \"w\") as f:\n",
    "    json.dump({\"batch_unique_ids\": batch_unique_ids, \"batch_split_ids\": batch_split_ids,\"videos_in_batch\":batches}, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id:batch_6733144d35d88190befb955dbea1a154 status:completed descrepition:nightly group1 overall_consistency eval job batch 0\n",
      "batch batch_6733144d35d88190befb955dbea1a154 done,end index 10\n",
      "id:batch_673314518c848190b4376eb7b53b84a2 status:in_progress descrepition:nightly group1 overall_consistency eval job batch 10\n",
      "batch batch_673314518c848190b4376eb7b53b84a2 is not completed\n",
      "id:batch_67331453cdf88190ba211f0791e6c7b5 status:finalizing descrepition:nightly group1 overall_consistency eval job batch 6\n",
      "batch batch_67331453cdf88190ba211f0791e6c7b5 is not completed\n",
      "id:batch_6733145719fc8190bf3d6c4c0f62513e status:completed descrepition:nightly group1 overall_consistency eval job batch 1\n",
      "batch batch_6733145719fc8190bf3d6c4c0f62513e done,end index 21\n",
      "id:batch_673314590ff081908eba9a6aeb0bfebb status:completed descrepition:nightly group1 overall_consistency eval job batch 24\n",
      "batch batch_673314590ff081908eba9a6aeb0bfebb done,end index 272\n",
      "id:batch_67331475a48c81908eb6b4ba22637da8 status:in_progress descrepition:nightly group1 overall_consistency eval job batch 14\n",
      "batch batch_67331475a48c81908eb6b4ba22637da8 is not completed\n",
      "id:batch_673314783574819091acab4a5f4c22aa status:in_progress descrepition:nightly group1 overall_consistency eval job batch 7\n",
      "batch batch_673314783574819091acab4a5f4c22aa is not completed\n",
      "id:batch_6733147a79c08190ab39317d79117b50 status:in_progress descrepition:nightly group1 overall_consistency eval job batch 2\n",
      "batch batch_6733147a79c08190ab39317d79117b50 is not completed\n",
      "id:batch_6733147c81fc8190b769f29600adac06 status:in_progress descrepition:nightly group1 overall_consistency eval job batch 18\n",
      "batch batch_6733147c81fc8190b769f29600adac06 is not completed\n",
      "id:batch_673314873d008190a4108f1957bd326b status:in_progress descrepition:nightly group1 overall_consistency eval job batch 20\n",
      "batch batch_673314873d008190a4108f1957bd326b is not completed\n",
      "id:batch_67331493409881908fd14909651323b6 status:in_progress descrepition:nightly group1 overall_consistency eval job batch 22\n",
      "batch batch_67331493409881908fd14909651323b6 is not completed\n",
      "id:batch_67331493fa288190bc761ce59ef5a7ef status:in_progress descrepition:nightly group1 overall_consistency eval job batch 3\n",
      "batch batch_67331493fa288190bc761ce59ef5a7ef is not completed\n",
      "id:batch_6733149629a0819094c6cc5136d260ec status:in_progress descrepition:nightly group1 overall_consistency eval job batch 19\n",
      "batch batch_6733149629a0819094c6cc5136d260ec is not completed\n",
      "id:batch_67331499349c819080acc838a4cd8a72 status:validating descrepition:nightly group1 overall_consistency eval job batch 9\n",
      "batch batch_67331499349c819080acc838a4cd8a72 is not completed\n",
      "id:batch_6733149f7ef88190839c028bb1faf493 status:in_progress descrepition:nightly group1 overall_consistency eval job batch 12\n",
      "batch batch_6733149f7ef88190839c028bb1faf493 is not completed\n",
      "id:batch_673314a2522481909564b2c3d593842c status:validating descrepition:nightly group1 overall_consistency eval job batch 16\n",
      "batch batch_673314a2522481909564b2c3d593842c is not completed\n",
      "id:batch_673314a39f4c8190a369cc40a0112179 status:validating descrepition:nightly group1 overall_consistency eval job batch 11\n",
      "batch batch_673314a39f4c8190a369cc40a0112179 is not completed\n",
      "id:batch_673314a644148190a1839e26b9c23b28 status:validating descrepition:nightly group1 overall_consistency eval job batch 8\n",
      "batch batch_673314a644148190a1839e26b9c23b28 is not completed\n",
      "id:batch_673314ac77488190a3e35a65f6ea6353 status:in_progress descrepition:nightly group1 overall_consistency eval job batch 5\n",
      "batch batch_673314ac77488190a3e35a65f6ea6353 is not completed\n",
      "id:batch_673314ad6ca481909b0a21f179c58f75 status:in_progress descrepition:nightly group1 overall_consistency eval job batch 21\n",
      "batch batch_673314ad6ca481909b0a21f179c58f75 is not completed\n",
      "id:batch_673314b430c88190a98a38b3916efee9 status:in_progress descrepition:nightly group1 overall_consistency eval job batch 15\n",
      "batch batch_673314b430c88190a98a38b3916efee9 is not completed\n",
      "id:batch_673314b42c84819084736ca0bad8292c status:in_progress descrepition:nightly group1 overall_consistency eval job batch 13\n",
      "batch batch_673314b42c84819084736ca0bad8292c is not completed\n",
      "id:batch_673314b4c660819085941788c3b7e707 status:in_progress descrepition:nightly group1 overall_consistency eval job batch 4\n",
      "batch batch_673314b4c660819085941788c3b7e707 is not completed\n",
      "id:batch_673314b8ea0c81909f087f367bb3b884 status:in_progress descrepition:nightly group1 overall_consistency eval job batch 17\n",
      "batch batch_673314b8ea0c81909f087f367bb3b884 is not completed\n",
      "id:batch_673314b96240819090b904bd77545212 status:in_progress descrepition:nightly group1 overall_consistency eval job batch 23\n",
      "batch batch_673314b96240819090b904bd77545212 is not completed\n"
     ]
    }
   ],
   "source": [
    "with open(\"./batch_infos/batch_info_{}_onebyone.json\".format(dimension), \"r\") as f:\n",
    "    batch_info = json.load(f)\n",
    "\n",
    "    \n",
    "batchids = batch_info[\"batch_unique_ids\"]\n",
    "llmeval_path = \"./GPT4o_eval_results/{}/{}_llmeval_onebyone.json\".format(dimension,dimension)\n",
    "\n",
    "with open(llmeval_path, \"r\") as f:\n",
    "    llmeval = json.load(f)\n",
    "    \n",
    "for i in ls:\n",
    "    if str(i) not in llmeval.keys():\n",
    "         llmeval[str(i)] = {}\n",
    "\n",
    "for id in batchids:\n",
    "    batch_object = client.batches.retrieve(id)\n",
    "    print(\"id:{} status:{} descrepition:{}\".format(id,batch_object.status,batch_object.metadata['description']))\n",
    "\n",
    "    if batch_object.status != \"completed\":\n",
    "        print(\"batch {} is not completed\".format(id))\n",
    "        continue    \n",
    "\n",
    "    file_response = client.files.content(batch_object.output_file_id)\n",
    "    for line in file_response.text.splitlines():\n",
    "\n",
    "        \n",
    "        # index = json.loads(line)[\"custom_id\"].split(\"-\")[-3]\n",
    "        # model = json.loads(line)[\"custom_id\"].split(\"-\")[-2]\n",
    "        # frameid = json.loads(line)[\"custom_id\"].split(\"-\")[-1]\n",
    "\n",
    "        index = json.loads(line)[\"custom_id\"].split(\"-\")[-2]\n",
    "        model = json.loads(line)[\"custom_id\"].split(\"-\")[-1]\n",
    "\n",
    "        # index = json.loads(line)[\"custom_id\"].split(\"-\")[-1]\n",
    "\n",
    "        eval_res = json.loads(line)[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"].replace('\\n\\n','\\n')\n",
    "        \n",
    "        # if model not in llmeval[index].keys():\n",
    "        #     llmeval[index][model] = {}\n",
    "        # llmeval[index][model][frameid] = eval_res\n",
    "        \n",
    "        llmeval[index][model] = eval_res\n",
    "        # llmeval[index] = eval_res\n",
    "    with open(llmeval_path, \"w\") as f:\n",
    "        json.dump(llmeval, f, indent=4)\n",
    "\n",
    "    print(\"batch {} done,end index {}\".format(id,index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
