{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from tool import videoreader\n",
    "# 创建一个OpenAI客户端实例\n",
    "client = OpenAI(\n",
    "    api_key=\"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\",\n",
    "    base_url=\"https://gateway.ai.cloudflare.com/v1/627f1b1f372e3a198dc32573bbc6f720/openai-gpt/openai\"  # 替换为你的自定义API域\n",
    ")\n",
    "\n",
    "## Set the API key and model name\n",
    "MODEL=\"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 'motion_effects'\n",
    "from PromptTemplate4GPTeval import Prompt4Motioneffects\n",
    "prompt_template = Prompt4Motioneffects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data_prepath = '../data4dimensions/'\n",
    "# data_prepath = \"../../data4dimensions/\"\n",
    "with open(\"./Human_anno/{}.json\".format(dimension)) as f:\n",
    "    human_anno = json.load(f)\n",
    "\n",
    "batch_stpath = '../batch_api/{}'.format(dimension)\n",
    "if not os.path.exists(batch_stpath):\n",
    "    os.makedirs(batch_stpath)\n",
    "\n",
    "batch_unique_ids = []\n",
    "batch_split_ids = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_batch(index_list,batch_id):\n",
    "#     requests = []\n",
    "#     for i in index_list:     \n",
    "#         request ={\"custom_id\": \"request-{}\".format(i), \n",
    "#                 \"method\": \"POST\", \n",
    "#                 \"url\": \"/v1/chat/completions\",\n",
    "#                 \"body\": {\"model\": MODEL,\n",
    "#                             \"messages\": [],\n",
    "#                             \"temperature\": 0}}\n",
    "\n",
    "#         frames = videoreader.process_video(data_prepath,human_anno[i]['videos'],2 ,resize_fx=1,resize_fy=1)\n",
    "\n",
    "#         prompten = human_anno[i]['prompt_en']\n",
    "#         # question = human_anno[i]['question_en']\n",
    "#         # subject = human_anno[i]['subject_en']\n",
    "#         # scene = human_anno[i]['scene_en']\n",
    "#         # objet = human_anno[i]['object']\n",
    "#         messages=[\n",
    "#         {\n",
    "#         \"role\": \"system\", \"content\":\n",
    "#             prompt_template\n",
    "#             }\n",
    "#             ,\n",
    "#         {\n",
    "#             \"role\": \"user\", \"content\": [\n",
    "#             \"These are the frames from the videos.\",\n",
    "#             \"12 frames from cogvideox5b \\n \", \n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['cogvideox5b']),\n",
    "#             \"10 frames from kling \\n \", \n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['kling']),\n",
    "#             \"10 frames from gen3 \\n \", \n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['gen3']),\n",
    "#             \" 4 frames from videocrafter2 \\n \",\n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['videocrafter2']),   \n",
    "#             \"\\n 7 frames from pika \\n\",\n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['pika']),\n",
    "#             \"\\n 8 frames from show1\\n \",\n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\":    f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['show1']),                             \n",
    "#             \"\\n5 frames from lavie\\n \",\n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}},frames['lavie']),\n",
    "#                                                         ],\n",
    "#             }\n",
    "#         ]\n",
    "\n",
    "#         request['body']['messages'] = messages\n",
    "\n",
    "#         requests.append(request)\n",
    "\n",
    "#     with open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"w\") as f:\n",
    "#         for entry in requests:\n",
    "#             json_line = json.dumps(entry)\n",
    "#             f.write(json_line + '\\n')\n",
    "    \n",
    "#     batch_input_file = client.files.create(\n",
    "#              file=open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"rb\"),\n",
    "#               purpose=\"batch\"\n",
    "#              )\n",
    "\n",
    "#     batch_input_file_id = batch_input_file.id    \n",
    "\n",
    "#     batch_object = client.batches.create(\n",
    "#             input_file_id=batch_input_file_id,\n",
    "#             endpoint=\"/v1/chat/completions\",\n",
    "#             completion_window=\"24h\",\n",
    "#             metadata={\n",
    "#             \"description\": \"nightly group1 {} eval job batch {}\".format(dimension,batch_id)\n",
    "#             }\n",
    "#                                         )\n",
    "\n",
    "#     batch_unique_ids.append(batch_object.id)\n",
    "#     batch_split_ids.append(batch_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_batch_onebyone(index_list,batch_id):\n",
    "    print(\"Thread {} is running\".format(batch_id))\n",
    "    model2message = {\n",
    "    'cogvideox5b':\"12 frames from cogvideox5b\\n\",\n",
    "    'kling':\"10 frames from kling \\n \", \n",
    "    'gen3': \"10 frames from gen3 \\n\",\n",
    "    'videocrafter2':\"4 frames from videocrafter2\",\n",
    "    'pika':\"7 frames from pika \",\n",
    "    'show1':\"8 frames from show1 \",\n",
    "    'lavie':\"5 frames from lavie \",\n",
    "    }\n",
    "    requests = []\n",
    "    for key, value in model2message.items():\n",
    "        modelname = key\n",
    "        modelmessage = value\n",
    "   \n",
    "        for i in index_list:     \n",
    "            request ={\"custom_id\": \"request-{}-{}\".format(i,modelname), \n",
    "                    \"method\": \"POST\", \n",
    "                    \"url\": \"/v1/chat/completions\",\n",
    "                    \"body\": {\"model\": MODEL,\n",
    "                                \"messages\": [],\n",
    "                                \"temperature\": 0}}\n",
    "\n",
    "            frames = videoreader.process_video2gridview(data_prepath,human_anno[i]['videos'],4)\n",
    "            \n",
    "            prompten = human_anno[i]['prompt_en']\n",
    "            # question = human_anno[i]['question_en']\n",
    "            # subject = human_anno[i]['subject_en']\n",
    "            # scene = human_anno[i]['scene_en']\n",
    "            # objet = human_anno[i]['object']\n",
    "            messages=[\n",
    "            {\n",
    "            \"role\": \"system\", \"content\":\n",
    "                prompt_template\n",
    "                }\n",
    "                ,\n",
    "            {\n",
    "                \"role\": \"user\", \"content\": [\n",
    "                \" The following images arrange 4 key frames per second video clip from a video in a 1*4 grid view.\" ,\n",
    "                *map(lambda x: {\"type\": \"image_url\", \n",
    "                                \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}},frames[modelname]),                                                         \n",
    "                \"Assuming there are a video scoring 'x',provide your analysis and explanation in the output format as follows:\\n\"\n",
    "                \"- Video: x ,because ...\"\n",
    "              ],\n",
    "                }\n",
    "            ]\n",
    "            request['body']['messages'] = messages\n",
    "            requests.append(request)\n",
    "\n",
    "    with open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"w\") as f:\n",
    "        for entry in requests:\n",
    "            json_line = json.dumps(entry)\n",
    "            f.write(json_line + '\\n')\n",
    "    \n",
    "    batch_input_file = client.files.create(\n",
    "             file=open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"rb\"),\n",
    "              purpose=\"batch\"\n",
    "             )\n",
    "\n",
    "    batch_input_file_id = batch_input_file.id    \n",
    "\n",
    "    batch_object = client.batches.create(\n",
    "            input_file_id=batch_input_file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "            metadata={\n",
    "            \"description\": \"nightly group1 {} eval job batch {}\".format(dimension,batch_id)\n",
    "            }\n",
    "                                        )\n",
    "    \n",
    "    batch_split_ids.append(batch_id)\n",
    "    batch_unique_ids.append(batch_object.id)\n",
    "\n",
    "    print(\"Thread {} is done\".format(batch_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 = list(range(1,len(human_anno),3))\n",
    "# l2 = list(range(2,len(human_anno),3))\n",
    "l3 = list(range(0,len(human_anno),1))\n",
    "ls = l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 0 is running\n",
      "Thread 1 is running\n",
      "Thread 2 is running\n",
      "Thread 3 is running\n",
      "Thread 4 is running\n",
      "Thread 5 is running\n",
      "Thread 6 is running\n",
      "Thread 7 is running\n",
      "Thread 8 is running\n",
      "Thread 9 is running\n",
      "Thread 10 is running\n",
      "Thread 11 is running\n",
      "Thread 12 is running\n",
      "Thread 13 is running\n",
      "Thread 14 is running\n",
      "Thread 15 is running\n",
      "Thread 16 is running\n",
      "Thread 17 is running\n",
      "Thread 18 is running\n",
      "Thread 19 is running\n",
      "Thread 20 is running\n",
      "Thread 21 is running\n",
      "Thread 22 is running\n",
      "Thread 23 is running\n",
      "Thread 24 is running\n",
      "Thread 25 is running\n",
      "Thread 26 is running\n",
      "Thread 27 is running\n",
      "Thread 28 is running\n",
      "Thread 29 is running\n",
      "Thread 30 is running\n",
      "Thread 31 is running\n",
      "Thread 32 is running\n",
      "Thread 33 is running\n",
      "Thread 34 is running\n",
      "Thread 35 is running\n",
      "Thread 36 is running\n",
      "Thread 37 is running\n",
      "Thread 38 is running\n",
      "Thread 39 is running\n",
      "Thread 40 is running\n",
      "Thread 41 is running\n",
      "Thread 42 is running\n",
      "Thread 43 is running\n",
      "Thread 44 is running\n",
      "Thread 45 is running\n",
      "Thread 46 is running\n",
      "Thread 47 is running\n",
      "Thread 48 is running\n",
      "Thread 49 is running\n",
      "Thread 50 is running\n",
      "Thread 51 is running\n",
      "Thread 52 is running\n",
      "Thread 53 is running\n",
      "Thread 54 is running\n",
      "Thread 55 is running\n",
      "Thread 56 is running\n",
      "Thread 57 is running\n",
      "Thread 58 is running\n",
      "All threads started\n",
      "Thread 58 is done\n",
      "Thread 56 is done\n",
      "Thread 11 is done\n",
      "Thread 37 is done\n",
      "Thread 0 is done\n",
      "Thread 19 is done\n",
      "Thread 12 is done\n",
      "Thread 10 is done\n",
      "Thread 3 is done\n",
      "Thread 9 is done\n",
      "Thread 7 is done\n",
      "Thread 23 is done\n",
      "Thread 1 is done\n",
      "Thread 54 is done\n",
      "Thread 57 is done\n",
      "Thread 20 is done\n",
      "Thread 30 is done\n",
      "Thread 55 is done\n",
      "Thread 24 is done\n",
      "Thread 15 is done\n",
      "Thread 21 is done\n",
      "Thread 44 is done\n",
      "Thread 31 is done\n",
      "Thread 5 is done\n",
      "Thread 14 is done\n",
      "Thread 8 is done\n",
      "Thread 48 is done\n",
      "Thread 29 is done\n",
      "Thread 49 is done\n",
      "Thread 13 is done\n",
      "Thread 2 is done\n",
      "Thread 33 is done\n",
      "Thread 36 is done\n",
      "Thread 16 is done\n",
      "Thread 34 is done\n",
      "Thread 25 is done\n",
      "Thread 46 is done\n",
      "Thread 50 is done\n",
      "Thread 43 is done\n",
      "Thread 47 is done\n",
      "Thread 27 is done\n",
      "Thread 22 is done\n",
      "Thread 28 is done\n",
      "Thread 40 is done\n",
      "Thread 51 is done\n",
      "Thread 41 is done\n",
      "Thread 38 is done\n",
      "Thread 45 is done\n",
      "Thread 18 is done\n",
      "Thread 42 is done\n",
      "Thread 35 is done\n",
      "Thread 4 is done\n",
      "Thread 39 is done\n",
      "Thread 52 is done\n",
      "Thread 32 is done\n",
      "Thread 53 is done\n",
      "Thread 17 is done\n",
      "Thread 6 is done\n",
      "Thread 26 is done\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "batch_size = 4\n",
    "batches = [ls[i:i + batch_size] for i in range(0, len(ls), batch_size)]\n",
    "\n",
    "# with open(\"./batch_infos/batch_info_{}.json\".format(dimension), \"r\") as f:\n",
    "#     batch_info = json.load(f)\n",
    "\n",
    "# batch_split_ids = batch_info['batch_split_ids']\n",
    "# batches = batch_info['videos_in_batch']\n",
    "\n",
    "threads = []\n",
    "for i, batch in enumerate(batches):\n",
    "    thread = threading.Thread(target=eval_batch_onebyone, args=(batch, i))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "print(\"All threads started\")\n",
    "# 等待所有线程完成\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "#保存batch信息\n",
    "with open(\"./batch_infos/batch_info_{}.json\".format(dimension), \"w\") as f:\n",
    "    json.dump({\"batch_unique_ids\": batch_unique_ids, \"batch_split_ids\": batch_split_ids,\"videos_in_batch\":batches}, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./batch_infos/batch_info_{}.json\".format(dimension), \"r\") as f:\n",
    "    batch_info = json.load(f)\n",
    "\n",
    "    \n",
    "batchids = batch_info[\"batch_unique_ids\"]\n",
    "llmeval_path = \"./GPT4o_eval_results/{}/{}_llmeval_gridview.json\".format(dimension,dimension)\n",
    "\n",
    "with open(llmeval_path, \"r\") as f:\n",
    "    llmeval = json.load(f)\n",
    "# for i in ls:\n",
    "#     llmeval[str(i)] = {}\n",
    "\n",
    "# for id in batchids:\n",
    "#     batch_object = client.batches.retrieve(id)\n",
    "#     print(\"id:{} status:{} descrepition:{}\".format(id,batch_object.status,batch_object.metadata['description']))\n",
    "\n",
    "#     if batch_object.status != \"completed\":\n",
    "#         print(\"batch {} is not completed\".format(id))\n",
    "#         continue    \n",
    "\n",
    "#     file_response = client.files.content(batch_object.output_file_id)\n",
    "#     for line in file_response.text.splitlines():\n",
    "#         index = json.loads(line)[\"custom_id\"].split(\"-\")[-2]\n",
    "#         model = json.loads(line)[\"custom_id\"].split(\"-\")[-1]\n",
    "#         eval_res = json.loads(line)[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"].replace('\\n\\n','\\n')\n",
    "#         llmeval[index][model] = eval_res\n",
    "#     with open(llmeval_path, \"w\") as f:\n",
    "#         json.dump(llmeval, f, indent=4)\n",
    "\n",
    "#     print(\"batch {} done,end index {}\".format(id,index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
