{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from tool import videoreader\n",
    "# 创建一个OpenAI客户端实例\n",
    "client = OpenAI(\n",
    "    api_key=\"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\",\n",
    "    base_url=\"https://gateway.ai.cloudflare.com/v1/627f1b1f372e3a198dc32573bbc6f720/openai-gpt/openai\"  # 替换为你的自定义API域\n",
    ")\n",
    "\n",
    "## Set the API key and model name\n",
    "MODEL=\"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 'temporal_consistency'\n",
    "from PromptTemplate4GPTeval import Prompt4TemperalConsistency\n",
    "prompt_template = Prompt4TemperalConsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# data_prepath = r'D:\\Astudying\\VideoEval\\data4dimensions'\n",
    "data_prepath = \"../../data4dimensions/\"\n",
    "with open(\"./Human_anno/{}.json\".format(dimension)) as f:\n",
    "    human_anno = json.load(f)\n",
    "\n",
    "batch_stpath = '../batch_api/{}'.format(dimension)\n",
    "batch_unique_ids = []\n",
    "batch_split_ids = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fewshot_path = \"./fewshot_examples/{}/\".format(dimension)\n",
    "# examples = {}\n",
    "\n",
    "# for file in os.listdir(fewshot_path):\n",
    "#     if file.endswith('.txt'):\n",
    "#         with open(fewshot_path+file, \"r\") as f:\n",
    "#             examples[file.split('.')[0]] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_batch(index_list,batch_id):\n",
    "#     requests = []\n",
    "#     for i in index_list:     \n",
    "#         request ={\"custom_id\": \"request-{}\".format(i), \n",
    "#                 \"method\": \"POST\", \n",
    "#                 \"url\": \"/v1/chat/completions\",\n",
    "#                 \"body\": {\"model\": MODEL,\n",
    "#                             \"messages\": [],\n",
    "#                             \"temperature\": 0}}\n",
    "\n",
    "#         frames = videoreader.process_video(data_prepath,human_anno[i]['videos'],2 ,resize_fx=1,resize_fy=1)\n",
    "\n",
    "#         prompten = human_anno[i]['prompt_en']\n",
    "#         # question = human_anno[i]['question_en']\n",
    "#         # subject = human_anno[i]['subject_en']\n",
    "#         # scene = human_anno[i]['scene_en']\n",
    "#         # objet = human_anno[i]['object']\n",
    "#         messages=[\n",
    "#         {\n",
    "#         \"role\": \"system\", \"content\":\n",
    "#             prompt_template\n",
    "#             }\n",
    "#             ,\n",
    "#         {\n",
    "#             \"role\": \"user\", \"content\": [\n",
    "#             \"These are the frames from the videos.\",\n",
    "#             \"12 frames from cogvideox5b \\n \", \n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['cogvideox5b']),\n",
    "#             \"10 frames from kling \\n \", \n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['kling']),\n",
    "#             \"10 frames from gen3 \\n \", \n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['gen3']),\n",
    "#             \" 4 frames from videocrafter2 \\n \",\n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['videocrafter2']),   \n",
    "#             \"\\n 7 frames from pika \\n\",\n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['pika']),\n",
    "#             \"\\n 8 frames from show1\\n \",\n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\":    f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['show1']),                             \n",
    "#             \"\\n5 frames from lavie\\n \",\n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}},frames['lavie']),\n",
    "#                                                         ],\n",
    "#             }\n",
    "#         ]\n",
    "\n",
    "#         request['body']['messages'] = messages\n",
    "\n",
    "#         requests.append(request)\n",
    "\n",
    "#     with open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"w\") as f:\n",
    "#         for entry in requests:\n",
    "#             json_line = json.dumps(entry)\n",
    "#             f.write(json_line + '\\n')\n",
    "    \n",
    "#     batch_input_file = client.files.create(\n",
    "#              file=open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"rb\"),\n",
    "#               purpose=\"batch\"\n",
    "#              )\n",
    "\n",
    "#     batch_input_file_id = batch_input_file.id    \n",
    "\n",
    "#     batch_object = client.batches.create(\n",
    "#             input_file_id=batch_input_file_id,\n",
    "#             endpoint=\"/v1/chat/completions\",\n",
    "#             completion_window=\"24h\",\n",
    "#             metadata={\n",
    "#             \"description\": \"nightly group1 {} eval job batch {}\".format(dimension,batch_id)\n",
    "#             }\n",
    "#                                         )\n",
    "\n",
    "#     batch_unique_ids.append(batch_object.id)\n",
    "#     batch_split_ids.append(batch_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_batch_onebyone(index_list,batch_id):\n",
    "    print(\"Thread {} is running\".format(batch_id))\n",
    "    # model2message = {\n",
    "    # 'cogvideox5b':\"12 frames from cogvideox5b\\n\",\n",
    "    # 'kling':\"10 frames from kling \\n \", \n",
    "    # 'gen3': \"10 frames from gen3 \\n\",\n",
    "    # 'videocrafter2':\"4 frames from videocrafter2\",\n",
    "    # 'pika':\"7 frames from pika \",\n",
    "    # 'show1':\"8 frames from show1 \",\n",
    "    # 'lavie':\"5 frames from lavie \",\n",
    "    # }\n",
    "    # requests = []\n",
    "    # for key, value in model2message.items():\n",
    "    #     modelname = key\n",
    "    #     modelmessage = value\n",
    "   \n",
    "    #     for i in index_list:     \n",
    "    #         request ={\"custom_id\": \"request-{}-{}\".format(i,modelname), \n",
    "    #                 \"method\": \"POST\", \n",
    "    #                 \"url\": \"/v1/chat/completions\",\n",
    "    #                 \"body\": {\"model\": MODEL,\n",
    "    #                             \"messages\": [],\n",
    "    #                             \"temperature\": 0}}\n",
    "\n",
    "    #         frames = videoreader.process_video2gridview(data_prepath,human_anno[i]['videos'],8)\n",
    "            \n",
    "    #         prompten = human_anno[i]['prompt_en']\n",
    "    #         # question = human_anno[i]['question_en']\n",
    "    #         # subject = human_anno[i]['subject_en']\n",
    "    #         # scene = human_anno[i]['scene_en']\n",
    "    #         # objet = human_anno[i]['object']\n",
    "    #         messages=[\n",
    "    #         {\n",
    "    #         \"role\": \"system\", \"content\":\n",
    "    #             prompt_template\n",
    "    #             }\n",
    "    #             ,\n",
    "    #         {\n",
    "    #             \"role\": \"user\", \"content\": [\n",
    "    #             \"The following images are concatenated by the key frames of the video.And one of the following images arranges 8 key frames per second from a video in a 1*8 grid view.\\n\" ,\n",
    "    #             *map(lambda x: {\"type\": \"image_url\", \n",
    "    #                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}},frames[modelname]),                                                         \n",
    "    #             \"The video may have some unnatural changes.Find unnatural changes and evaluate the temporal consistency of the video.\\n\",                       \n",
    "    #                                   ],\n",
    "    #             }\n",
    "    #         ]\n",
    "    #         request['body']['messages'] = messages\n",
    "    #         requests.append(request)\n",
    "\n",
    "    # with open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"w\") as f:\n",
    "    #     for entry in requests:\n",
    "    #         json_line = json.dumps(entry)\n",
    "    #         f.write(json_line + '\\n')\n",
    "    # batch_split_ids.append(batch_id)\n",
    "    \n",
    "    batch_input_file = client.files.create(\n",
    "             file=open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"rb\"),\n",
    "              purpose=\"batch\"\n",
    "             )\n",
    "\n",
    "    batch_input_file_id = batch_input_file.id    \n",
    "\n",
    "    batch_object = client.batches.create(\n",
    "            input_file_id=batch_input_file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "            metadata={\n",
    "            \"description\": \"nightly group1 {} eval job batch {}\".format(dimension,batch_id)\n",
    "            }\n",
    "                                        )\n",
    "\n",
    "    batch_unique_ids.append(batch_object.id)\n",
    "\n",
    "    print(\"Thread {} is done\".format(batch_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 = list(range(1,len(human_anno),3))\n",
    "# l2 = list(range(2,len(human_anno),3))\n",
    "l3 = list(range(0,len(human_anno),3))\n",
    "ls = l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 0 is running\n",
      "Thread 1 is running\n",
      "Thread 2 is running\n",
      "Thread 3 is running\n",
      "Thread 4 is running\n",
      "Thread 5 is running\n",
      "Thread 6 is running\n",
      "Thread 7 is running\n",
      "Thread 8 is running\n",
      "Thread 9 is running\n",
      "Thread 10 is running\n",
      "Thread 11 is running\n",
      "Thread 12 is running\n",
      "Thread 13 is running\n",
      "Thread 14 is running\n",
      "Thread 15 is running\n",
      "Thread 16 is running\n",
      "Thread 17 is running\n",
      "Thread 18 is running\n",
      "Thread 19 is running\n",
      "All threads started\n",
      "Thread 19 is done\n",
      "Thread 3 is done\n",
      "Thread 6 is done\n",
      "Thread 1 is done\n",
      "Thread 0 is done\n",
      "Thread 2 is done\n",
      "Thread 18 is done\n",
      "Thread 11 is done\n",
      "Thread 12 is done\n",
      "Thread 14 is done\n",
      "Thread 5 is done\n",
      "Thread 8 is done\n",
      "Thread 4 is done\n",
      "Thread 13 is done\n",
      "Thread 10 is done\n",
      "Thread 7 is done\n",
      "Thread 9 is done\n",
      "Thread 17 is done\n",
      "Thread 15 is done\n",
      "Thread 16 is done\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "# batch_size = 4\n",
    "# batches = [ls[i:i + batch_size] for i in range(0, len(ls), batch_size)]\n",
    "with open(\"./batch_infos/batch_info_{}.json\".format(dimension), \"r\") as f:\n",
    "    batch_info = json.load(f)\n",
    "\n",
    "batch_split_ids = batch_info['batch_split_ids']\n",
    "batches = batch_info['videos_in_batch']\n",
    "\n",
    "threads = []\n",
    "for i, batch in enumerate(batches):\n",
    "    thread = threading.Thread(target=eval_batch_onebyone, args=(batch, i))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "print(\"All threads started\")\n",
    "# 等待所有线程完成\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "#保存batch信息\n",
    "with open(\"./batch_infos/batch_info_{}.json\".format(dimension), \"w\") as f:\n",
    "    json.dump({\"batch_unique_ids\": batch_unique_ids, \"batch_split_ids\": batch_split_ids,\"videos_in_batch\":batches}, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id:batch_672b26c03f688190b3b9f1c0948d4726 status:completed descrepition:nightly group1 temporal_consistency eval job batch 19\n",
      "batch batch_672b26c03f688190b3b9f1c0948d4726 done,end index 231\n",
      "id:batch_672b2721b6fc819094a1e28457f30a3e status:completed descrepition:nightly group1 temporal_consistency eval job batch 3\n",
      "batch batch_672b2721b6fc819094a1e28457f30a3e done,end index 45\n",
      "id:batch_672b2729303081909c11a7ab56e9eab3 status:completed descrepition:nightly group1 temporal_consistency eval job batch 6\n",
      "batch batch_672b2729303081909c11a7ab56e9eab3 done,end index 81\n",
      "id:batch_672b272cbc1c81909274f4f5bbe3bc51 status:completed descrepition:nightly group1 temporal_consistency eval job batch 1\n",
      "batch batch_672b272cbc1c81909274f4f5bbe3bc51 done,end index 21\n",
      "id:batch_672b272ceb1c8190bb8a41121b1ce926 status:completed descrepition:nightly group1 temporal_consistency eval job batch 0\n",
      "batch batch_672b272ceb1c8190bb8a41121b1ce926 done,end index 9\n",
      "id:batch_672b27348e7c81909cf0569b1926167b status:completed descrepition:nightly group1 temporal_consistency eval job batch 2\n",
      "batch batch_672b27348e7c81909cf0569b1926167b done,end index 33\n",
      "id:batch_672b273b39d48190a2e55b39232b3408 status:completed descrepition:nightly group1 temporal_consistency eval job batch 18\n",
      "batch batch_672b273b39d48190a2e55b39232b3408 done,end index 225\n",
      "id:batch_672b273c87ac8190846f54317a2246b7 status:completed descrepition:nightly group1 temporal_consistency eval job batch 11\n",
      "batch batch_672b273c87ac8190846f54317a2246b7 done,end index 141\n",
      "id:batch_672b273d5f488190b8292f9c26ae575b status:completed descrepition:nightly group1 temporal_consistency eval job batch 12\n",
      "batch batch_672b273d5f488190b8292f9c26ae575b done,end index 153\n",
      "id:batch_672b2744b92c8190b0cdc965b2599f9e status:completed descrepition:nightly group1 temporal_consistency eval job batch 14\n",
      "batch batch_672b2744b92c8190b0cdc965b2599f9e done,end index 177\n",
      "id:batch_672b274b103c81908e0811b96600a784 status:completed descrepition:nightly group1 temporal_consistency eval job batch 5\n",
      "batch batch_672b274b103c81908e0811b96600a784 done,end index 69\n",
      "id:batch_672b274b573881908ec38fd0fafa283d status:completed descrepition:nightly group1 temporal_consistency eval job batch 8\n",
      "batch batch_672b274b573881908ec38fd0fafa283d done,end index 105\n",
      "id:batch_672b274c59c88190b1939eaf23097660 status:completed descrepition:nightly group1 temporal_consistency eval job batch 4\n",
      "batch batch_672b274c59c88190b1939eaf23097660 done,end index 57\n",
      "id:batch_672b274d86a8819089d4298c62bec2f9 status:failed descrepition:nightly group1 temporal_consistency eval job batch 13\n",
      "batch batch_672b274d86a8819089d4298c62bec2f9 is not completed\n",
      "id:batch_672b274f96bc8190a455c5314a7bd356 status:completed descrepition:nightly group1 temporal_consistency eval job batch 10\n",
      "batch batch_672b274f96bc8190a455c5314a7bd356 done,end index 129\n",
      "id:batch_672b275586b08190a5be1fb108f1b10a status:completed descrepition:nightly group1 temporal_consistency eval job batch 7\n",
      "batch batch_672b275586b08190a5be1fb108f1b10a done,end index 93\n",
      "id:batch_672b27568e8481909b44be2febe35a02 status:completed descrepition:nightly group1 temporal_consistency eval job batch 9\n",
      "batch batch_672b27568e8481909b44be2febe35a02 done,end index 117\n",
      "id:batch_672b27578e7881908fc1838716e88e29 status:failed descrepition:nightly group1 temporal_consistency eval job batch 17\n",
      "batch batch_672b27578e7881908fc1838716e88e29 is not completed\n",
      "id:batch_672b275aea4881909dc7778fc40a516d status:failed descrepition:nightly group1 temporal_consistency eval job batch 15\n",
      "batch batch_672b275aea4881909dc7778fc40a516d is not completed\n",
      "id:batch_672b275b08348190a6dc764942bc9165 status:failed descrepition:nightly group1 temporal_consistency eval job batch 16\n",
      "batch batch_672b275b08348190a6dc764942bc9165 is not completed\n"
     ]
    }
   ],
   "source": [
    "with open(\"./batch_infos/batch_info_{}.json\".format(dimension), \"r\") as f:\n",
    "    batch_info = json.load(f)\n",
    "\n",
    "    \n",
    "batchids = batch_info[\"batch_unique_ids\"]\n",
    "llmeval_path = \"./GPT4o_eval_results/{}/{}_llmeval_gridview2.json\".format(dimension,dimension)\n",
    "\n",
    "with open(llmeval_path, \"r\") as f:\n",
    "    llmeval = json.load(f)\n",
    "for i in ls:\n",
    "    llmeval[str(i)] = {}\n",
    "for id in batchids:\n",
    "    batch_object = client.batches.retrieve(id)\n",
    "    print(\"id:{} status:{} descrepition:{}\".format(id,batch_object.status,batch_object.metadata['description']))\n",
    "\n",
    "    if batch_object.status != \"completed\":\n",
    "        print(\"batch {} is not completed\".format(id))\n",
    "        continue    \n",
    "\n",
    "    file_response = client.files.content(batch_object.output_file_id)\n",
    "    for line in file_response.text.splitlines():\n",
    "        index = json.loads(line)[\"custom_id\"].split(\"-\")[-2]\n",
    "        model = json.loads(line)[\"custom_id\"].split(\"-\")[-1]\n",
    "        eval_res = json.loads(line)[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"].replace('\\n\\n','\\n')\n",
    "        llmeval[index][model] = eval_res\n",
    "    with open(llmeval_path, \"w\") as f:\n",
    "        json.dump(llmeval, f, indent=4)\n",
    "\n",
    "    print(\"batch {} done,end index {}\".format(id,index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
