{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from tool import videoreader\n",
    "# 创建一个OpenAI客户端实例\n",
    "client = OpenAI(\n",
    "    api_key=\"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\",\n",
    "    base_url=\"https://gateway.ai.cloudflare.com/v1/627f1b1f372e3a198dc32573bbc6f720/openai-gpt/openai\"  # 替换为你的自定义API域\n",
    ")\n",
    "\n",
    "## Set the API key and model name\n",
    "MODEL=\"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 'temporal_consistency'\n",
    "from PromptTemplate4GPTeval import Prompt4TemperalConsistency\n",
    "prompt_template = Prompt4TemperalConsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data_prepath = r'D:\\Astudying\\VideoEval\\data4dimensions'\n",
    "# data_prepath = \"../../data4dimensions/\"\n",
    "with open(\"./Human_anno/{}.json\".format(dimension)) as f:\n",
    "    human_anno = json.load(f)\n",
    "\n",
    "batch_stpath = '../batch_api/{}'.format(dimension)\n",
    "if not os.path.exists(batch_stpath):\n",
    "    os.makedirs(batch_stpath)\n",
    "\n",
    "batch_unique_ids = []\n",
    "batch_split_ids = []\n",
    "\n",
    "# with open(\"./batch_infos/batch_info_{}_gridstress_group3.json\".format(dimension), \"r\") as f:\n",
    "#     batch_info = json.load(f)\n",
    "\n",
    "# batch_split_ids = batch_info['batch_split_ids']\n",
    "# batch_unique_ids = batch_info['batch_unique_ids']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_batch(index_list,batch_id):\n",
    "#     requests = []\n",
    "# #     model2message = {\n",
    "# #     'cogvideox5b':\"12 frames from cogvideox5b,which you need to evaluate \\n\",\n",
    "# #     'kling':\"10 frames from kling ,which you need to evaluate\\n \", \n",
    "# #     'gen3': \"10 frames from gen3 ,which you need to evaluate\\n\",\n",
    "# #     'videocrafter2':\"4 frames from videocrafter2,which you need to evaluate\",\n",
    "# #     'pika':\"7 frames from pika ,which you need to evaluate\",\n",
    "# #     'show1':\"8 frames from show1,which you need to evaluate \",\n",
    "# #     'lavie':\"5 frames from lavie ,which you need to evaluate\",\n",
    "# #     }\n",
    "#     for i in index_list:     \n",
    "#         request ={\"custom_id\": \"request-{}\".format(i), \n",
    "#                 \"method\": \"POST\", \n",
    "#                 \"url\": \"/v1/chat/completions\",\n",
    "#                 \"body\": {\"model\": MODEL,\n",
    "#                             \"messages\": [],\n",
    "#                             \"temperature\": 0}}\n",
    "\n",
    "#         frames = videoreader.process_video(data_prepath,human_anno[i]['videos'],2)\n",
    "\n",
    "#         prompten = human_anno[i]['prompt_en']\n",
    "#         # question = human_anno[i]['question_en']\n",
    "#         # subject = human_anno[i]['subject_en']\n",
    "#         # scene = human_anno[i]['scene_en']\n",
    "#         # objet = human_anno[i]['object']\n",
    "#         messages=[\n",
    "#         {\n",
    "#         \"role\": \"system\", \"content\":\n",
    "#             prompt_template\n",
    "#             }\n",
    "#             ,\n",
    "#         {\n",
    "#             \"role\": \"user\", \"content\": [\n",
    "#                 \"These are the frames from the video.The prompt is '{}'.\".format(prompten),\n",
    "#                 \"12 frames from cogvideox5b \\n \", \n",
    "#                 *map(lambda x: {\"type\": \"image_url\", \n",
    "#                                 \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['cogvideox5b']),\n",
    "#                 \"10 frames from kling \\n \", \n",
    "#                 *map(lambda x: {\"type\": \"image_url\", \n",
    "#                                 \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['kling']),\n",
    "#                 \"10 frames from gen3 \\n \", \n",
    "#                 *map(lambda x: {\"type\": \"image_url\", \n",
    "#                                 \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['gen3']),\n",
    "#                 \" 4 frames from videocrafter2 \\n \",\n",
    "#                 *map(lambda x: {\"type\": \"image_url\", \n",
    "#                                 \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['videocrafter2']),   \n",
    "#                 \"\\n 7 frames from pika \\n\",\n",
    "#                 *map(lambda x: {\"type\": \"image_url\", \n",
    "#                                 \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['pika']),\n",
    "#                 \"\\n 8 frames from show1\\n \",\n",
    "#                 *map(lambda x: {\"type\": \"image_url\", \n",
    "#                                 \"image_url\": {\"url\":    f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['show1']),                             \n",
    "#                 \"\\n5 frames from lavie\\n \",\n",
    "#                 *map(lambda x: {\"type\": \"image_url\", \n",
    "#                                 \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}},frames['lavie']),\n",
    "#                                                           ], \n",
    "#             }\n",
    "#         ]\n",
    "\n",
    "#         request['body']['messages'] = messages\n",
    "\n",
    "#         requests.append(request)\n",
    "\n",
    "#     with open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"w\") as f:\n",
    "#         for entry in requests:\n",
    "#             json_line = json.dumps(entry)\n",
    "#             f.write(json_line + '\\n')\n",
    "    \n",
    "#     batch_input_file = client.files.create(\n",
    "#              file=open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"rb\"),\n",
    "#               purpose=\"batch\"\n",
    "#              )\n",
    "\n",
    "#     batch_input_file_id = batch_input_file.id    \n",
    "\n",
    "#     batch_object = client.batches.create(\n",
    "#             input_file_id=batch_input_file_id,\n",
    "#             endpoint=\"/v1/chat/completions\",\n",
    "#             completion_window=\"24h\",\n",
    "#             metadata={\n",
    "#             \"description\": \"nightly group1 {} eval job batch {}\".format(dimension,batch_id)\n",
    "#             }\n",
    "#                                         )\n",
    "\n",
    "#     batch_unique_ids.append(batch_object.id)\n",
    "#     batch_split_ids.append(batch_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_batch_onebyone(index_list,batch_id):\n",
    "    print(\"Thread {} is running\".format(batch_id))\n",
    "    model2message = {\n",
    "    'cogvideox5b':\"12 frames from cogvideox5b,which you need to evaluate \\n\",\n",
    "    'kling':\"10 frames from kling ,which you need to evaluate\\n \", \n",
    "    'gen3': \"10 frames from gen3 ,which you need to evaluate\\n\",\n",
    "    'videocrafter2':\"4 frames from videocrafter2,which you need to evaluate\",\n",
    "    'pika':\"7 frames from pika ,which you need to evaluate\",\n",
    "    'show1':\"8 frames from show1,which you need to evaluate \",\n",
    "    'lavie':\"5 frames from lavie ,which you need to evaluate\",\n",
    "    }\n",
    "    requests = []\n",
    "    for i in index_list:     \n",
    "        frames = videoreader.process_video2gridview(data_prepath,human_anno[i]['videos'],8)\n",
    "        for key, value in model2message.items():\n",
    "            modelname = key\n",
    "            modelmessage = value\n",
    "            for frameid in range(len(frames[modelname])):\n",
    "                request ={\"custom_id\": \"request-{}-{}-{}frames\".format(i,modelname,frameid), \n",
    "                        \"method\": \"POST\", \n",
    "                        \"url\": \"/v1/chat/completions\",\n",
    "                        \"body\": {\"model\": MODEL,\n",
    "                                    \"messages\": [],\n",
    "                                    \"temperature\": 0}}\n",
    "\n",
    "                examplemodels = [x for x in model2message.keys() if x != modelname]\n",
    "\n",
    "\n",
    "                prompten = human_anno[i]['prompt_en']\n",
    "                # question = human_anno[i]['question_en']\n",
    "                # subject = human_anno[i]['subject_en']\n",
    "                # scene = human_anno[i]['scene_en']\n",
    "                # objet = human_anno[i]['object']\n",
    "                messages=[\n",
    "                {\n",
    "                \"role\": \"system\", \"content\":\n",
    "                    prompt_template\n",
    "                    }\n",
    "                    ,\n",
    "                {\n",
    "                    \"role\": \"user\", \"content\":[\n",
    "\n",
    "                \"The following image is concatenated by the key frames of the video and arrange 8 key frames 1 second video clip in a 1*8 grid view.\\n\" ,\n",
    "                *map(lambda x: {\"type\": \"image_url\", \n",
    "                    \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}},[frames[modelname][frameid]]),    \n",
    "                 \"The video clip most likely have some unnatural changes and frame flickering.Find unnatural changes and evaluate the temporal consistency of the video.\\n\",                       \n",
    "                \"Assuming there are a video scoring 'x',provide your analysis and explanation in the output format as follows:\\n\"\n",
    "                \"- video clip: x ,because ...\"\n",
    "                ],\n",
    "                    }\n",
    "                ]\n",
    "                request['body']['messages'] = messages\n",
    "                requests.append(request)\n",
    "\n",
    "    with open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"w\") as f:\n",
    "        for entry in requests:\n",
    "            json_line = json.dumps(entry)\n",
    "            f.write(json_line + '\\n')\n",
    "    \n",
    "    batch_input_file = client.files.create(\n",
    "             file=open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"rb\"),\n",
    "              purpose=\"batch\"\n",
    "             )\n",
    "\n",
    "    batch_input_file_id = batch_input_file.id    \n",
    "\n",
    "    batch_object = client.batches.create(\n",
    "            input_file_id=batch_input_file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "            metadata={\n",
    "            \"description\": \"nightly group1 {} eval job batch {}\".format(dimension,batch_id)\n",
    "            }\n",
    "                                        )\n",
    "    \n",
    "    batch_split_ids.append(batch_id)\n",
    "    batch_unique_ids.append(batch_object.id)\n",
    "\n",
    "    print(\"Thread {} is done\".format(batch_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 = list(range(1,len(human_anno),3))\n",
    "# l2 = list(range(2,len(human_anno),3))\n",
    "l3 = list(range(0,len(human_anno),3))\n",
    "\n",
    "\n",
    "\n",
    "ls = l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 0 is running\n",
      "Thread 1 is running\n",
      "Thread 2 is running\n",
      "Thread 3 is running\n",
      "Thread 4 is running\n",
      "Thread 5 is running\n",
      "Thread 6 is running\n",
      "Thread 7 is running\n",
      "Thread 8 is running\n",
      "Thread 9 is running\n",
      "Thread 10 is running\n",
      "Thread 11 is running\n",
      "Thread 12 is running\n",
      "Thread 13 is running\n",
      "Thread 14 is running\n",
      "Thread 15 is running\n",
      "Thread 16 is running\n",
      "Thread 17 is running\n",
      "Thread 18 is running\n",
      "Thread 19 is running\n",
      "Thread 20 is running\n",
      "Thread 21 is running\n",
      "Thread 22 is running\n",
      "Thread 23 is running\n",
      "Thread 24 is running\n",
      "Thread 25 is running\n",
      "All threads started\n",
      "Thread 25 is done\n",
      "Thread 10 is done\n",
      "Thread 4 is done\n",
      "Thread 5 is done\n",
      "Thread 16 is done\n",
      "Thread 24 is done\n",
      "Thread 19 is done\n",
      "Thread 0 is done\n",
      "Thread 8 is done\n",
      "Thread 7 is done\n",
      "Thread 1 is done\n",
      "Thread 3 is done\n",
      "Thread 15 is done\n",
      "Thread 9 is done\n",
      "Thread 2 is done\n",
      "Thread 14 is done\n",
      "Thread 21 is done\n",
      "Thread 11 is done\n",
      "Thread 20 is done\n",
      "Thread 12 is done\n",
      "Thread 13 is done\n",
      "Thread 17 is done\n",
      "Thread 18 is done\n",
      "Thread 22 is done\n",
      "Thread 23 is done\n",
      "Thread 6 is done\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "batch_size = 3\n",
    "batches = [ls[i:i + batch_size] for i in range(0, len(ls), batch_size)]\n",
    "\n",
    "threads = []\n",
    "for i, batch in enumerate(batches):\n",
    "    if i in batch_split_ids:\n",
    "        continue\n",
    "    thread = threading.Thread(target=eval_batch_onebyone, args=(batch, i))\n",
    "    threads.append(thread)      \n",
    "    thread.start()\n",
    "\n",
    "print(\"All threads started\")\n",
    "# 等待所有线程完成\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "#保存batch信息\n",
    "with open(\"./batch_infos/batch_info_{}_videoclip.json\".format(dimension), \"w\") as f:\n",
    "    json.dump({\"batch_unique_ids\": batch_unique_ids, \"batch_split_ids\": batch_split_ids,\"videos_in_batch\":batches}, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id:batch_6732d79b26608190825dd03cf07f4358 status:completed descrepition:nightly group1 temporal_consistency eval job batch 25\n",
      "batch batch_6732d79b26608190825dd03cf07f4358 done,end index 231\n",
      "id:batch_6732d7c0387c819080cfad4110297ddc status:completed descrepition:nightly group1 temporal_consistency eval job batch 10\n",
      "batch batch_6732d7c0387c819080cfad4110297ddc done,end index 96\n",
      "id:batch_6732d7d474a48190ac6cd358ac9b614b status:completed descrepition:nightly group1 temporal_consistency eval job batch 4\n",
      "batch batch_6732d7d474a48190ac6cd358ac9b614b done,end index 42\n",
      "id:batch_6732d869edac8190a8ac083273f229f8 status:completed descrepition:nightly group1 temporal_consistency eval job batch 5\n",
      "batch batch_6732d869edac8190a8ac083273f229f8 done,end index 51\n",
      "id:batch_6732d87329588190ac1d53a45a38f2b6 status:completed descrepition:nightly group1 temporal_consistency eval job batch 16\n",
      "batch batch_6732d87329588190ac1d53a45a38f2b6 done,end index 150\n",
      "id:batch_6732d8740a1c81909f596ef8f94730fa status:completed descrepition:nightly group1 temporal_consistency eval job batch 24\n",
      "batch batch_6732d8740a1c81909f596ef8f94730fa done,end index 222\n",
      "id:batch_6732d898cddc81909166d9403a76ab71 status:completed descrepition:nightly group1 temporal_consistency eval job batch 19\n",
      "batch batch_6732d898cddc81909166d9403a76ab71 done,end index 177\n",
      "id:batch_6732d89d08c481908faaac4475fe3365 status:completed descrepition:nightly group1 temporal_consistency eval job batch 0\n",
      "batch batch_6732d89d08c481908faaac4475fe3365 done,end index 6\n",
      "id:batch_6732d8ab390c819088a2a0ae06f2c6c3 status:completed descrepition:nightly group1 temporal_consistency eval job batch 8\n",
      "batch batch_6732d8ab390c819088a2a0ae06f2c6c3 done,end index 78\n",
      "id:batch_6732d8c0fb6881909350bcde8b23d121 status:completed descrepition:nightly group1 temporal_consistency eval job batch 7\n",
      "batch batch_6732d8c0fb6881909350bcde8b23d121 done,end index 69\n",
      "id:batch_6732d8cf902881908ba05fc33e0ffe0f status:completed descrepition:nightly group1 temporal_consistency eval job batch 1\n",
      "batch batch_6732d8cf902881908ba05fc33e0ffe0f done,end index 15\n",
      "id:batch_6732d8da8cf481909d0bdc20c0417bc2 status:completed descrepition:nightly group1 temporal_consistency eval job batch 3\n",
      "batch batch_6732d8da8cf481909d0bdc20c0417bc2 done,end index 33\n",
      "id:batch_6732d8ec1af48190a5cf338f4e07fa10 status:completed descrepition:nightly group1 temporal_consistency eval job batch 15\n",
      "batch batch_6732d8ec1af48190a5cf338f4e07fa10 done,end index 141\n",
      "id:batch_6732d8f075408190aaa0b9b6215e4d4a status:completed descrepition:nightly group1 temporal_consistency eval job batch 9\n",
      "batch batch_6732d8f075408190aaa0b9b6215e4d4a done,end index 87\n",
      "id:batch_6732d91075d48190ada8af769a99890e status:completed descrepition:nightly group1 temporal_consistency eval job batch 2\n",
      "batch batch_6732d91075d48190ada8af769a99890e done,end index 24\n",
      "id:batch_6732d926df2c8190a02ae000f3c7f95c status:completed descrepition:nightly group1 temporal_consistency eval job batch 14\n",
      "batch batch_6732d926df2c8190a02ae000f3c7f95c done,end index 132\n",
      "id:batch_6732d92f512481908c245cb4ac5715dd status:completed descrepition:nightly group1 temporal_consistency eval job batch 21\n",
      "batch batch_6732d92f512481908c245cb4ac5715dd done,end index 195\n",
      "id:batch_6732d94998388190ac4e1db7a0039729 status:completed descrepition:nightly group1 temporal_consistency eval job batch 11\n",
      "batch batch_6732d94998388190ac4e1db7a0039729 done,end index 105\n",
      "id:batch_6732d94f8f688190a952380f0f3f6090 status:completed descrepition:nightly group1 temporal_consistency eval job batch 20\n",
      "batch batch_6732d94f8f688190a952380f0f3f6090 done,end index 186\n",
      "id:batch_6732d9537c50819084df2c4dfa742c97 status:completed descrepition:nightly group1 temporal_consistency eval job batch 12\n",
      "batch batch_6732d9537c50819084df2c4dfa742c97 done,end index 114\n",
      "id:batch_6732d97518388190911beab1faf4a1a4 status:completed descrepition:nightly group1 temporal_consistency eval job batch 13\n",
      "batch batch_6732d97518388190911beab1faf4a1a4 done,end index 123\n",
      "id:batch_6732d97f58988190992c0b7f39ab1075 status:completed descrepition:nightly group1 temporal_consistency eval job batch 17\n",
      "batch batch_6732d97f58988190992c0b7f39ab1075 done,end index 159\n",
      "id:batch_6732d98998fc8190a74b4a529166c1fc status:completed descrepition:nightly group1 temporal_consistency eval job batch 18\n",
      "batch batch_6732d98998fc8190a74b4a529166c1fc done,end index 168\n",
      "id:batch_6732d9898e008190a64a14a830f01f0a status:completed descrepition:nightly group1 temporal_consistency eval job batch 22\n",
      "batch batch_6732d9898e008190a64a14a830f01f0a done,end index 204\n",
      "id:batch_6732d997f9988190b332ef6849894c1f status:completed descrepition:nightly group1 temporal_consistency eval job batch 23\n",
      "batch batch_6732d997f9988190b332ef6849894c1f done,end index 213\n",
      "id:batch_6732d9984f708190b1e2fc710efe26dc status:completed descrepition:nightly group1 temporal_consistency eval job batch 6\n",
      "batch batch_6732d9984f708190b1e2fc710efe26dc done,end index 60\n"
     ]
    }
   ],
   "source": [
    "with open(\"./batch_infos/batch_info_{}_videoclip.json\".format(dimension), \"r\") as f:\n",
    "    batch_info = json.load(f)\n",
    "\n",
    "    \n",
    "batchids = batch_info[\"batch_unique_ids\"]\n",
    "llmeval_path = \"./GPT4o_eval_results/{}/{}_llmeval_clip.json\".format(dimension,dimension)\n",
    "\n",
    "with open(llmeval_path, \"r\") as f:\n",
    "    llmeval = json.load(f)\n",
    "    \n",
    "for i in ls:\n",
    "    if str(i) not in llmeval.keys():\n",
    "         llmeval[str(i)] = {}\n",
    "\n",
    "for id in batchids:\n",
    "    batch_object = client.batches.retrieve(id)\n",
    "    print(\"id:{} status:{} descrepition:{}\".format(id,batch_object.status,batch_object.metadata['description']))\n",
    "\n",
    "    if batch_object.status != \"completed\":\n",
    "        print(\"batch {} is not completed\".format(id))\n",
    "        continue    \n",
    "\n",
    "    file_response = client.files.content(batch_object.output_file_id)\n",
    "    for line in file_response.text.splitlines():\n",
    "\n",
    "        \n",
    "        index = json.loads(line)[\"custom_id\"].split(\"-\")[-3]\n",
    "        model = json.loads(line)[\"custom_id\"].split(\"-\")[-2]\n",
    "        frameid = json.loads(line)[\"custom_id\"].split(\"-\")[-1]\n",
    "\n",
    "        # index = json.loads(line)[\"custom_id\"].split(\"-\")[-2]\n",
    "        # model = json.loads(line)[\"custom_id\"].split(\"-\")[-1]\n",
    "\n",
    "        # index = json.loads(line)[\"custom_id\"].split(\"-\")[-1]\n",
    "\n",
    "        eval_res = json.loads(line)[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"].replace('\\n\\n','\\n')\n",
    "        \n",
    "        if model not in llmeval[index].keys():\n",
    "            llmeval[index][model] = {}\n",
    "        llmeval[index][model][frameid] = eval_res\n",
    "        \n",
    "        # llmeval[index][model] = eval_res\n",
    "        # llmeval[index] = eval_res\n",
    "    with open(llmeval_path, \"w\") as f:\n",
    "        json.dump(llmeval, f, indent=4)\n",
    "\n",
    "    print(\"batch {} done,end index {}\".format(id,index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
