{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from tool import videoreader\n",
    "# 创建一个OpenAI客户端实例\n",
    "client = OpenAI(\n",
    "    api_key=\"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\",\n",
    "    base_url=\"https://gateway.ai.cloudflare.com/v1/627f1b1f372e3a198dc32573bbc6f720/openai-gpt/openai\"  # 替换为你的自定义API域\n",
    ")\n",
    "\n",
    "## Set the API key and model name\n",
    "MODEL=\"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 'scene'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# data_prepath = r'D:\\Astudying\\VideoEval\\data4dimensions'\n",
    "data_prepath = \"../../data4dimensions/\"\n",
    "with open(\"./Human_anno/{}.json\".format(dimension)) as f:\n",
    "    human_anno = json.load(f)\n",
    "\n",
    "from PromptTemplate4GPTeval import Prompt4Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = list(range(0,len(human_anno),3))\n",
    "# l2 = list(range(161,len(human_anno),3))\n",
    "l = l1\n",
    "requests = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m l:     \n\u001b[0;32m      3\u001b[0m     request \u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest-1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m      4\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m      5\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/v1/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: MODEL,\n\u001b[0;32m      7\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m      8\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m}}\n\u001b[1;32m---> 10\u001b[0m     frames \u001b[38;5;241m=\u001b[39m \u001b[43mvideoreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_prepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhuman_anno\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvideos\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mresize_fx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mresize_fy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     prompten \u001b[38;5;241m=\u001b[39m human_anno[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt_en\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# question = human_anno[i]['question_en']\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# subject = human_anno[i]['subject_en']\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# scene = human_anno[i]['scene_en']\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# objet = human_anno[i]['object']\u001b[39;00m\n",
      "File \u001b[1;32md:\\AStudying\\AI\\Niii_1\\hopes\\codes\\HighlyHumanLikeVEB\\tool\\videoreader.py:14\u001b[0m, in \u001b[0;36mprocess_video\u001b[1;34m(datadir, videos_path, extract_frames_persecond, resize_fx, resize_fy)\u001b[0m\n\u001b[0;32m     12\u001b[0m base64Frames \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcogvideox5b\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkling\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgen3\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlavie\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpika\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow1\u001b[39m\u001b[38;5;124m\"\u001b[39m:[],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideocrafter2\u001b[39m\u001b[38;5;124m\"\u001b[39m:[]}\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m base64Frames\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m---> 14\u001b[0m     video \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVideoCapture\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatadir\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvideos_path\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m video\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Cannot open video file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatadir\u001b[38;5;241m+\u001b[39mvideos_path[key]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# skip_index = list(range(0, len(human_anno),5))\n",
    "for i in l:     \n",
    "    request ={\"custom_id\": \"request-{}\".format(i), \n",
    "              \"method\": \"POST\", \n",
    "              \"url\": \"/v1/chat/completions\",\n",
    "              \"body\": {\"model\": MODEL,\n",
    "                        \"messages\": [],\n",
    "                        \"temperature\": 0}}\n",
    "\n",
    "    frames = videoreader.process_video(data_prepath,human_anno[i]['videos'],2 ,resize_fx=1,resize_fy=1)\n",
    "\n",
    "    prompten = human_anno[i]['prompt_en']\n",
    "    # question = human_anno[i]['question_en']\n",
    "    # subject = human_anno[i]['subject_en']\n",
    "    # scene = human_anno[i]['scene_en']\n",
    "    # objet = human_anno[i]['object']\n",
    "    messages=[\n",
    "    {\n",
    "    \"role\": \"system\", \"content\":\n",
    "        Prompt4Scene\n",
    "        }\n",
    "        ,\n",
    "    {\n",
    "        \"role\": \"user\", \"content\": [\n",
    "        \"During the evaluation,you shouldn't take any video from any model in input as a reference for the evaluation.Please evaluate the video independently based on 'Evaluation Criteria'.\"\n",
    "        \"These are the frames from the video.The prompt is '{}.\\n\".format(prompten),\n",
    "        \"12 frames from cogvideox5b \\n \", \n",
    "        *map(lambda x: {\"type\": \"image_url\", \n",
    "                        \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['cogvideox5b']),\n",
    "        \"10 frames from kling \\n \", \n",
    "        *map(lambda x: {\"type\": \"image_url\", \n",
    "                        \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['kling']),\n",
    "        \"10 frames from gen3 \\n \", \n",
    "        *map(lambda x: {\"type\": \"image_url\", \n",
    "                        \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['gen3']),\n",
    "        \" 4 frames from videocrafter2 \\n \",\n",
    "        *map(lambda x: {\"type\": \"image_url\", \n",
    "                        \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['videocrafter2']),   \n",
    "        \"\\n 7 frames from pika \\n\",\n",
    "        *map(lambda x: {\"type\": \"image_url\", \n",
    "                        \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['pika']),\n",
    "        \"\\n 8 frames from show1\\n \",\n",
    "        *map(lambda x: {\"type\": \"image_url\", \n",
    "                        \"image_url\": {\"url\":    f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['show1']),                             \n",
    "        \"\\n5 frames from lavie\\n \",\n",
    "        *map(lambda x: {\"type\": \"image_url\", \n",
    "                        \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}},frames['lavie']),\n",
    "                                                    ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    request['body']['messages'] = messages\n",
    "\n",
    "{}    requests.append(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
