{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from tool import videoreader\n",
    "# 创建一个OpenAI客户端实例\n",
    "client = OpenAI(\n",
    "    api_key=\"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\",\n",
    "    base_url=\"https://gateway.ai.cloudflare.com/v1/627f1b1f372e3a198dc32573bbc6f720/openai-gpt/openai\"  # 替换为你的自定义API域\n",
    ")\n",
    "\n",
    "## Set the API key and model name\n",
    "MODEL=\"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 'temporal_consistency'\n",
    "from PromptTemplate4GPTeval import Prompt4TemperalConsistency\n",
    "prompt_template = Prompt4TemperalConsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data_prepath = r'D:\\Astudying\\VideoEval\\data4dimensions'\n",
    "# data_prepath = \"../../data4dimensions/\"\n",
    "with open(\"./Human_anno/{}.json\".format(dimension)) as f:\n",
    "    human_anno = json.load(f)\n",
    "\n",
    "batch_stpath = '../batch_api/{}'.format(dimension)\n",
    "if not os.path.exists(batch_stpath):\n",
    "    os.makedirs(batch_stpath)\n",
    "\n",
    "batch_unique_ids = []\n",
    "batch_split_ids = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_batch(index_list,batch_id):\n",
    "#     requests = []\n",
    "#     for i in index_list:     \n",
    "#         request ={\"custom_id\": \"request-{}\".format(i), \n",
    "#                 \"method\": \"POST\", \n",
    "#                 \"url\": \"/v1/chat/completions\",\n",
    "#                 \"body\": {\"model\": MODEL,\n",
    "#                             \"messages\": [],\n",
    "#                             \"temperature\": 0}}\n",
    "\n",
    "#         frames = videoreader.process_video2gridview(data_prepath,human_anno[i]['videos'],4)\n",
    "\n",
    "#         prompten = human_anno[i]['prompt_en']\n",
    "#         # question = human_anno[i]['question_en']\n",
    "#         # subject = human_anno[i]['subject_en']\n",
    "#         # scene = human_anno[i]['scene_en']\n",
    "#         # objet = human_anno[i]['object']\n",
    "#         messages=[\n",
    "#         {\n",
    "#         \"role\": \"system\", \"content\":\n",
    "#             prompt_template\n",
    "#             }\n",
    "#             ,\n",
    "#         {\n",
    "#             \"role\": \"user\", \"content\": [\n",
    "            \n",
    "#             \" The following images arrange 4 key frames from 1 second video clip from videos in a 1*4 grid view.\" ,\n",
    "\n",
    "#             \"The grid view images from model1 \\n \", \n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['cogvideox5b']),\n",
    "#             \"The grid view images from model2 \\n \", \n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['kling']),\n",
    "#             \"The grid view images from model3 \\n \", \n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['gen3']),\n",
    "#             \" The grid view images from model4 \\n \",\n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['videocrafter2']),   \n",
    "#             \"\\nThe grid view images from model5 \\n\",\n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['pika']),\n",
    "#             \"\\n The grid view images from model6\\n \",\n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\":    f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['show1']),                             \n",
    "#             \"\\nThe grid view images from  model7\\n \",\n",
    "#             *map(lambda x: {\"type\": \"image_url\", \n",
    "#                             \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}},frames['lavie']),\n",
    "\n",
    "#            \"Assuming there are  videos scoring 'x,y,z..',provide your analysis and explanation in the output format as follows:\\n\"\n",
    "#             \"- model1: x ,because ...\\n \"\n",
    "#             \"- model2: y ,because ...\\n \"\n",
    "#             \"- model3: z ,because ...\\n \"\n",
    "#                                                         ],\n",
    " \n",
    "#             }\n",
    "#         ]\n",
    "\n",
    "#         request['body']['messages'] = messages\n",
    "\n",
    "#         requests.append(request)\n",
    "\n",
    "#     with open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"w\") as f:\n",
    "#         for entry in requests:\n",
    "#             json_line = json.dumps(entry)\n",
    "#             f.write(json_line + '\\n')\n",
    "    \n",
    "#     batch_input_file = client.files.create(\n",
    "#              file=open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"rb\"),\n",
    "#               purpose=\"batch\"\n",
    "#              )\n",
    "\n",
    "#     batch_input_file_id = batch_input_file.id    \n",
    "\n",
    "#     batch_object = client.batches.create(\n",
    "#             input_file_id=batch_input_file_id,\n",
    "#             endpoint=\"/v1/chat/completions\",\n",
    "#             completion_window=\"24h\",\n",
    "#             metadata={\n",
    "#             \"description\": \"nightly group1 {} eval job batch {}\".format(dimension,batch_id)\n",
    "#             }\n",
    "#                                         )\n",
    "\n",
    "#     batch_unique_ids.append(batch_object.id)\n",
    "#     batch_split_ids.append(batch_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_batch_onebyone(index_list,batch_id):\n",
    "    print(\"Thread {} is running\".format(batch_id))\n",
    "    model2message = {\n",
    "    'cogvideox5b':\"12 frames from cogvideox5b,which you need to evaluate \\n\",\n",
    "    'kling':\"10 frames from kling ,which you need to evaluate\\n \", \n",
    "    'gen3': \"10 frames from gen3 ,which you need to evaluate\\n\",\n",
    "    'videocrafter2':\"4 frames from videocrafter2,which you need to evaluate\",\n",
    "    'pika':\"7 frames from pika ,which you need to evaluate\",\n",
    "    'show1':\"8 frames from show1,which you need to evaluate \",\n",
    "    'lavie':\"5 frames from lavie ,which you need to evaluate\",\n",
    "    }\n",
    "    requests = []\n",
    "    for i in index_list:     \n",
    "        frames = videoreader.process_video2gridview(data_prepath,human_anno[i]['videos'],8)\n",
    "        for key, value in model2message.items():\n",
    "            modelname = key\n",
    "            modelmessage = value\n",
    "    \n",
    "            request ={\"custom_id\": \"request-{}-{}\".format(i,modelname), \n",
    "                    \"method\": \"POST\", \n",
    "                    \"url\": \"/v1/chat/completions\",\n",
    "                    \"body\": {\"model\": MODEL,\n",
    "                                \"messages\": [],\n",
    "                                \"temperature\": 0}}\n",
    "\n",
    "            examplemodels = [x for x in model2message.keys() if x != modelname]\n",
    "\n",
    "\n",
    "            prompten = human_anno[i]['prompt_en']\n",
    "            # question = human_anno[i]['question_en']\n",
    "            # subject = human_anno[i]['subject_en']\n",
    "            # scene = human_anno[i]['scene_en']\n",
    "            # objet = human_anno[i]['object']\n",
    "            messages=[\n",
    "            {\n",
    "            \"role\": \"system\", \"content\":\n",
    "                prompt_template\n",
    "                }\n",
    "                ,\n",
    "            {\n",
    "                \"role\": \"user\", \"content\":[\n",
    "\n",
    "            \"The following images are concatenated by the key frames of the video.And one of the following images arranges 8 key frames per second from a video in a 1*8 grid view.\\n\" ,\n",
    "            \"Please associate the images in time order to help you watch the whole video.\\n\",\n",
    "            *map(lambda x: {\"type\": \"image_url\", \n",
    "                \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}},frames[modelname]),    \n",
    "            \"The video most likely have some unnatural changes and frame flickering.Find unnatural changes and frame flickering, then evaluate the temporal consistency of the video.\\n\",                       \n",
    "            \"Assuming there are a video scoring 'x',provide your analysis and explanation in the output format as follows:\\n\"\n",
    "            \"- video: x ,because ...\"\n",
    "              ],\n",
    "                }\n",
    "            ]\n",
    "            request['body']['messages'] = messages\n",
    "            requests.append(request)\n",
    "\n",
    "    with open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"w\") as f:\n",
    "        for entry in requests:\n",
    "            json_line = json.dumps(entry)\n",
    "            f.write(json_line + '\\n')\n",
    "    \n",
    "    batch_input_file = client.files.create(\n",
    "             file=open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"rb\"),\n",
    "              purpose=\"batch\"\n",
    "             )\n",
    "\n",
    "    batch_input_file_id = batch_input_file.id    \n",
    "\n",
    "    batch_object = client.batches.create(\n",
    "            input_file_id=batch_input_file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "            metadata={\n",
    "            \"description\": \"nightly group1 {} eval job batch {}\".format(dimension,batch_id)\n",
    "            }\n",
    "                                        )\n",
    "    \n",
    "    batch_split_ids.append(batch_id)\n",
    "    batch_unique_ids.append(batch_object.id)\n",
    "\n",
    "    print(\"Thread {} is done\".format(batch_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 = list(range(1,len(human_anno),3))\n",
    "l2 = list(range(2,len(human_anno),3))\n",
    "# l3 = list(range(0,len(human_anno),3))\n",
    "\n",
    "# l = [int(x) for x in['204', '207', '210', '213', '216', '219', '222', '225', '228', '231']]\n",
    "\n",
    "\n",
    "ls = l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 0 is runningThread 1 is running\n",
      "\n",
      "Thread 2 is running\n",
      "Thread 3 is running\n",
      "Thread 4 is running\n",
      "Thread 5 is running\n",
      "Thread 6 is running\n",
      "Thread 7 is running\n",
      "Thread 8 is running\n",
      "Thread 9 is running\n",
      "Thread 10 is running\n",
      "Thread 11 is running\n",
      "Thread 12 is running\n",
      "Thread 13 is running\n",
      "Thread 14 is running\n",
      "Thread 15 is running\n",
      "Thread 16 is running\n",
      "Thread 17 is running\n",
      "Thread 18 is running\n",
      "Thread 19 is running\n",
      "Thread 20 is running\n",
      "Thread 21 is running\n",
      "Thread 22 is running\n",
      "Thread 23 is running\n",
      "Thread 24 is running\n",
      "Thread 25 is running\n",
      "All threads started\n",
      "Thread 25 is done\n",
      "Thread 8 is done\n",
      "Thread 16 is done\n",
      "Thread 5 is done\n",
      "Thread 10 is done\n",
      "Thread 4 is done\n",
      "Thread 3 is done\n",
      "Thread 2 is done\n",
      "Thread 24 is done\n",
      "Thread 20 is done\n",
      "Thread 0 is done\n",
      "Thread 19 is done\n",
      "Thread 1 is done\n",
      "Thread 9 is done\n",
      "Thread 13 is done\n",
      "Thread 15 is done\n",
      "Thread 18 is done\n",
      "Thread 12 is done\n",
      "Thread 23 is done\n",
      "Thread 14 is done\n",
      "Thread 6 is done\n",
      "Thread 21 is done\n",
      "Thread 22 is done\n",
      "Thread 17 is done\n",
      "Thread 7 is done\n",
      "Thread 11 is done\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "batch_size = 3\n",
    "batches = [ls[i:i + batch_size] for i in range(0, len(ls), batch_size)]\n",
    "# with open(\"./batch_infos/batch_info_{}.json\".format(dimension), \"r\") as f:\n",
    "#     batch_info = json.load(f)\n",
    "\n",
    "# batch_split_ids = batch_info['batch_split_ids']\n",
    "# batches = batch_info['videos_in_batch']\n",
    "\n",
    "threads = []\n",
    "for i, batch in enumerate(batches):\n",
    "    thread = threading.Thread(target=eval_batch_onebyone, args=(batch, i))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "print(\"All threads started\")\n",
    "# 等待所有线程完成\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "#保存batch信息\n",
    "with open(\"./batch_infos/batch_info_{}_gridstress_group3.json\".format(dimension), \"w\") as f:\n",
    "    json.dump({\"batch_unique_ids\": batch_unique_ids, \"batch_split_ids\": batch_split_ids,\"videos_in_batch\":batches}, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id:batch_6731ee6d94d48190b0d3cf430dd95255 status:completed descrepition:nightly group1 temporal_consistency eval job batch 25\n",
      "batch batch_6731ee6d94d48190b0d3cf430dd95255 done,end index 233\n",
      "id:batch_6731ee6e3e2c81909285e3c5ed7e6b3e status:completed descrepition:nightly group1 temporal_consistency eval job batch 8\n",
      "batch batch_6731ee6e3e2c81909285e3c5ed7e6b3e done,end index 80\n",
      "id:batch_6731ee7eb6cc8190a70d00ff4450210e status:completed descrepition:nightly group1 temporal_consistency eval job batch 16\n",
      "batch batch_6731ee7eb6cc8190a70d00ff4450210e done,end index 152\n",
      "id:batch_6731ee8bd49081909a3edf01d2483c04 status:completed descrepition:nightly group1 temporal_consistency eval job batch 5\n",
      "batch batch_6731ee8bd49081909a3edf01d2483c04 done,end index 53\n",
      "id:batch_6731ee9419348190a771314964f3f98a status:completed descrepition:nightly group1 temporal_consistency eval job batch 10\n",
      "batch batch_6731ee9419348190a771314964f3f98a done,end index 98\n",
      "id:batch_6731ee9549ac819084a636058ac67358 status:completed descrepition:nightly group1 temporal_consistency eval job batch 4\n",
      "batch batch_6731ee9549ac819084a636058ac67358 done,end index 44\n",
      "id:batch_6731ee9ad0848190b11e157202f5125b status:completed descrepition:nightly group1 temporal_consistency eval job batch 3\n",
      "batch batch_6731ee9ad0848190b11e157202f5125b done,end index 35\n",
      "id:batch_6731eea1b35c8190b9c2873733ff7cdf status:completed descrepition:nightly group1 temporal_consistency eval job batch 2\n",
      "batch batch_6731eea1b35c8190b9c2873733ff7cdf done,end index 26\n",
      "id:batch_6731eea4440c81908941c3970ef528ba status:completed descrepition:nightly group1 temporal_consistency eval job batch 24\n",
      "batch batch_6731eea4440c81908941c3970ef528ba done,end index 224\n",
      "id:batch_6731eea64ba881908c8f90a1e34e8aaf status:completed descrepition:nightly group1 temporal_consistency eval job batch 20\n",
      "batch batch_6731eea64ba881908c8f90a1e34e8aaf done,end index 188\n",
      "id:batch_6731eea8e62081909658ff8203e05d8e status:completed descrepition:nightly group1 temporal_consistency eval job batch 0\n",
      "batch batch_6731eea8e62081909658ff8203e05d8e done,end index 8\n",
      "id:batch_6731eea994d08190b11214f07a608a2d status:completed descrepition:nightly group1 temporal_consistency eval job batch 19\n",
      "batch batch_6731eea994d08190b11214f07a608a2d done,end index 179\n",
      "id:batch_6731eeb108248190b1c96db4ce70636b status:completed descrepition:nightly group1 temporal_consistency eval job batch 1\n",
      "batch batch_6731eeb108248190b1c96db4ce70636b done,end index 17\n",
      "id:batch_6731eeb30cb48190a1f74ea82975e5ec status:completed descrepition:nightly group1 temporal_consistency eval job batch 9\n",
      "batch batch_6731eeb30cb48190a1f74ea82975e5ec done,end index 89\n",
      "id:batch_6731eec3d4a08190810f660f9db6ef24 status:completed descrepition:nightly group1 temporal_consistency eval job batch 13\n",
      "batch batch_6731eec3d4a08190810f660f9db6ef24 done,end index 125\n",
      "id:batch_6731eecc1fd0819090c98480992aa201 status:completed descrepition:nightly group1 temporal_consistency eval job batch 15\n",
      "batch batch_6731eecc1fd0819090c98480992aa201 done,end index 143\n",
      "id:batch_6731eece013c8190972cfea3bf6abee8 status:completed descrepition:nightly group1 temporal_consistency eval job batch 18\n",
      "batch batch_6731eece013c8190972cfea3bf6abee8 done,end index 170\n",
      "id:batch_6731eed4125481909c7d606a7f1a4e60 status:completed descrepition:nightly group1 temporal_consistency eval job batch 12\n",
      "batch batch_6731eed4125481909c7d606a7f1a4e60 done,end index 116\n",
      "id:batch_6731eed8c5808190885e734a95f4fd62 status:completed descrepition:nightly group1 temporal_consistency eval job batch 23\n",
      "batch batch_6731eed8c5808190885e734a95f4fd62 done,end index 215\n",
      "id:batch_6731eed9c6c88190ae81f7502c601a7f status:completed descrepition:nightly group1 temporal_consistency eval job batch 14\n",
      "batch batch_6731eed9c6c88190ae81f7502c601a7f done,end index 134\n",
      "id:batch_6731eee151c881908d78cfeee6af02f4 status:completed descrepition:nightly group1 temporal_consistency eval job batch 6\n",
      "batch batch_6731eee151c881908d78cfeee6af02f4 done,end index 62\n",
      "id:batch_6731eee285488190a3d274ee881b2ee8 status:completed descrepition:nightly group1 temporal_consistency eval job batch 21\n",
      "batch batch_6731eee285488190a3d274ee881b2ee8 done,end index 197\n",
      "id:batch_6731eeef83fc8190bbcfd30ec8c092bf status:completed descrepition:nightly group1 temporal_consistency eval job batch 22\n",
      "batch batch_6731eeef83fc8190bbcfd30ec8c092bf done,end index 206\n",
      "id:batch_6731ef025888819097d0b7b3357d3d0e status:completed descrepition:nightly group1 temporal_consistency eval job batch 17\n",
      "batch batch_6731ef025888819097d0b7b3357d3d0e done,end index 161\n",
      "id:batch_6731ef0769b08190a2fa045a01fe7d50 status:completed descrepition:nightly group1 temporal_consistency eval job batch 7\n",
      "batch batch_6731ef0769b08190a2fa045a01fe7d50 done,end index 71\n",
      "id:batch_6731ef31cc288190821bd9b80bb682f3 status:completed descrepition:nightly group1 temporal_consistency eval job batch 11\n",
      "batch batch_6731ef31cc288190821bd9b80bb682f3 done,end index 107\n"
     ]
    }
   ],
   "source": [
    "with open(\"./batch_infos/batch_info_{}_gridstress_group3.json\".format(dimension), \"r\") as f:\n",
    "    batch_info = json.load(f)\n",
    "\n",
    "    \n",
    "batchids = batch_info[\"batch_unique_ids\"]\n",
    "llmeval_path = \"./GPT4o_eval_results/{}/{}_llmeval_gridview_usrstress.json\".format(dimension,dimension)\n",
    "\n",
    "with open(llmeval_path, \"r\") as f:\n",
    "    llmeval = json.load(f)\n",
    "    \n",
    "for i in ls:\n",
    "    # if str(i) not in llmeval.keys():\n",
    "         llmeval[str(i)] = {}\n",
    "\n",
    "for id in batchids:\n",
    "    batch_object = client.batches.retrieve(id)\n",
    "    print(\"id:{} status:{} descrepition:{}\".format(id,batch_object.status,batch_object.metadata['description']))\n",
    "\n",
    "    if batch_object.status != \"completed\":\n",
    "        print(\"batch {} is not completed\".format(id))\n",
    "        continue    \n",
    "\n",
    "    file_response = client.files.content(batch_object.output_file_id)\n",
    "    for line in file_response.text.splitlines():\n",
    "        index = json.loads(line)[\"custom_id\"].split(\"-\")[-2]\n",
    "        model = json.loads(line)[\"custom_id\"].split(\"-\")[-1]\n",
    "\n",
    "        # index = json.loads(line)[\"custom_id\"].split(\"-\")[-1]\n",
    "\n",
    "        eval_res = json.loads(line)[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"].replace('\\n\\n','\\n')\n",
    "        \n",
    "        llmeval[index][model] = eval_res\n",
    "        # llmeval[index] = eval_res\n",
    "    with open(llmeval_path, \"w\") as f:\n",
    "        json.dump(llmeval, f, indent=4)\n",
    "\n",
    "    print(\"batch {} done,end index {}\".format(id,index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
