{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from tool import videoreader\n",
    "# 创建一个OpenAI客户端实例\n",
    "client = OpenAI(\n",
    "    api_key=\"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\",\n",
    "    base_url=\"https://gateway.ai.cloudflare.com/v1/627f1b1f372e3a198dc32573bbc6f720/openai-gateway/openai\"  # 替换为你的自定义API域\n",
    ")\n",
    "\n",
    "## Set the API key and model name\n",
    "MODEL=\"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data_prepath = r\"D:\\Astudying\\VideoEval\\data\"\n",
    "with open(r'D:\\Astudying\\VideoEval\\HighlyHumanLikeVEB\\Human_anno\\color.json') as f:\n",
    "    human_anno = json.load(f)\n",
    "s = dict()\n",
    "from PromptTemplate4GPTeval import Prompt4Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames = videoreader.process_video(data_prepath,human_anno[1]['videos'],2 ,resize_fx=1,resize_fy=1)\n",
    "# videoreader.display_base64_images(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Scores:\n",
      "\n",
      "- Gen2: 5, because the color of the grapes is consistent with the text prompt throughout the video, with no abrupt changes. The grapes are depicted in natural shades of purple and green, matching the expected appearance.\n",
      "\n",
      "- Pika: 4, because the colors are mostly consistent with the text prompt, but there are slight variations in the color saturation of the grapes. The overall effect is good, but not perfect.\n",
      "\n",
      "- Show1: 3, because the colors are moderately consistent with the text prompt. The grapes appear in purple and green, but the colors are somewhat muted and lack vibrancy, affecting the viewing experience.\n",
      "\n",
      "- Videocrafter2: 4, because the colors are generally consistent with the text prompt, with vibrant purple and green grapes. However, there are minor inconsistencies in color distribution.\n",
      "\n",
      "- Lavie: 3, because the colors are moderately consistent with the text prompt. The grapes are depicted in purple, but the overall color is less vibrant and appears slightly washed out, impacting the viewing experience.\n",
      "Final Scores:\n",
      "\n",
      "- Gen2: 5, because the color of the grapes is consistent with the text prompt throughout the video, with no abrupt changes or incorrect color distribution, providing an excellent viewing experience.\n",
      "\n",
      "- Pika: 5, because the colors of the grapes are vibrant and consistent with the text prompt, with no abrupt changes or incorrect color distribution, ensuring an excellent viewing experience.\n",
      "\n",
      "- Show1: 4, because the color is mostly consistent with the text prompt, but there are slight variations in color distribution that slightly affect the viewing experience.\n",
      "\n",
      "- Videocrafter2: 4, because the colors are consistent with the text prompt, but there are minor variations in lighting that slightly affect the viewing experience.\n",
      "\n",
      "- Lavie: 3, because the colors are generally consistent with the text prompt, but there are noticeable variations in color distribution and lighting that impact the viewing experience.\n"
     ]
    }
   ],
   "source": [
    "# skip_index = list(range(0, len(human_anno),5))\n",
    "for i in range(0, len(human_anno)):\n",
    "    # if i in skip_index:\n",
    "    #     continue\n",
    "    # # frames = videoreader.process_video(data_dir,human_anno[i]['videos'],4 )\n",
    "    # else:\n",
    "        frames = videoreader.process_video(data_prepath,human_anno[i]['videos'],2 ,resize_fx=1,resize_fy=1)\n",
    "        prompten = human_anno[i]['prompt_en']\n",
    "        # question = human_anno[i]['question_en']\n",
    "        # subject = human_anno[i]['subject_en']\n",
    "        # scene = human_anno[i]['scene_en']\n",
    "        # objet = human_anno[i]['object']\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "            model=MODEL, \n",
    "            messages=[\n",
    "            {\n",
    "            \"role\": \"system\", \"content\":\n",
    "             Prompt4Color\n",
    "             }\n",
    "             ,\n",
    "            {\n",
    "                \"role\": \"user\", \"content\": [\n",
    "                \"These are the frames from the video.The prompt is '{}'.\".format(prompten),\n",
    "                \"9 frames from gen2 and captured at 0s,0.5s,1s,1.5s,2s,2.5s,3s,3.5s,4s\",\n",
    "                *map(lambda x: {\"type\": \"image_url\", \n",
    "                                \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['gen2']),\n",
    "                \"7 frames from pika and  captured at 0s,0.5s,1s,1.5s,2s,2.5s,3s\",\n",
    "                *map(lambda x: {\"type\": \"image_url\", \n",
    "                                \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['pika']),\n",
    "                \"8 frames from show1 and captured at 0s,0.5s,1s,1.5s,2s,2.5s,3s,3.5s\",\n",
    "                *map(lambda x: {\"type\": \"image_url\", \n",
    "                                \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['show1']),               \n",
    "                \"4 frames from videocrafter2 and captured at 0s,0.5s,1s,1.5s,1.5s\",\n",
    "                *map(lambda x: {\"type\": \"image_url\", \n",
    "                                \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['videocrafter2']),                 \n",
    "                \"5 frames from lavie and  captured at 0s,0.5s,1s,1.5s,2s\",\n",
    "                *map(lambda x: {\"type\": \"image_url\", \n",
    "                                \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames['lavie']),\n",
    " \n",
    "                                                          ],\n",
    "            }\n",
    "            ],\n",
    "            temperature=0,\n",
    "            )\n",
    "            print(response.choices[0].message.content) \n",
    "            s[i] = response.choices[0].message.content.replace('\\n\\n','\\n')\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            s[i] = 'Error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# 使用 json 保存字典\n",
    "with open(r\"D:\\Astudying\\VideoEval\\HighlyHumanLikeVEB\\GPT4o_eval_results\\color_gpt4eval_results.json\", \"w\") as f:\n",
    "    json.dump(s, f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"D:\\Astudying\\VideoEval\\HighlyHumanLikeVEB\\GPT4o_eval_results\\color_gpt4eval_results.json\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "video_path = r\"D:\\Astudying\\VideoEval\\HighlyHumanLikeVEB\\Human_anno\\color.json\"\n",
    "with open(video_path, \"r\") as file:\n",
    "    annotations = json.load(file)\n",
    "\n",
    "for index,key in enumerate(data.keys()):       \n",
    "    for line in data[key].split('\\n'):\n",
    "        if line == '' or line[0] != '-':\n",
    "            continue\n",
    "        model_name = line.split(',')[0].split(' ')[1].split(':')[0].lower()\n",
    "        score = int(line.split(',')[0].split(' ')[2])\n",
    "        annotations[index]['gpt4o_eval'][model_name] = score\n",
    "    \n",
    "with open(video_path, \"w\") as f:\n",
    "    json.dump(annotations, f,indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
