{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from tool import videoreader\n",
    "# 创建一个OpenAI客户端实例\n",
    "client = OpenAI(\n",
    "    api_key=\"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\",\n",
    "    base_url=\"https://gateway.ai.cloudflare.com/v1/627f1b1f372e3a198dc32573bbc6f720/openai-gpt/openai\"  # 替换为你的自定义API域\n",
    ")\n",
    "\n",
    "## Set the API key and model name\n",
    "MODEL=\"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 'object_class'\n",
    "from PromptTemplate4GPTeval import Prompt4Scene\n",
    "prompt_template = Prompt4Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data_prepath = r'D:\\Astudying\\VideoEval\\data4dimensions'\n",
    "# data_prepath = \"../../data4dimensions/\"\n",
    "with open(\"./Human_anno/{}.json\".format(dimension)) as f:\n",
    "    human_anno = json.load(f)\n",
    "\n",
    "batch_stpath = '../batch_api/{}'.format(dimension)\n",
    "if not os.path.exists(batch_stpath):\n",
    "    os.makedirs(batch_stpath)\n",
    "\n",
    "batch_unique_ids = []\n",
    "batch_split_ids = []\n",
    "\n",
    "# with open(\"./batch_infos/batch_info_{}_gridstress_group3.json\".format(dimension), \"r\") as f:\n",
    "#     batch_info = json.load(f)\n",
    "\n",
    "# batch_split_ids = batch_info['batch_split_ids']\n",
    "# batch_unique_ids = batch_info['batch_unique_ids']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ablation study\n",
    "def eval_batch_onebyone(index_list,batch_id):\n",
    "    print(\"Thread {} is running\".format(batch_id))\n",
    "    model2message = {\n",
    "    'cogvideox5b':\"12 frames from cogvideox5b,which you need to evaluate \\n\",\n",
    "    'kling':\"10 frames from kling ,which you need to evaluate\\n \", \n",
    "    'gen3': \"10 frames from gen3 ,which you need to evaluate\\n\",\n",
    "    'videocrafter2':\"4 frames from videocrafter2,which you need to evaluate\",\n",
    "    'pika':\"7 frames from pika ,which you need to evaluate\",\n",
    "    'show1':\"8 frames from show1,which you need to evaluate \",\n",
    "    'lavie':\"5 frames from lavie ,which you need to evaluate\",\n",
    "    }\n",
    "    requests = []\n",
    "    for i in index_list:     \n",
    "        frames = videoreader.process_video(data_prepath,human_anno[i]['videos'],2)\n",
    "        for key, value in model2message.items():\n",
    "            modelname = key\n",
    "            modelmessage = value\n",
    "            request ={\"custom_id\": \"request-{}-{}\".format(i,modelname), \n",
    "                    \"method\": \"POST\", \n",
    "                    \"url\": \"/v1/chat/completions\",\n",
    "                    \"body\": {\"model\": MODEL,\n",
    "                                \"messages\": [],\n",
    "                                \"temperature\": 0}}\n",
    "\n",
    "            prompten = human_anno[i]['prompt_en']\n",
    "            # question = human_anno[i]['question_en']\n",
    "            # subject = human_anno[i]['subject_en']\n",
    "            # scene = human_anno[i]['scene_en']\n",
    "            # objet = human_anno[i]['object']\n",
    "            messages=[\n",
    "            {\n",
    "            \"role\": \"system\", \"content\":\n",
    "                'You are a Video Evaluation Expert tasked with evaluating the object class consistencybetween the video and the text prompt.'\n",
    "                }\n",
    "                ,\n",
    "            {\n",
    "                \"role\": \"user\", \"content\":[\n",
    "\n",
    "            \"These are the frames from a video.\",\n",
    "            *map(lambda x: {\"type\": \"image_url\", \n",
    "                \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}},frames[modelname]),    \n",
    "                \"Describe the provided frames within 20 words, highlight all the object class's attributes that appear in the frames.\"\n",
    "            ],\n",
    "                }\n",
    "            ]\n",
    "            request['body']['messages'] = messages\n",
    "            requests.append(request)\n",
    "\n",
    "    with open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"w\") as f:\n",
    "        for entry in requests:\n",
    "            json_line = json.dumps(entry)\n",
    "            f.write(json_line + '\\n')\n",
    "    \n",
    "    batch_input_file = client.files.create(\n",
    "             file=open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"rb\"),\n",
    "              purpose=\"batch\"\n",
    "             )\n",
    "\n",
    "    batch_input_file_id = batch_input_file.id    \n",
    "\n",
    "    batch_object = client.batches.create(\n",
    "            input_file_id=batch_input_file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "            metadata={\n",
    "            \"description\": \"nightly group1 {} eval job batch {}\".format(dimension,batch_id)\n",
    "            }\n",
    "                                        )\n",
    "    \n",
    "    batch_split_ids.append(batch_id)\n",
    "    batch_unique_ids.append(batch_object.id)\n",
    "\n",
    "    print(\"Thread {} is done\".format(batch_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 = list(range(1,len(human_anno),3))\n",
    "# l2 = list(range(2,len(human_anno),3))\n",
    "# l3 = list(range(0,len(human_anno),3))\n",
    "l = list(range(0,len(human_anno)))\n",
    "\n",
    "\n",
    "ls = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 0 is running\n",
      "Thread 1 is running\n",
      "Thread 2 is running\n",
      "Thread 3 is running\n",
      "Thread 4 is running\n",
      "Thread 5 is running\n",
      "Thread 6 is running\n",
      "Thread 7 is running\n",
      "Thread 8 is running\n",
      "Thread 9 is running\n",
      "Thread 10 is running\n",
      "Thread 11 is running\n",
      "Thread 12 is running\n",
      "Thread 13 is running\n",
      "Thread 14 is running\n",
      "Thread 15 is running\n",
      "All threads started\n",
      "Thread 15 is done\n",
      "Thread 8 is done\n",
      "Thread 5 is done\n",
      "Thread 7 is done\n",
      "Thread 6 is done\n",
      "Thread 12 is done\n",
      "Thread 9 is done\n",
      "Thread 13 is done\n",
      "Thread 3 is done\n",
      "Thread 0 is done\n",
      "Thread 2 is done\n",
      "Thread 14 is done\n",
      "Thread 1 is done\n",
      "Thread 10 is done\n",
      "Thread 11 is done\n",
      "Thread 4 is done\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "batch_size = 15\n",
    "batches = [ls[i:i + batch_size] for i in range(0, len(ls), batch_size)]\n",
    "\n",
    "threads = []\n",
    "for i, batch in enumerate(batches):\n",
    "    if i in batch_split_ids:\n",
    "        continue\n",
    "    thread = threading.Thread(target=eval_batch_onebyone, args=(batch, i))\n",
    "    threads.append(thread)      \n",
    "    thread.start()\n",
    "\n",
    "print(\"All threads started\")\n",
    "# 等待所有线程完成\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "#保存batch信息\n",
    "with open(\"./batch_infos/batch_info_{}_combench_description.json\".format(dimension), \"w\") as f:\n",
    "    json.dump({\"batch_unique_ids\": batch_unique_ids, \"batch_split_ids\": batch_split_ids,\"videos_in_batch\":batches}, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id:batch_67337f7e3d4481909fcc34f74887a6ca status:in_progress descrepition:nightly group1 object_class eval job batch 15\n",
      "id:batch_67338058b1b48190961d0909e63d5170 status:in_progress descrepition:nightly group1 object_class eval job batch 8\n",
      "id:batch_6733807bbe7481909ccf1960531dab5a status:in_progress descrepition:nightly group1 object_class eval job batch 5\n",
      "id:batch_673380a4c5988190b8a83fc3619d256a status:in_progress descrepition:nightly group1 object_class eval job batch 7\n",
      "id:batch_673380abab4c819098e43b2519e81e07 status:in_progress descrepition:nightly group1 object_class eval job batch 6\n",
      "id:batch_673380e9a114819091a9b6808c42f9bd status:in_progress descrepition:nightly group1 object_class eval job batch 12\n",
      "id:batch_67338118a8ac81909ef94220a98e5225 status:in_progress descrepition:nightly group1 object_class eval job batch 9\n",
      "id:batch_67338124ff648190be1d3cd2ba95802a status:in_progress descrepition:nightly group1 object_class eval job batch 13\n",
      "id:batch_67338142412481908b61cecf21769994 status:in_progress descrepition:nightly group1 object_class eval job batch 3\n",
      "id:batch_6733814728d4819083ac39eb09932432 status:in_progress descrepition:nightly group1 object_class eval job batch 0\n",
      "id:batch_67338147cca8819081bd894a2f012077 status:in_progress descrepition:nightly group1 object_class eval job batch 2\n",
      "id:batch_6733815248d881909129874f87abe341 status:in_progress descrepition:nightly group1 object_class eval job batch 14\n",
      "id:batch_6733815cae9c8190bea4bb8fa6431ce8 status:in_progress descrepition:nightly group1 object_class eval job batch 1\n",
      "id:batch_67338169304c8190a26e2121dad8c497 status:in_progress descrepition:nightly group1 object_class eval job batch 10\n",
      "id:batch_6733816f46dc819081ed2b3df0c56d2d status:in_progress descrepition:nightly group1 object_class eval job batch 11\n",
      "id:batch_67338178c1608190a68abedfeffab9a4 status:in_progress descrepition:nightly group1 object_class eval job batch 4\n"
     ]
    }
   ],
   "source": [
    "with open(\"./batch_infos/batch_info_{}_combench_description.json\".format(dimension), \"r\") as f:\n",
    "    batch_info = json.load(f)\n",
    "\n",
    "    \n",
    "batchids = batch_info[\"batch_unique_ids\"]\n",
    "# llmeval_path = \"./GPT4o_eval_results/{}/combench/{}_combench_description.json\".format(dimension,dimension)\n",
    "\n",
    "# with open(llmeval_path, \"r\") as f:\n",
    "#     llmeval = json.load(f)\n",
    "    \n",
    "# for i in ls:\n",
    "#     if str(i) not in llmeval.keys():\n",
    "#          llmeval[str(i)] = {}\n",
    "\n",
    "for id in batchids:\n",
    "    batch_object = client.batches.retrieve(id)\n",
    "    print(\"id:{} status:{} descrepition:{}\".format(id,batch_object.status,batch_object.metadata['description']))\n",
    "\n",
    "    # if batch_object.status != \"completed\":\n",
    "    #     print(\"batch {} is not completed\".format(id))\n",
    "    #     continue    \n",
    "\n",
    "    # file_response = client.files.content(batch_object.output_file_id)\n",
    "    # for line in file_response.text.splitlines():\n",
    "\n",
    "        \n",
    "    #     # index = json.loads(line)[\"custom_id\"].split(\"-\")[-3]\n",
    "    #     # model = json.loads(line)[\"custom_id\"].split(\"-\")[-2]\n",
    "    #     # frameid = json.loads(line)[\"custom_id\"].split(\"-\")[-1]\n",
    "\n",
    "    #     index = json.loads(line)[\"custom_id\"].split(\"-\")[-2]\n",
    "    #     model = json.loads(line)[\"custom_id\"].split(\"-\")[-1]\n",
    "\n",
    "    #     # index = json.loads(line)[\"custom_id\"].split(\"-\")[-1]\n",
    "\n",
    "    #     eval_res = json.loads(line)[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"].replace('\\n\\n','\\n')\n",
    "        \n",
    "    #     # if model not in llmeval[index].keys():\n",
    "    #     #     llmeval[index][model] = {}\n",
    "    #     # llmeval[index][model][frameid] = eval_res\n",
    "        \n",
    "    #     llmeval[index][model] = eval_res\n",
    "    #     # llmeval[index] = eval_res\n",
    "    # with open(llmeval_path, \"w\") as f:\n",
    "    #     json.dump(llmeval, f, indent=4)\n",
    "\n",
    "    # print(\"batch {} done,end index {}\".format(id,index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
