{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prepath = \"../../data4dimensions/Prompts4dimensions/\"\n",
    "dimensions = ['action','color','scene','object_class','overall_consistency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import base64\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image\n",
    "# from io import BytesIO\n",
    "\n",
    "# video = cv2.VideoCapture(r'D:\\AStudying\\AI\\Niii_1\\hopes\\data4dimensions\\overall_consistency\\gen3\\A cat wearing sunglasses at a pool_0.mp4')\n",
    "\n",
    "# if not video.isOpened():\n",
    "#     print(f\"Error: Cannot open video file \")\n",
    "\n",
    "# total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# fps = video.get(cv2.CAP_PROP_FPS)\n",
    "# frames_to_skip = int(fps/8)\n",
    "# print(f\"Total frames: {total_frames}, FPS: {fps}, Frames to skip: {frames_to_skip}\")\n",
    "# base64Frames = []\n",
    "# frames = []\n",
    "# curr_frame=1\n",
    "# end_frame = total_frames - 1\n",
    "# # Loop through the video and extract frames at specified sampling rate\n",
    "# while curr_frame < total_frames - 1:\n",
    "#     video.set(cv2.CAP_PROP_POS_FRAMES, curr_frame)\n",
    "#     curr_frame += frames_to_skip\n",
    "#     success, frame = video.read()\n",
    "#     if not success:\n",
    "#         break\n",
    "#     frames.append(frame)\n",
    "#     if len(frames) == 8:\n",
    "#         height, width, _ = frames[0].shape\n",
    "\n",
    "#         # 创建一个空白图像用于网格\n",
    "#         grid_image = np.zeros(( 2*height, 4 * width, 3))\n",
    "\n",
    "#         # 将帧放置到网格中\n",
    "#         for i in range(2):\n",
    "#             for j in range(4):\n",
    "#                 grid_image[i * height:(i + 1) * height, j * width:(j + 1) * width] = frames[i * 4 + j]\n",
    "\n",
    "#         _, buffer = cv2.imencode(\".jpg\", grid_image)\n",
    "#         base64Frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
    "#         frames = []\n",
    "\n",
    "\n",
    "# video.release()\n",
    "\n",
    "# for idx, base64_image in enumerate(base64Frames):\n",
    "#     # 解码 base64 编码的图片\n",
    "#     img_data = base64.b64decode(base64_image)\n",
    "#     np_arr = np.frombuffer(img_data, np.uint8)\n",
    "#     img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
    "\n",
    "#     # 将图像转换为RGB格式\n",
    "#     img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#     # 将图像转换为PIL格式\n",
    "#     pil_img = Image.fromarray(img_rgb)\n",
    "\n",
    "#     # 在Jupyter Notebook中显示图像\n",
    "#     display(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import base64\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image\n",
    "# from io import BytesIO\n",
    "\n",
    "# video = cv2.VideoCapture(\"../../data4dimensions/overall_consistency/lavie/Pacific coast, carmel by the sea ocean and waves._0.mp4\")\n",
    "\n",
    "# if not video.isOpened():\n",
    "#     print(f\"Error: Cannot open video file \")\n",
    "\n",
    "# total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# fps = video.get(cv2.CAP_PROP_FPS)\n",
    "# frames_to_skip = int(fps/2)\n",
    "# print(f\"Total frames: {total_frames}, FPS: {fps}, Frames to skip: {frames_to_skip}\")\n",
    "# base64Frames = []\n",
    "# frames = []\n",
    "# curr_frame=1\n",
    "# end_frame = total_frames - 1\n",
    "# # Loop through the video and extract frames at specified sampling rate\n",
    "# while curr_frame < total_frames - 1:\n",
    "#     video.set(cv2.CAP_PROP_POS_FRAMES, curr_frame)\n",
    "#     curr_frame += frames_to_skip\n",
    "#     success, frame = video.read()\n",
    "#     if not success:\n",
    "#         break\n",
    "\n",
    "#     _, buffer = cv2.imencode(\".jpg\", frame)\n",
    "#     base64Frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
    "\n",
    "\n",
    "\n",
    "# video.release()\n",
    "\n",
    "# for idx, base64_image in enumerate(base64Frames):\n",
    "#     # 解码 base64 编码的图片\n",
    "#     img_data = base64.b64decode(base64_image)\n",
    "#     np_arr = np.frombuffer(img_data, np.uint8)\n",
    "#     img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
    "\n",
    "#     # 将图像转换为RGB格式\n",
    "#     img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#     # 将图像转换为PIL格式\n",
    "#     pil_img = Image.fromarray(img_rgb)\n",
    "\n",
    "#     # 在Jupyter Notebook中显示图像\n",
    "#     display(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import base64\n",
    "\n",
    "# # 定义保存base64编码图片的函数\n",
    "# datapath = \"./fewshot_examples/imaging_quality/\"\n",
    "# for file in os.listdir(datapath):\n",
    "#     if file.endswith(\".png\") or file.endswith(\".jpg\"):\n",
    "#         image_path = datapath + file\n",
    "#         output_path = datapath + file.split(\".\")[0] + \".txt\"\n",
    "#         with open(image_path, \"rb\") as image_file:\n",
    "#             encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "#         with open(output_path, \"w\") as output_file:\n",
    "#             output_file.write(encoded_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # process the e4e eval results\n",
    "# import os \n",
    "# import json\n",
    "# dimension = 'imaging_quality'\n",
    "# e4eval_path = r\".\\GPT4o_eval_results\\{}\\{}_multillmeval_3.json\".format(dimension, dimension)\n",
    "# e4eval = json.load(open(e4eval_path, \"r\"))\n",
    "# e4eval2model = {}\n",
    "\n",
    "# for key in e4eval:\n",
    "#     e4eval2model[key] = {}\n",
    "#     modelevals = e4eval[key].split(\"\\n\")[1:]\n",
    "#     for line in modelevals:\n",
    "#         line = line.replace(\"**\",'')\n",
    "#         modelname = line.split(\" \")[1][:-1]\n",
    "#         e4eval2model[key][modelname] = line\n",
    "# with open(r\".\\GPT4o_eval_results\\{}\\{}_multillmeval2model_3.json\".format(dimension, dimension), \"w\") as f:\n",
    "#     json.dump(e4eval2model, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from openai import OpenAI\n",
    "# import openai\n",
    "# from tool import videoreader\n",
    "# # 创建一个OpenAI客户端实例\n",
    "# client = OpenAI(\n",
    "#     api_key=\"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\",\n",
    "#     base_url=\"https://gateway.ai.cloudflare.com/v1/627f1b1f372e3a198dc32573bbc6f720/openai-gpt/openai\"  # 替换为你的自定义API域\n",
    "# )\n",
    "\n",
    "# ## Set the API key and model name\n",
    "# MODEL=\"gpt-4o-2024-08-06\"\n",
    "\n",
    "# filels = []\n",
    "# for i in client.files.list():\n",
    "#     filels.append(i)\n",
    "# for i in range(len(filels)-1,int(len(filels)/3),-1):\n",
    "#     client.files.delete(filels[i].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 转换稳定性格式\n",
    "# import json\n",
    "# with open('./GPT4o_eval_results\\imaging_quality\\imaging_quality_stability.json','r') as f:\n",
    "#     stability = json.load(f)\n",
    "\n",
    "# new_stability = []\n",
    "# models = ['cogvideox5b','kling', 'gen3','videocrafter2', 'pika', 'show1', 'lavie']\n",
    "\n",
    "# for i in range(len(stability[0].keys())):\n",
    "#     new_stability.append({'human_anno':{}})\n",
    "#     for model in models:\n",
    "#         new_stability[i]['human_anno'][model] = []\n",
    "#         for j in range(len(stability)):\n",
    "#             for index,key in enumerate(stability[j]):\n",
    "#                 if index == i:\n",
    "#                     new_stability[i]['human_anno'][model].append(stability[j][key][model])\n",
    "# with open('./GPT4o_eval_results\\imaging_quality\\imaging_quality_stability_new.json','w') as f:\n",
    "#     json.dump(new_stability,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "jsonpath = './Human_anno/stable/object_class.json'\n",
    "with open(jsonpath,'r') as f:\n",
    "    oc = json.load(f)\n",
    "\n",
    "jsonpath = './Human_anno/stable/object_class-2.json'\n",
    "with open(jsonpath,'r') as f:\n",
    "    oc_s = json.load(f)\n",
    "\n",
    "jsonpath = './Human_anno//stable/object_class-3.json'\n",
    "with open(jsonpath,'r') as f:\n",
    "    oc_s2 = json.load(f)\n",
    "\n",
    "ll = [oc,oc_s,oc_s2]\n",
    "\n",
    "new_stability = []\n",
    "models = ['cogvideox5b','kling', 'gen3','videocrafter2', 'pika', 'show1', 'lavie']\n",
    "\n",
    "l = list(range(0,len(oc),3))\n",
    "idexls = l\n",
    "length = len(idexls)\n",
    "for i in range(length):\n",
    "    new_stability.append({'human_anno':{}})\n",
    "    for model in models:\n",
    "        new_stability[i]['human_anno'][model] = []\n",
    "        for data in ll:\n",
    "            new_stability[i]['human_anno'][model].append(data[idexls[i]]['multiagent_score'][model])\n",
    "with open('./Human_anno/stable/object_class_new.json','w') as f:\n",
    "    json.dump(new_stability,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# action_ls = []\n",
    "\n",
    "# with open(r'D:\\Astudying\\VideoEval\\HighlyHumanLikeVEB\\baseline\\action\\results_human_action_cogvideox5b_eval_results.json','r') as f:\n",
    "#     action_base = json.load(f)\n",
    "# action_base = action_base['human_action'][1]\n",
    "\n",
    "# with open('./Human_anno/final/action.json','r') as f:\n",
    "#     oc = json.load(f)\n",
    "\n",
    "# for i in range(len(oc)):\n",
    "#     videoph = oc[i]['videos']['cogvideox5b'] \n",
    "#     for j in range(len(action_base)):\n",
    "#         if videoph== action_base[j]['video_path'] and videoph.split('/')[-1].split(' ')[1] == 'person' :\n",
    "#             action_ls.append(i)\n",
    "# print(action_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
