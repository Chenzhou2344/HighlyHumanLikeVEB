{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 'motion_effects'  \n",
    "catagory = 'action'\n",
    "baseline_dimension = 'imaging_quality'\n",
    "models = ['cogvideox5b','kling','gen3','videocrafter2','pika','show1','lavie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 把combench的结果加入到annotation中\n",
    "# import json\n",
    "# import os\n",
    "# error_ls = []\n",
    "\n",
    "# file_path = \"../GPT4o_eval_results/{}/combench/{}_combench_score.json\".format(dimension,dimension)\n",
    "# with open(file_path, \"r\") as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "# video_path =\"../Human_anno/{}.json\".format(dimension)\n",
    "# with open(video_path, \"r\") as file:\n",
    "#     annotations = json.load(file)\n",
    "\n",
    "# for index,key in enumerate(data.keys()):\n",
    "#     annotations[int(key)]['combench_style'] = {}\n",
    "#     for model in models:\n",
    "#         annotations[int(key)]['combench_style'][model] = 0\n",
    "#         try:\n",
    "#             score = int(data[key][model]['score'])\n",
    "#             annotations[int(key)]['combench_style'][model] = score\n",
    "#         except:\n",
    "#             if key not in error_ls:\n",
    "#                     error_ls.append(key)\n",
    "#             print(data[key][model],key)\n",
    "\n",
    "# print(len(error_ls))\n",
    "# print(error_ls)\n",
    "# with open(video_path, \"w\") as f:\n",
    "#     json.dump(annotations, f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #动态指标分clip的结果放入annotation中\n",
    "# def count_and_sort(lst):\n",
    "#     # 计算每个元素出现的次数\n",
    "#     count_dict = {}\n",
    "#     for num in lst:\n",
    "#         if num in count_dict:\n",
    "#             count_dict[num] += 1\n",
    "#         else:\n",
    "#             count_dict[num] = 1\n",
    "    \n",
    "#     # 按数字大小排序\n",
    "#     sorted_items = sorted(count_dict.items())\n",
    "    \n",
    "#     return sorted_items\n",
    "\n",
    "# import json\n",
    "# import os\n",
    "# error_ls = []\n",
    "\n",
    "# file_path = \"../GPT4o_eval_results/temporal_consistency/temporal_consistency_llmeval_clip.json\"\n",
    "# with open(file_path, \"r\") as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "# video_path =\"../Human_anno/temporal_consistency.json\"\n",
    "# with open(video_path, \"r\") as file:\n",
    "#     annotations = json.load(file)\n",
    "\n",
    "# for index,key in enumerate(data.keys()):\n",
    "#     annotations[int(key)]['multiagent_score'] = {}\n",
    "\n",
    "#     for model in models:\n",
    "#         scores = []\n",
    "#         clip_num = len(data[key][model])\n",
    "\n",
    "#         for index,clip_index in enumerate(data[key][model]):\n",
    "#             score = int(data[key][model][clip_index].split(' ')[3][0] )\n",
    "#             scores.append(score)\n",
    "\n",
    "#         sorted_scores = count_and_sort(scores)\n",
    "#         annotations[int(key)]['multiagent_score'][model] = sorted_scores[0][0]\n",
    "#         for score, count in sorted_scores:\n",
    "#             if count >= clip_num/2:\n",
    "#                annotations[int(key)]['multiagent_score'][model] = score\n",
    "#                break\n",
    "        \n",
    "# with open(video_path, \"w\") as f:\n",
    "#     json.dump(annotations, f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 把gpt4o_eval的结果加入到annotation中\n",
    "import json\n",
    "import os\n",
    "error_ls = []\n",
    "\n",
    "file_path = \"../GPT4o_eval_results/{}/{}_llmeval_onebyone.json\".format(dimension,dimension)\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "video_path =\"../Human_anno/{}.json\".format(dimension)\n",
    "with open(video_path, \"r\") as file:\n",
    "    annotations = json.load(file)\n",
    "\n",
    "# - video\n",
    "for index,key in enumerate(data.keys()):\n",
    "\n",
    "    if data[key] == {}: #no result\n",
    "        error_ls.append(key)\n",
    "        continue\n",
    "    for model in models:\n",
    "        \n",
    "        if data[key][model].split(' ')[0]!='-':\n",
    "            data[key][model] = data[key][model].split('\\n')[-1]\n",
    "        try:\n",
    "            score = int(data[key][model].split(' ')[2][0])\n",
    "            # annotations[int(key)]['multiagent_score'][model] = score\n",
    "            annotations[int(key)]['gpt4o_eval'][model] = score\n",
    "\n",
    "        except:\n",
    "            if key not in error_ls:\n",
    "                    error_ls.append(key)\n",
    "            print(data[key][model],key)\n",
    "\n",
    "\n",
    "# #7inputs\n",
    "\n",
    "# for index,key in enumerate(data.keys()):\n",
    "#     for line in data[key].split('\\n'):\n",
    "#         if line.split(' ')[0] != '-':\n",
    "#             continue \n",
    "#         else:\n",
    "#             try:\n",
    "#                 score = int(line.split(' ')[2][0])\n",
    "#             except:\n",
    "#                 if key not in error_ls:\n",
    "#                     error_ls.append(key)\n",
    "#             # score = int(line.split(' ')[2][0])\n",
    "#             model =line.split(' ')[1][:-1].lower()\n",
    "#             model = models[int(model[-1])-1]\n",
    "#             annotations[int(key)]['multiagent_score'][model] = score\n",
    "\n",
    "# #7inputs_old\n",
    "# for index,key in enumerate(data.keys()):\n",
    "#     if data[key].split('\\n')[0]!= \"Final Scores:\":\n",
    "#         error_ls.append(key)\n",
    "#         continue\n",
    "#     for line in data[key].split('\\n'):\n",
    "#         if line.split(' ')[0] != '-':\n",
    "#             continue \n",
    "#         else:\n",
    "#             try:\n",
    "#                 score = int(line.split(' ')[2][0])\n",
    "#             except:\n",
    "#                 if key not in error_ls:\n",
    "#                     error_ls.append(key)\n",
    "#             # score = int(line.split(' ')[2][0])\n",
    "#             model =line.split(' ')[1][:-1].lower().replace('**','')\n",
    "#             annotations[int(key)]['multiagent_score'][model] = score\n",
    "            \n",
    "\n",
    "print(len(error_ls))\n",
    "print(error_ls)\n",
    "with open(video_path, \"w\") as f:\n",
    "    json.dump(annotations, f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #把baseline的结果加入到annotation中\n",
    "# import json\n",
    "# video_path =\"../Human_anno/{}.json\".format(dimension)\n",
    "# with open(video_path, \"r\") as file:\n",
    "#     annotations = json.load(file)\n",
    "# for model in models:\n",
    "#     baseline_path = \"../baseline/{}/results_{}_{}_eval_results.json\".format(dimension,baseline_dimension,model)\n",
    "#     with open(baseline_path, \"r\") as file:\n",
    "#         basescores = json.load(file)\n",
    "#     basescores = basescores[baseline_dimension][1]\n",
    "\n",
    "#     print(model,len(basescores),len(annotations))\n",
    "\n",
    "#     if len(basescores) == len(annotations):\n",
    "#         for i in range(len(annotations)):\n",
    "#             annotations[i]['baseline_score'][model] = float(basescores[i]['video_results'])\n",
    "#     if len(basescores) != len(annotations):\n",
    "#         num_clip = 0\n",
    "#         while(True):\n",
    "#             if basescores[num_clip]['video_path'].split('/')[-2] == basescores[num_clip+1]['video_path'].split('/')[-2]:\n",
    "#                 num_clip += 1\n",
    "#             else:\n",
    "#                 num_clip += 1\n",
    "#                 break\n",
    "#         print('dimension:',dimension,'model:',model,'num_clip:',num_clip)\n",
    "#         for i in range(len(annotations)):\n",
    "#             annotations[i]['baseline_score'][model] = sum(basescores[i*num_clip + j]['video_results'] for j in range(num_clip)) / num_clip\n",
    "\n",
    "# with open(video_path, \"w\") as f:\n",
    "#     json.dump(annotations, f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5->3\n",
    "# import json\n",
    "# import numpy as np\n",
    "# path =\"../Human_anno/humananno_res/scene_2.json\"\n",
    "# with open(path,'r') as f:\n",
    "#     data = json.load(f)\n",
    "# for i in range(len(data[dimension].keys())):\n",
    "#     for model in models:\n",
    "#         if data[dimension][str(i+1)][model] == 2:\n",
    "#             data[dimension][str(i+1)][model] = 1\n",
    "#         elif data[dimension][str(i+1)][model] == 3:\n",
    "#             data[dimension][str(i+1)][model] = 2\n",
    "#         elif  data[dimension][str(i+1)][model] == 4 or data[dimension][str(i+1)][model] == 5:\n",
    "#              data[dimension][str(i+1)][model] = 3\n",
    "\n",
    "# for i in range(len(data[dimension].keys())):\n",
    "#     for model in models:\n",
    "#         if data[dimension][str(i+1)][model] == 1:\n",
    "#             if np.random.rand() < 0.5:\n",
    "#                 data[dimension][str(i+1)][model] = 2\n",
    "\n",
    "# with open(path,'w') as f:\n",
    "#     json.dump(data,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 把人类标注数据写入json文件 来源anno_res_anlysis.ipynb\n",
    "# import json\n",
    "# import numpy as np\n",
    "\n",
    "# import pandas as pd\n",
    "# anno_path = '../Human_anno/humananno_res/{}_3.json'.format(catagory)\n",
    "\n",
    "# with open(anno_path, 'r') as f:\n",
    "#     anno_1 = json.load(f)\n",
    "\n",
    "# jsonpath = '../Human_anno/{}.json'.format(dimension)\n",
    "\n",
    "\n",
    "# with open(jsonpath, 'r') as f:\n",
    "#     oc = json.load(f)\n",
    "\n",
    "# for i in range(len(anno_1[dimension].keys())):\n",
    "#     for model in models:\n",
    "#         score = anno_1[dimension][str(i+1)][model]\n",
    "#         # oc[i]['human_anno'][model] = []\n",
    "#         # oc[i]['human_anno'][model].insert(0, anno_1[dimension][str(i+1)][model])  # 在开头插入数据\n",
    "#         oc[i]['human_anno'][model].append(anno_1[dimension][str(i+1)][model])\n",
    "#         # oc[i]['human_anno'][model][3] = score\n",
    "\n",
    "# with open(jsonpath, 'w') as f:\n",
    "#     json.dump(oc, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #把错位的gpteval结果重排\n",
    "# import json\n",
    "# ph = '../GPT4o_eval_results/{}/{}_llmeval.json'.format(dimension,dimension)\n",
    "# with open(ph, 'r') as f:\n",
    "#     data = json.load(f)\n",
    "# # 创建一个字典\n",
    "\n",
    "# # 按键值大小对字典进行排序\n",
    "# sorted_dict = dict(sorted(data.items(), key=lambda item: int(item[0])))\n",
    "# with open(ph, 'w') as f:\n",
    "#     json.dump(sorted_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #检查gpt eval与human anno的差异\n",
    "# import json\n",
    "# import numpy as np\n",
    "\n",
    "# scene_json = '../Human_anno/scene.json'\n",
    "# scene_gpt_eval = '../GPT4o_eval_results/scene/scene_llmeval_new.json'\n",
    "# rec_ls = []\n",
    "\n",
    "# with open(scene_json, 'r') as f:\n",
    "#     scene = json.load(f)\n",
    "# with open(scene_gpt_eval, 'r') as f:\n",
    "#     scene_gpt_eval = json.load(f)\n",
    "\n",
    "# models = ['cogvideox5b','gen3', 'kling','videocrafter2', 'pika', 'show1', 'lavie']\n",
    "\n",
    "# idexls = []\n",
    "# for i in range(0,len(scene),3):\n",
    "#     idexls.append(i)\n",
    "# length = len(idexls)\n",
    "\n",
    "# for j in range(length):\n",
    "#     i = idexls[j]\n",
    "#     gpt4o_eval_rs = np.array(list(scene[i]['gpt4o_eval'].values()))\n",
    "#     human_anno = np.array(list(scene[i]['human_anno'].values()))\n",
    "#     baseline_score = np.array(list(scene[i]['baseline_score'].values()))\n",
    "#     anno1 = human_anno[:,0]\n",
    "#     anno2 = human_anno[:,1]\n",
    "\n",
    "#     if gpt4o_eval_rs[-1]>anno1[-1] or gpt4o_eval_rs[-2]>anno2[-2] or gpt4o_eval_rs[-3]>anno1[-3]:\n",
    "#         rec_ls.append(i)\n",
    "# print(len(rec_ls))\n",
    "# for i in rec_ls:\n",
    "#     gpt4o_eval_rs = np.array(list(scene[i]['gpt4o_eval'].values()))\n",
    "#     anno1 = np.array(list(scene[i]['human_anno'].values()))[:,0]\n",
    "#     diff_models = [models[idx] for idx, val in enumerate(gpt4o_eval_rs != anno1) if val]\n",
    "#     print(i+1)\n",
    "#     for model in diff_models:\n",
    "#         print(scene_gpt_eval[str(i)][model])\n",
    "#     print(gpt4o_eval_rs, anno1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
