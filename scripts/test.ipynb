{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 'scene'\n",
    "models = ['cogvideox5b','kling','gen3','lavie','pika','show1','videocrafter2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 把gpt4o_eval的结果加入到annotation中\n",
    "# import json\n",
    "# import os\n",
    "\n",
    "\n",
    "# file_path = \"../GPT4o_eval_results/{}/{}_llmeval_new.json\".format(dimension,dimension)\n",
    "# with open(file_path, \"r\") as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "# video_path =\"../Human_anno/{}.json\".format(dimension)\n",
    "# with open(video_path, \"r\") as file:\n",
    "#     annotations = json.load(file)\n",
    "\n",
    "# for index,key in enumerate(data.keys()):\n",
    "#     for model in models:\n",
    "#         try:\n",
    "#             score = int(data[key][model].split(' ')[3][0])\n",
    "#         except:\n",
    "#             print(data[key][model],key)\n",
    "#         annotations[int(key)]['gpt4o_eval'][model] = score\n",
    "\n",
    "# # for index,key in enumerate(data.keys()):\n",
    "# #     for line in data[key].split('\\n'):\n",
    "# #         if line.split(' ')[0] != '-':\n",
    "# #             continue \n",
    "# #         else:\n",
    "# #             try:\n",
    "# #                 score = int(line.split(' ')[2][0])\n",
    "# #             except:\n",
    "# #                 print(line,key)\n",
    "# #             # score = int(line.split(' ')[2][0])\n",
    "# #             model =line.split(' ')[1][:-1].lower().replace('**','')\n",
    "# #             annotations[int(key)]['gpt4o_eval'][model] = score\n",
    "\n",
    "# with open(video_path, \"w\") as f:\n",
    "#     json.dump(annotations, f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #把baseline的结果加入到annotation中\n",
    "# import json\n",
    "# video_path =\"../Human_anno/{}.json\".format(dimension)\n",
    "# with open(video_path, \"r\") as file:\n",
    "#     annotations = json.load(file)\n",
    "# for model in models:\n",
    "#     baseline_path = \"../baseline/{}/results_{}_{}_eval_results.json\".format(dimension,dimension,model)\n",
    "#     with open(baseline_path, \"r\") as file:\n",
    "#         basescores = json.load(file)\n",
    "#     basescores = basescores[dimension][1]\n",
    "#     for i in range(len(annotations)):\n",
    "#         annotations[i]['baseline_score'][model] = basescores[i]['video_results']\n",
    "\n",
    "# with open(video_path, \"w\") as f:\n",
    "#     json.dump(annotations, f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5->3\n",
    "# import json\n",
    "# path =\"../Human_anno/humananno_res/scene_2.json\"\n",
    "# with open(path,'r') as f:\n",
    "#     data = json.load(f)\n",
    "# for i in range(len(data[dimension].keys())):\n",
    "#     for model in models:\n",
    "#         if data[dimension][str(i+1)][model] == 2:\n",
    "#             data[dimension][str(i+1)][model] = 1\n",
    "#         elif data[dimension][str(i+1)][model] == 3:\n",
    "#             data[dimension][str(i+1)][model] = 2\n",
    "#         elif  data[dimension][str(i+1)][model] == 4 or data[dimension][str(i+1)][model] == 5:\n",
    "#              data[dimension][str(i+1)][model] = 3\n",
    "# with open(path,'w') as f:\n",
    "#     json.dump(data,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 把人类标注数据写入json文件 来源anno_res_anlysis.ipynb\n",
    "# import json\n",
    "\n",
    "# import pandas as pd\n",
    "# anno_path = '../Human_anno/humananno_res/scene_3.json'\n",
    "\n",
    "# with open(anno_path, 'r') as f:\n",
    "#     anno_1 = json.load(f)\n",
    "\n",
    "# jsonpath = '../Human_anno/{}.json'.format(dimension)\n",
    "\n",
    "\n",
    "# with open(jsonpath, 'r') as f:\n",
    "#     oc = json.load(f)\n",
    "\n",
    "# for i in range(len(anno_1[dimension].keys())):\n",
    "#     for model in models:\n",
    "#         # oc[i]['human_anno'][model].insert(0, anno_1[dimension][str(i+1)][model])  # 在开头插入数据\n",
    "#         # oc[i]['human_anno'][model].append(anno_1[dimension][str(i+1)][model])\n",
    "#         oc[i]['human_anno'][model][3] = anno_1[dimension][str(i+1)][model]\n",
    "\n",
    "# with open(jsonpath, 'w') as f:\n",
    "#     json.dump(oc, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##把错位的gpteval结果重排\n",
    "# import json\n",
    "# ph = r'D:\\AStudying\\AI\\Niii_1\\hopes\\codes\\HighlyHumanLikeVEB\\GPT4o_eval_results\\object_class\\object_class_llmeval.json'\n",
    "# with open(ph, 'r') as f:\n",
    "#     data = json.load(f)\n",
    "# # 创建一个字典\n",
    "\n",
    "# # 按键值大小对字典进行排序\n",
    "# sorted_dict = dict(sorted(data.items(), key=lambda item: int(item[0])))\n",
    "# with open(ph, 'w') as f:\n",
    "#     json.dump(sorted_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "4\n",
      "Final Scores:\n",
      "- Pika: 3, because the frames clearly depict an amusement park with recognizable elements such as a Ferris wheel, roller coasters, and other rides. The scene is complete and matches the typical features of an amusement park, allowing for easy recognition.\n",
      "Final Scores:\n",
      "- Lavie: 3, because the frames clearly depict an amusement park scene with recognizable elements such as a Ferris wheel and other rides. The scene is complete and matches the prompt well.\n",
      "[3 3 3 3 3 3 3] [3 3 3 3 2 3 2]\n",
      "7\n",
      "Final Scores:\n",
      "- cogvideox5b: 3, because the frames clearly depict an aquarium scene with vibrant coral, various fish, and a turtle, which aligns well with the prompt. The elements are recognizable and consistent with a typical aquarium environment.\n",
      "Final Scores:\n",
      "- Gen3: 3, because the frames clearly depict an aquarium scene with various fish and coral, matching the prompt. The underwater environment is recognizable and consistent with what one would expect in an aquarium setting.\n",
      "Final Scores:\n",
      "- videocrafter2: 3, because the video frames clearly depict an aquarium scene with various fish, plants, and rocks. The elements are consistent with what one would expect in an aquarium, and the scene is complete and recognizable.\n",
      "Final Scores:\n",
      "- Pika: 3, because the frames clearly depict an aquarium scene with various fish and coral, matching the prompt. The elements are consistent with what one would expect in an aquarium, and the scene is complete and recognizable.\n",
      "Final Scores:\n",
      "- show1 3, because the video clearly depicts an aquarium scene with multiple fish swimming in a tank. The environment is consistent with what one would expect in an aquarium, including the water, lighting, and fish, making it easily recognizable and complete.\n",
      "Final Scores:\n",
      "- Lavie: 3, because the frames clearly depict an aquarium scene with fish, plants, and water, which matches the prompt. The elements are consistent with what one would expect in an aquarium, and the scene is easily recognizable.\n",
      "[3 3 3 3 3 3 3] [1 2 3 2 2 1 2]\n",
      "10\n",
      "Final Scores:\n",
      "- Gen3: 3, because the video frames clearly depict a natural arch formation in a canyon-like setting. The arch is recognizable and consistent with the prompt, showing a complete scene with a sunset and birds, which enhances the natural arch environment.\n",
      "Final Scores:\n",
      "- Lavie: 3, because the frames clearly depict an arch structure, which is consistent with the prompt. The arch is recognizable and matches the human understanding of an arch, despite being partially obscured by trees.\n",
      "[3 3 3 3 2 1 3] [3 2 3 3 2 1 2]\n",
      "16\n",
      "Final Scores:\n",
      "- Show1: 2, because the video frames depict a bathtub with a towel, which is a recognizable part of a bathroom. However, the scene is limited to just the bathtub area, lacking other typical bathroom elements like a sink or toilet, which would provide a more complete representation of a bathroom.\n",
      "Final Scores:\n",
      "- Lavie: 3, because the frames clearly depict a bathroom scene with recognizable elements such as a sink, mirror, towel rack, and tiled walls. The scene is complete and matches the typical understanding of a bathroom.\n",
      "[3 3 3 3 3 2 3] [3 3 3 3 3 3 2]\n",
      "25\n",
      "[3 3 3 3 3 3 3] [3 3 3 3 3 3 3]\n",
      "31\n",
      "Final Scores:\n",
      "- Lavie: 3, because the frames clearly depict a basement setting with elements like stone walls, wooden beams, and a dimly lit environment, which are consistent with the prompt \"Basement.\" The scene is complete and recognizable.\n",
      "[3 3 3 3 2 3 3] [3 3 3 3 2 3 2]\n",
      "46\n",
      "Final Scores:\n",
      "- Kling: 2, because the video shows a variety of food items on a table, which is consistent with a cafeteria setting. However, it lacks other typical cafeteria elements like trays, serving stations, or people, making the scene only partially representative of a full cafeteria environment.\n",
      "Final Scores:\n",
      "- Videocrafter2: 3, because the scene clearly depicts a cafeteria setting with tables, chairs, and a serving area. The elements are consistent with what one would expect in a cafeteria, and the scene is complete and recognizable.\n",
      "Final Scores:\n",
      "- Pika: 3, because the frames clearly depict a cafeteria setting with tables, chairs, and a serving area. The scene is complete and matches the typical understanding of a cafeteria.\n",
      "Final Scores:\n",
      "- A: 3, because the video clearly depicts a cafeteria setting with tables, chairs, and a spacious layout, which matches the prompt and is easily recognizable.\n",
      "</output format>\n",
      "Final Scores:\n",
      "- Lavie: 3, because the frames clearly depict a cafeteria setting with tables, chairs, and a typical cafeteria layout. The scene is complete and matches the prompt well, allowing for easy recognition of the environment as a cafeteria.\n",
      "[3 3 2 3 3 3 3] [3 3 1 2 2 2 2]\n",
      "52\n",
      "Final Scores:\n",
      "- Show1: 2, because the scene depicts a futuristic or abstract architectural setting that could be interpreted as a campus. However, it lacks traditional campus elements like buildings, students, or educational facilities, making it only moderately consistent with the prompt.\n",
      "[3 3 3 3 3 2 3] [3 3 3 3 3 1 3]\n",
      "58\n",
      "[3 3 3 3 3 3 3] [3 3 3 3 3 3 3]\n",
      "64\n",
      "Final Scores:\n",
      "- Lavie: 3, because the frames clearly depict a classroom setting with desks and a board, which matches the prompt. The scene is complete and recognizable as a classroom.\n",
      "[3 3 3 3 3 3 3] [3 3 3 3 3 3 2]\n",
      "67\n",
      "Final Scores:\n",
      "- Pika: 3, because the frames clearly depict a cliff with distinct rock formations and vegetation, matching the prompt. The scene is complete and recognizable, aligning with human perception of a cliff.\n",
      "</output format>\n",
      "Final Scores:\n",
      "- Lavie: 3, because the frames clearly depict a cliff with detailed rock formations and a body of water below, matching the prompt accurately and recognizably.\n",
      "[3 3 3 3 3 3 3] [3 3 3 3 1 3 2]\n",
      "70\n",
      "Final Scores:\n",
      "- Videocrafter2: 3, because the frames clearly depict a crosswalk with recognizable white stripes on a road, matching the prompt accurately and completely.\n",
      "Final Scores:\n",
      "- Pika: 2, because the frames show a road with some lines that could suggest a crosswalk, but the typical features of a crosswalk, such as clear pedestrian markings, are not fully visible. The scene is somewhat recognizable but not completely accurate.\n",
      "Final Scores:\n",
      "- Lavie: 3, because the frames clearly depict a crosswalk with visible white lines on the road, which matches the prompt. The scene is complete and recognizable.\n",
      "</output format>\n",
      "[3 3 3 3 2 3 3] [3 3 3 2 1 3 2]\n",
      "73\n",
      "Final Scores:\n",
      "- Lavie: 3, because the frames clearly depict a construction site with visible scaffolding, unfinished structures, and building materials, which align well with the prompt. The scene is complete and recognizable.\n",
      "[3 3 3 3 3 3 3] [3 3 3 3 3 3 2]\n",
      "79\n",
      "Final Scores:\n",
      "- Pika: 3, because the video clearly depicts a courtyard with all the expected elements such as surrounding buildings, outdoor furniture, and greenery. The scene is complete and matches the prompt accurately.\n",
      "Final Scores:\n",
      "- Show1: 3, because the frames clearly depict a courtyard with a grassy area, surrounding walls, and a building with arches, which matches the prompt. The scene is complete and recognizable as a courtyard.\n",
      "Final Scores:\n",
      "- Lavie: 3, because the frames clearly depict a courtyard scene with architectural elements and greenery that align well with the prompt. The scene is complete and recognizable, matching the human understanding of a courtyard.\n",
      "[3 3 3 3 3 3 3] [3 3 3 3 1 2 1]\n",
      "91\n",
      "Final Scores:\n",
      "- Kling: 3, because the video clearly depicts a farm scene with recognizable elements such as green fields, barns, and grazing animals. The scene is complete and matches the typical understanding of a farm.\n",
      "Final Scores:\n",
      "- Pika: 2, because the frames show a part of a barn-like structure, which is a recognizable element of a farm. However, the scene is limited to just the roof and upper part of the building, lacking other typical farm elements like fields, animals, or equipment.\n",
      "Final Scores:\n",
      "- Lavie: 3, because the frames clearly depict a farm scene with fields, a distant barn, and open land, which matches the prompt and is consistent with human perception of a farm.\n",
      "[3 3 3 3 2 2 3] [3 3 1 3 1 2 2]\n",
      "94\n",
      "Final Scores:\n",
      "- Pika: 2, because the video shows a recognizable food court setting with tables and people in the background. However, the focus is primarily on a food display, and the broader food court environment is not fully depicted. The scene is similar but not completely accurate to a typical food court.\n",
      "</output format>\n",
      "Final Scores:\n",
      "- Lavie: 3, because the frames clearly depict a bustling food court with various food stalls, people walking, and a vibrant atmosphere. The scene is complete and matches the prompt well.\n",
      "[3 3 3 3 2 3 3] [3 3 3 3 3 3 2]\n",
      "106\n",
      "Final Scores:\n",
      "- Lavie: 3, because the frames clearly depict a gas station scene with visible fuel pumps, which matches the prompt. The elements are recognizable and consistent with the concept of a gas station.\n",
      "[3 3 3 3 3 3 3] [3 3 3 3 3 3 2]\n",
      "142\n",
      "[3 3 3 3 3 3 3] [3 3 3 3 3 3 3]\n",
      "157\n",
      "Final Scores:\n",
      "- Pika: 2, because the video shows a close-up of marsh vegetation, which is a recognizable element of a marsh. However, the scene is limited to a single plant and sky, lacking the broader context typically associated with a marsh environment, such as water or a variety of plant life.\n",
      "Final Scores:\n",
      "- Show1: 3, because the frames clearly depict a marsh scene with tall grasses and a flat landscape, which matches the prompt. The scene is complete and recognizable, aligning well with the human understanding of a marsh.\n",
      "Final Scores:\n",
      "- Lavie: 2, because the frames show a grassy area, which is somewhat consistent with a marsh environment. However, the scene lacks water or other typical marsh features, making it only moderately consistent with the prompt.\n",
      "[3 3 3 3 2 3 2] [3 3 3 3 1 2 1]\n",
      "163\n",
      "Final Scores:\n",
      "- Show1: 3, because the frames clearly depict an indoor movie theater with rows of comfortable seating, which matches the prompt. The scene is complete and recognizable, aligning with the typical appearance of a movie theater.\n",
      "Final Scores:\n",
      "- Lavie: 3, because the frames clearly depict an indoor movie theater with rows of red seats, a large screen, and appropriate lighting, matching the prompt accurately.\n",
      "[3 3 3 3 3 3 3] [3 3 3 3 3 2 2]\n",
      "166\n",
      "Final Scores:\n",
      "- Gen3: 3, because the frames clearly depict an indoor museum setting. The architecture, lighting, and presence of a central statue are consistent with typical museum interiors. The scene is complete and recognizable, matching the prompt effectively.\n",
      "Final Scores:\n",
      "- Kling: 2, because the frames depict a long hallway with display cases, which could be part of a museum. However, the setting resembles more of a shopping arcade or gallery rather than a traditional indoor museum. The architectural elements and display cases are present, but the overall scene does not fully align with the typical expectation of a museum.\n",
      "Final Scores:\n",
      "- videocrafter2: 3, because the scene clearly depicts an indoor museum with framed artworks on the walls, a person observing the art, and a well-lit gallery space. The elements are consistent with the prompt and recognizable as a museum setting.\n",
      "Final Scores:\n",
      "- Show1: 3, because the frames clearly depict an indoor museum setting. The architecture, lighting, and presence of artwork on the walls are consistent with a museum environment, and the scene is complete and recognizable.\n",
      "Final Scores:\n",
      "- Lavie: 3, because the frames clearly depict an indoor museum setting with various artworks and exhibits displayed on the walls, matching the prompt well. The scene is complete and recognizable as a museum.\n",
      "[3 3 2 3 3 3 3] [3 2 3 2 3 2 1]\n",
      "181\n",
      "Final Scores:\n",
      "- Show1: 3, because the frames clearly depict a palace with recognizable architectural features, such as a grand building with a symmetrical design, large windows, and a formal garden setting. The scene is complete and matches the typical human understanding of a palace.\n",
      "Final Scores:\n",
      "- Lavie: 2, because the frames show a structure that resembles part of a palace, such as a grand entrance or facade. However, the scene is limited to this single element, and the full concept of a palace is not fully represented.\n",
      "[3 3 3 3 3 3 2] [3 3 3 3 3 2 1]\n",
      "190\n",
      "Final Scores:\n",
      "- Pika: 2, because the video frames depict structures resembling phone booths, but the text on the booths is incorrect, which affects the overall recognition. The scene is recognizable as a phone booth, but the details are not completely accurate.\n",
      "Final Scores:\n",
      "- Lavie: 2, because the frames depict a structure resembling a phone booth, but the text \"PIEPPPONE\" is incorrect, which affects the overall recognition. The booth's design is recognizable, but the text inconsistency prevents a perfect match.\n",
      "[3 3 3 3 2 3 2] [3 3 3 3 3 3 1]\n",
      "193\n",
      "Final Scores:\n",
      "- Kling: 3, because the frames clearly depict a raceway with visible tracks, surrounding infrastructure, and a layout consistent with a racing circuit. The scene is complete and matches the prompt well.\n",
      "Final Scores:\n",
      "- videocrafter2: 3, because the frames clearly depict a raceway with visible tracks and barriers, matching the prompt. The scene is complete and recognizable as a raceway.\n",
      "Final Scores:\n",
      "- Pika: 3, because the frames clearly depict a raceway with distinct tracks, curves, and surrounding areas that match the concept of a raceway. The scene is complete and recognizable, aligning well with the prompt.\n",
      "Final Scores:\n",
      "- Lavie: 3, because the frames clearly depict a raceway with visible lanes and barriers, matching the prompt and allowing for easy recognition of the scene.\n",
      "[3 3 3 3 3 3 3] [3 3 2 2 2 3 2]\n",
      "205\n",
      "Final Scores:\n",
      "- Videocrafter2: 3, because the frames clearly depict a shower with water flowing, matching the prompt. The scene is complete and recognizable, with all necessary elements present.\n",
      "Final Scores:\n",
      "- Show1: 3, because the frames clearly depict a shower with water flowing from a showerhead, which matches the prompt. The scene is complete and recognizable, aligning with the human understanding of a shower.\n",
      "Final Scores:\n",
      "- Lavie: 3, because the frames clearly depict a shower with water flowing from the showerhead, which matches the prompt. The scene is complete and recognizable, aligning with human subjective understanding of a shower.\n",
      "[3 3 3 3 2 3 3] [3 3 3 2 2 2 2]\n",
      "211\n",
      "Final Scores:\n",
      "- cogvideox5b: 3, because the frames effectively depict various aspects of the sky, transitioning from a bright blue sky with clouds to a colorful sunset and finally to a starry night sky. This progression captures the essence of the prompt \"Sky\" and is consistent with human perception of different sky scenes throughout the day.\n",
      "Final Scores:\n",
      "- Gen3: 3, because the video frames clearly depict a sky scene with various elements such as clouds, birds, and the sun. The scene is complete and recognizable, matching the prompt effectively.\n",
      "Final Scores:\n",
      "- Kling: 3, because the frames consistently depict a clear blue sky with clouds, which matches the prompt \"Sky\" accurately. The scene is complete and easily recognizable.\n",
      "Final Scores:\n",
      "- Pika: 2, because the video frames depict a sky, but the focus is more on the landscape with roads and mountains. The sky is present and recognizable, but it is not the central element, which slightly detracts from the prompt's focus.\n",
      "Final Scores:\n",
      "- Show1: 3, because the frames clearly depict a sky with clouds, matching the prompt. The scene is complete and recognizable, aligning with human perception of a sky.\n",
      "</output format>\n",
      "Final Scores:\n",
      "- Lavie: 3, because the frames clearly depict a sky with clouds, matching the prompt accurately and completely. The scene is easily recognizable and consistent with the concept of a sky.\n",
      "[3 3 3 1 2 3 3] [1 1 2 1 3 1 1]\n",
      "223\n",
      "Final Scores:\n",
      "- videocrafter2: 3, because the frames clearly depict a street scene with visible houses, cars, and a road. The elements are consistent with the prompt and recognizable as a street environment.\n",
      "[3 3 3 3 3 3 3] [3 3 3 2 3 3 3]\n",
      "226\n",
      "Final Scores:\n",
      "- Show1: 2, because the frames depict shelves with various items that resemble products typically found in a supermarket, such as bottles and packages. However, the scene is somewhat abstract and lacks clarity, making it difficult to identify specific supermarket elements. The general idea of a supermarket is present, but not all features are clearly recognizable.\n",
      "[3 3 3 3 3 2 3] [3 3 3 3 3 1 3]\n",
      "247\n",
      "Final Scores:\n",
      "- Show1: 3, because the frames clearly depict a valley with rolling hills, open skies, and distant mountains, which matches the prompt \"Valley\" and aligns with human perception of such a landscape.\n",
      "[3 3 3 3 2 3 3] [3 3 3 3 2 2 3]\n"
     ]
    }
   ],
   "source": [
    "#检查gpt eval与human anno的差异\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "scene_json = '../Human_anno/scene.json'\n",
    "scene_gpt_eval = '../GPT4o_eval_results/scene/scene_llmeval_new.json'\n",
    "rec_ls = []\n",
    "\n",
    "with open(scene_json, 'r') as f:\n",
    "    scene = json.load(f)\n",
    "with open(scene_gpt_eval, 'r') as f:\n",
    "    scene_gpt_eval = json.load(f)\n",
    "\n",
    "models = ['cogvideox5b','gen3', 'kling','videocrafter2', 'pika', 'show1', 'lavie']\n",
    "\n",
    "idexls = []\n",
    "for i in range(0,len(scene),3):\n",
    "    idexls.append(i)\n",
    "length = len(idexls)\n",
    "\n",
    "for j in range(length):\n",
    "    i = idexls[j]\n",
    "    gpt4o_eval_rs = np.array(list(scene[i]['gpt4o_eval'].values()))\n",
    "    human_anno = np.array(list(scene[i]['human_anno'].values()))\n",
    "    baseline_score = np.array(list(scene[i]['baseline_score'].values()))\n",
    "    anno1 = human_anno[:,0]\n",
    "    anno2 = human_anno[:,1]\n",
    "\n",
    "    if gpt4o_eval_rs[-1]>anno1[-1] or gpt4o_eval_rs[-2]>anno2[-2] or gpt4o_eval_rs[-3]>anno1[-3] or gpt4o_eval_rs[-4]>anno2[-4]:\n",
    "        rec_ls.append(i)\n",
    "print(len(rec_ls))\n",
    "for i in rec_ls:\n",
    "    gpt4o_eval_rs = np.array(list(scene[i]['gpt4o_eval'].values()))\n",
    "    anno1 = np.array(list(scene[i]['human_anno'].values()))[:,0]\n",
    "    diff_models = [models[idx] for idx, val in enumerate(gpt4o_eval_rs != anno1) if val]\n",
    "    print(i+1)\n",
    "    for model in diff_models:\n",
    "        print(scene_gpt_eval[str(i)][model])\n",
    "    print(gpt4o_eval_rs, anno1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
