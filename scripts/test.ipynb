{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 'motion_effects'\n",
    "data_categories = 'action'\n",
    "models = ['cogvideox5b','kling','gen3','lavie','pika','show1','videocrafter2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 把gpt4o_eval的结果加入到annotation中\n",
    "# import json\n",
    "# import os\n",
    "\n",
    "\n",
    "# file_path = \"../GPT4o_eval_results/{}/{}_llmeval.json\".format(dimension,dimension)\n",
    "# with open(file_path, \"r\") as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "# video_path =\"../Human_anno/{}.json\".format(dimension)\n",
    "# with open(video_path, \"r\") as file:\n",
    "#     annotations = json.load(file)\n",
    "\n",
    "# # for index,key in enumerate(data.keys()):\n",
    "# #     for model in models:\n",
    "# #         try:\n",
    "# #             score = int(data[key][model].split(' ')[3][0])\n",
    "# #         except:\n",
    "# #             print(data[key][model],key)\n",
    "# #         annotations[int(key)]['gpt4o_eval'][model] = score\n",
    "\n",
    "# for index,key in enumerate(data.keys()):\n",
    "#     for line in data[key].split('\\n'):\n",
    "#         if line.split(' ')[0] != '-':\n",
    "#             continue \n",
    "#         else:\n",
    "#             try:\n",
    "#                 score = int(line.split(' ')[2][0])\n",
    "#             except:\n",
    "#                 print(line,key)\n",
    "#             # score = int(line.split(' ')[2][0])\n",
    "#             model =line.split(' ')[1][:-1].lower().replace('**','')\n",
    "#             annotations[int(key)]['gpt4o_eval'][model] = score\n",
    "\n",
    "# with open(video_path, \"w\") as f:\n",
    "#     json.dump(annotations, f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #把baseline的结果加入到annotation中\n",
    "# import json\n",
    "# video_path =\"../Human_anno/{}.json\".format(dimension)\n",
    "# with open(video_path, \"r\") as file:\n",
    "#     annotations = json.load(file)\n",
    "# for model in models:\n",
    "#     baseline_path = \"../baseline/{}/results_{}_{}_eval_results.json\".format(dimension,dimension,model)\n",
    "#     with open(baseline_path, \"r\") as file:\n",
    "#         basescores = json.load(file)\n",
    "#     basescores = basescores[dimension][1]\n",
    "#     for i in range(len(annotations)):\n",
    "#         annotations[i]['baseline_score'][model] = basescores[i]['video_results']\n",
    "\n",
    "# with open(video_path, \"w\") as f:\n",
    "#     json.dump(annotations, f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5->3\n",
    "# import json\n",
    "# import numpy as np\n",
    "# path =\"../Human_anno/humananno_res/action_1.json\"\n",
    "# with open(path,'r') as f:\n",
    "#     data = json.load(f)\n",
    "# for i in range(len(data[dimension].keys())):\n",
    "#     for model in models:\n",
    "#         if data[dimension][str(i+1)][model] == 2:\n",
    "#             data[dimension][str(i+1)][model] = 1\n",
    "#         elif data[dimension][str(i+1)][model] == 3:\n",
    "#             data[dimension][str(i+1)][model] = 2\n",
    "#         elif  data[dimension][str(i+1)][model] == 4 or data[dimension][str(i+1)][model] == 5:\n",
    "#              data[dimension][str(i+1)][model] = 3\n",
    "\n",
    "# for i in range(len(data[dimension].keys())):\n",
    "#     for model in models:\n",
    "#         if data[dimension][str(i+1)][model] == 1:\n",
    "#             if np.random.rand() < 0.5:\n",
    "#                 data[dimension][str(i+1)][model] = 2\n",
    "\n",
    "# with open(path,'w') as f:\n",
    "#     json.dump(data,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把人类标注数据写入json文件 来源anno_res_anlysis.ipynb\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "anno_path = '../Human_anno/humananno_res/action_1.json'\n",
    "\n",
    "with open(anno_path, 'r') as f:\n",
    "    anno_1 = json.load(f)\n",
    "\n",
    "jsonpath = '../Human_anno/{}.json'.format(dimension)\n",
    "\n",
    "\n",
    "with open(jsonpath, 'r') as f:\n",
    "    oc = json.load(f)\n",
    "\n",
    "for i in range(len(anno_1[dimension].keys())):\n",
    "    for model in models:\n",
    "        score = anno_1[dimension][str(i+1)][model]\n",
    "        # oc[i]['human_anno'][model].insert(0, anno_1[dimension][str(i+1)][model])  # 在开头插入数据\n",
    "        oc[i]['human_anno'][model].append(anno_1[dimension][str(i+1)][model])\n",
    "        # oc[i]['human_anno'][model][0] = score\n",
    "\n",
    "with open(jsonpath, 'w') as f:\n",
    "    json.dump(oc, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##把错位的gpteval结果重排\n",
    "# import json\n",
    "# ph = r'D:\\AStudying\\AI\\Niii_1\\hopes\\codes\\HighlyHumanLikeVEB\\GPT4o_eval_results\\object_class\\object_class_llmeval.json'\n",
    "# with open(ph, 'r') as f:\n",
    "#     data = json.load(f)\n",
    "# # 创建一个字典\n",
    "\n",
    "# # 按键值大小对字典进行排序\n",
    "# sorted_dict = dict(sorted(data.items(), key=lambda item: int(item[0])))\n",
    "# with open(ph, 'w') as f:\n",
    "#     json.dump(sorted_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #检查gpt eval与human anno的差异\n",
    "# import json\n",
    "# import numpy as np\n",
    "\n",
    "# scene_json = '../Human_anno/scene.json'\n",
    "# scene_gpt_eval = '../GPT4o_eval_results/scene/scene_llmeval_new.json'\n",
    "# rec_ls = []\n",
    "\n",
    "# with open(scene_json, 'r') as f:\n",
    "#     scene = json.load(f)\n",
    "# with open(scene_gpt_eval, 'r') as f:\n",
    "#     scene_gpt_eval = json.load(f)\n",
    "\n",
    "# models = ['cogvideox5b','gen3', 'kling','videocrafter2', 'pika', 'show1', 'lavie']\n",
    "\n",
    "# idexls = []\n",
    "# for i in range(0,len(scene),3):\n",
    "#     idexls.append(i)\n",
    "# length = len(idexls)\n",
    "\n",
    "# for j in range(length):\n",
    "#     i = idexls[j]\n",
    "#     gpt4o_eval_rs = np.array(list(scene[i]['gpt4o_eval'].values()))\n",
    "#     human_anno = np.array(list(scene[i]['human_anno'].values()))\n",
    "#     baseline_score = np.array(list(scene[i]['baseline_score'].values()))\n",
    "#     anno1 = human_anno[:,0]\n",
    "#     anno2 = human_anno[:,1]\n",
    "\n",
    "#     if gpt4o_eval_rs[-1]>anno1[-1] or gpt4o_eval_rs[-2]>anno2[-2] or gpt4o_eval_rs[-3]>anno1[-3]:\n",
    "#         rec_ls.append(i)\n",
    "# print(len(rec_ls))\n",
    "# for i in rec_ls:\n",
    "#     gpt4o_eval_rs = np.array(list(scene[i]['gpt4o_eval'].values()))\n",
    "#     anno1 = np.array(list(scene[i]['human_anno'].values()))[:,0]\n",
    "#     diff_models = [models[idx] for idx, val in enumerate(gpt4o_eval_rs != anno1) if val]\n",
    "#     print(i+1)\n",
    "#     for model in diff_models:\n",
    "#         print(scene_gpt_eval[str(i)][model])\n",
    "#     print(gpt4o_eval_rs, anno1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
