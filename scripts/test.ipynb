{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 'object_class'\n",
    "models = ['cogvideox5b','kling','gen3','lavie','pika','show1','videocrafter2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 把gpt4o_eval的结果加入到annotation中\n",
    "# import json\n",
    "# import os\n",
    "\n",
    "\n",
    "# file_path = \"../GPT4o_eval_results/{}/{}_llmeval.json\".format(dimension,dimension)\n",
    "# with open(file_path, \"r\") as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "# video_path =\"../Human_anno/{}.json\".format(dimension)\n",
    "# with open(video_path, \"r\") as file:\n",
    "#     annotations = json.load(file)\n",
    "\n",
    "# for index,key in enumerate(data.keys()):\n",
    "#     for line in data[key].split('\\n'):\n",
    "#         if line.split(' ')[0] != '-':\n",
    "#             continue \n",
    "#         else:\n",
    "#             try:\n",
    "#                 score = int(line.split(' ')[2][0])\n",
    "#             except:\n",
    "#                 print(line,key)\n",
    "#             # score = int(line.split(' ')[2][0])\n",
    "#             model =line.split(' ')[1][:-1].lower().replace('**','')\n",
    "#             annotations[int(key)]['gpt4o_eval'][model] = score\n",
    "\n",
    "# with open(video_path, \"w\") as f:\n",
    "#     json.dump(annotations, f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5->3\n",
    "# import json\n",
    "# path =\"../Human_anno/humananno_res/scene_2.json\"\n",
    "# with open(path,'r') as f:\n",
    "#     data = json.load(f)\n",
    "# for i in range(len(data[dimension].keys())):\n",
    "#     for model in models:\n",
    "#         if data[dimension][str(i+1)][model] == 2:\n",
    "#             data[dimension][str(i+1)][model] = 1\n",
    "#         elif data[dimension][str(i+1)][model] == 3:\n",
    "#             data[dimension][str(i+1)][model] = 2\n",
    "#         elif  data[dimension][str(i+1)][model] == 4 or data[dimension][str(i+1)][model] == 5:\n",
    "#              data[dimension][str(i+1)][model] = 3\n",
    "# with open(path,'w') as f:\n",
    "#     json.dump(data,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 把人类标注数据写入json文件 来源anno_res_anlysis.ipynb\n",
    "# import json\n",
    "\n",
    "# import pandas as pd\n",
    "# anno_path = '../Human_anno/humananno_res/object_lsy.json'\n",
    "\n",
    "# with open(anno_path, 'r') as f:\n",
    "#     anno_1 = json.load(f)\n",
    "\n",
    "# jsonpath = '../Human_anno/{}.json'.format(dimension)\n",
    "\n",
    "\n",
    "# with open(jsonpath, 'r') as f:\n",
    "#     oc = json.load(f)\n",
    "\n",
    "# for i in range(len(anno_1[dimension].keys())):\n",
    "#     for model in models:\n",
    "#         # oc[i]['human_anno'][model].insert(0, anno_1[dimension][str(i+1)][model])  # 在开头插入数据\n",
    "#         # oc[i]['human_anno'][model].append(anno_1[dimension][str(i+1)][model])\n",
    "#         oc[i]['human_anno'][model][0] = anno_1[dimension][str(i+1)][model]\n",
    "\n",
    "# with open(jsonpath, 'w') as f:\n",
    "#     json.dump(oc, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##把错位的gpteval结果重排\n",
    "# import json\n",
    "# ph = r'D:\\AStudying\\AI\\Niii_1\\hopes\\codes\\HighlyHumanLikeVEB\\GPT4o_eval_results\\object_class\\object_class_llmeval.json'\n",
    "# with open(ph, 'r') as f:\n",
    "#     data = json.load(f)\n",
    "# # 创建一个字典\n",
    "\n",
    "# # 按键值大小对字典进行排序\n",
    "# sorted_dict = dict(sorted(data.items(), key=lambda item: int(item[0])))\n",
    "# with open(ph, 'w') as f:\n",
    "#     json.dump(sorted_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "30\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m rec_ls:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mscene_gpt_eval\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "scene_json = '../Human_anno/scene.json'\n",
    "scene_gpt_eval = '../GPT4o_eval_results/scene/scene_llmeval.json'\n",
    "rec_ls = []\n",
    "\n",
    "with open(scene_json, 'r') as f:\n",
    "    scene = json.load(f)\n",
    "with open(scene_gpt_eval, 'r') as f:\n",
    "    scene_gpt_eval = json.load(f)\n",
    "\n",
    "models = ['cogvideox5b','gen3', 'kling','videocrafter2', 'pika', 'show1', 'lavie']\n",
    "\n",
    "idexls = []\n",
    "for i in range(0,len(scene),3):\n",
    "    idexls.append(i)\n",
    "length = len(idexls)\n",
    "\n",
    "for j in range(length):\n",
    "    i = idexls[j]\n",
    "    gpt4o_eval_rs = np.array(list(scene[i]['gpt4o_eval'].values()))\n",
    "    human_anno = np.array(list(scene[i]['human_anno'].values()))\n",
    "    baseline_score = np.array(list(scene[i]['baseline_score'].values()))\n",
    "    anno1 = human_anno[:,0]\n",
    "    anno2 = human_anno[:,1]\n",
    "\n",
    "    if gpt4o_eval_rs[-1]>anno1[-1]:\n",
    "        rec_ls.append(i)\n",
    "print(len(rec_ls))\n",
    "for i in rec_ls:\n",
    "    print(i)\n",
    "    print(scene_gpt_eval[str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
