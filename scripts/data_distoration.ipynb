{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def apply_gaussian_blur(frame, kernel_size=(5, 5)):\n",
    "    return cv2.GaussianBlur(frame, kernel_size, 0)\n",
    "\n",
    "def add_gaussian_noise(frame, mean=0, var=5):\n",
    "    sigma = var ** 0.1\n",
    "    gauss = np.random.normal(mean, sigma, frame.shape).astype('uint8')\n",
    "    noisy_frame = cv2.add(frame, gauss)\n",
    "    return noisy_frame\n",
    "\n",
    "\n",
    "def process_video(input_path, output_path):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    #                                                                                           \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # 使用MP4编码器并保持原视频的帧率\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        blurred_frame = apply_gaussian_blur(frame)\n",
    "        noisy_frame = add_gaussian_noise(blurred_frame)\n",
    "\n",
    "        out.write(noisy_frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "import numpy as np\n",
    "\n",
    "def apply_gaussian_blur_gif(frame, radius=5):\n",
    "    return frame.filter(ImageFilter.GaussianBlur(radius=radius))\n",
    "\n",
    "def add_gaussian_noise_gif(frame, mean=0, var=5):\n",
    "    np_frame = np.array(frame)\n",
    "    sigma = var **  0.1\n",
    "    gauss = np.random.normal(mean, sigma, np_frame.shape).astype('uint8')\n",
    "    noisy_frame = cv2.add(np_frame, gauss)\n",
    "    noisy_frame = np.clip(noisy_frame, 0, 255).astype('uint8')\n",
    "    return Image.fromarray(noisy_frame)\n",
    "\n",
    "def process_gif(input_path, output_path):\n",
    "    gif = Image.open(input_path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            frame = gif.copy().convert('RGB')\n",
    "            blurred_frame = apply_gaussian_blur_gif(frame)\n",
    "            noisy_frame = add_gaussian_noise_gif(blurred_frame)\n",
    "            frames.append(noisy_frame)  # Convert back to 'P' mode for GIF\n",
    "            gif.seek(gif.tell() + 1)\n",
    "    except EOFError:\n",
    "        pass\n",
    "\n",
    "    frames[0].save(output_path, save_all=True, append_images=frames[1:], loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [13:55<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish cogvideo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:18<00:00, 24.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish modelscope\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:21<00:00, 21.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish videocrafter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [01:16<00:00,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish lavie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "output_dir = '/home/yons/lsy/data/distorted/overall_consistency'\n",
    "input_dir = '/home/yons/lsy/data/per_dimension'\n",
    "model_name_list = ['cogvideo','modelscope','videocrafter','lavie']\n",
    "for model_name in model_name_list:\n",
    "    input_dir = '/home/yons/lsy/data/per_dimension/'+model_name+'/overall_consistency'\n",
    "    if model_name == 'cogvideo':\n",
    "        for gif_name in tqdm(os.listdir(input_dir)):\n",
    "            input_path = os.path.join(input_dir, gif_name)\n",
    "            output_path = os.path.join(output_dir, model_name,'overall_consistency', video_name)\n",
    "            process_gif(input_path, output_path)\n",
    "    else:\n",
    "        for video_name in tqdm(os.listdir(input_dir)):\n",
    "            input_path = os.path.join(input_dir, video_name)\n",
    "            output_path = os.path.join(output_dir, model_name,'overall_consistency', video_name)\n",
    "            process_video(input_path, output_path)\n",
    "    print('finish',model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yons/anaconda3/envs/lsyllm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation meta data saved to evaluation_results_ditorted/modelscope_full_info.json\n",
      "cur_full_info_path: evaluation_results_ditorted/modelscope_full_info.json\n",
      "Loading pretrained model MUSIQ from /home/yons/.cache/vbench/pyiqa_model/musiq_spaq_ckpt-358bb6af.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:43<00:00, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to evaluation_results_ditorted/modelscope_eval_results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from vbench import VBench\n",
    "my_VBench = VBench('cuda', \"./VBench_full_info.json\", \"evaluation_results_ditorted\")\n",
    "my_VBench.evaluate(\n",
    "    videos_path = \"/home/yons/lsy/data/distorted/overall_consistency/modelscope/overall_consistency\",\n",
    "    name = \"modelscope\",\n",
    "    dimension_list = [\"imaging_quality\"],\n",
    "    imaging_quality_preprocessing_mode = \"None\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/yons/lsy/VideoEvalAgent/GPT4o_results/score/Human_Action_Score_ev_results.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def save_frame_from_gif(gif_path, frame_index, output_path):\n",
    "    gif = Image.open(gif_path)\n",
    "    try:\n",
    "        gif.seek(frame_index)\n",
    "        frame = gif.convert('RGB')\n",
    "        frame.save(output_path)\n",
    "        print(\"Frame saved successfully.\")\n",
    "    except EOFError:\n",
    "        print(\"Error: Invalid frame index.\")\n",
    "\n",
    "# 示例用法\n",
    "gif_path = \"/home/yons/lsy/data/per_dimension/cogvideo/human_action/A person is sailing-0.gif\"\n",
    "frame_index = 16\n",
    "output_path = \"/home/yons/lsy/VideoEvalAgent/GPT4o_results/cogvideo_sailing.jpg\"\n",
    "\n",
    "save_frame_from_gif(gif_path, frame_index, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsyllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
