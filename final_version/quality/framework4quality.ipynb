{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from tool import videoreader\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 'imaging_quality'\n",
    "from tool.framework import critic_agent\n",
    "agent1 = critic_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prepath = r'D:\\Astudying\\VideoEval\\data4dimensions'\n",
    "# data_prepath = \"../../data4dimensions/\"\n",
    "with open(\"./Human_anno/{}.json\".format(dimension)) as f:\n",
    "    human_anno = json.load(f)\n",
    "\n",
    "eval_path =\"./GPT4o_eval_results/{}/{}_llmeval_7inputsfewshot.json\".format(dimension,dimension)\n",
    "with open(eval_path,'r') as f:\n",
    "    eval_results = json.load(f)\n",
    "\n",
    "critic_evalph = \"./GPT4o_eval_results/imaging_quality/imaging_quality_multillmeval.json\"\n",
    "with open(critic_evalph,'r') as f:\n",
    "    critic_eval = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 = list(range(0,len(human_anno),3))\n",
    "# l2 = list(range(161,len(human_anno),3))\n",
    "l1 = [0]\n",
    "l = l1\n",
    "for i in l:\n",
    "    if str(i) not in critic_eval:\n",
    "        critic_eval[str(i)] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here’s the analysis and evaluation of the video frames based on the provided examples and evaluation results:\n",
      "\n",
      "- **cogvideox5b**: should be scored **4**, because the frames exhibit good clarity with vibrant colors and minimal distortions. The brightness is well-balanced, contributing to a high-definition quality overall.\n",
      "\n",
      "- **kling**: should be scored **4**, because the frames demonstrate good clarity and high definition. The minimal distortions and well-balanced brightness enhance the viewing experience, resulting in high video quality.\n",
      "\n",
      "- **gen3**: should be scored **3**, because while the frames show good clarity and vibrant colors, there is noticeable overexposure in some areas that detracts from the overall quality. The details are well-defined, but the slight overexposure impacts the viewing experience.\n",
      "\n",
      "- **videocrafter2**: should be scored **4**, because the frames display high-definition clarity with vibrant colors and minimal noise. The brightness is well-balanced, providing a good overall viewing experience.\n",
      "\n",
      "- **pika**: should be scored **3**, because the frames show moderate quality with acceptable clarity, but there is noticeable blurriness and slight overexposure. The presence of noise affects the overall viewing experience, but it is not severely detrimental.\n",
      "\n",
      "- **show1**: should be scored **2**, because the frames exhibit noticeable blurriness and lack of clarity. The images are not sharp, and the slight overexposure negatively impacts the viewing experience.\n",
      "\n",
      "- **lavie**: should be scored **2**, because the frames show significant blurriness and lack of clarity. The images are not sharp, and the overexposure affects the overall quality, indicating substantial room for improvement in clarity and brightness balance.\n"
     ]
    }
   ],
   "source": [
    "# skip_index = list(range(0, len(human_anno),5))\n",
    "model2message = {\n",
    "'cogvideox5b':\"12 frames from cogvideox5b\\n\",\n",
    "'kling':\"10 frames from kling \\n \", \n",
    "'gen3': \"10 frames from gen3 \\n\",\n",
    "'videocrafter2':\"4 frames from videocrafter2\",\n",
    "'pika':\"7 frames from pika \",\n",
    "'show1':\"8 frames from show1 \",\n",
    "'lavie':\"5 frames from lavie \",\n",
    "}\n",
    "\n",
    "for i in l:        \n",
    "\n",
    "    examplemodels = [x for x in model2message.keys()]\n",
    "    eval_res = eval_results[str(i)] \n",
    "    frames = videoreader.process_video(data_prepath,human_anno[i]['videos'],2)\n",
    "    \n",
    "    # frames = videoreader.process_video(data_prepath,human_anno[i]['videos'],2)\n",
    "    # videoreader.display_base64_images(frames['kling'])\n",
    "\n",
    "    prompten = human_anno[i]['prompt_en']\n",
    "    # question = human_anno[i]['question_en']\n",
    "    # subject = human_anno[i]['subject_en']\n",
    "    # scene = human_anno[i]['scene_en']\n",
    "    # objet = human_anno[i]['object']\n",
    "\n",
    "    try:\n",
    "        response = agent1.client.chat.completions.create(\n",
    "        model=agent1.model_name, \n",
    "        messages=[\n",
    "        {\n",
    "        \"role\": \"system\", \"content\":\n",
    "        agent1.system_message,\n",
    "        }\n",
    "        ,\n",
    "        {\n",
    "        \"role\": \"user\", \"content\": [\n",
    "        \"According to  your **Goals**in system meassage, there are examples and evaluation results from video generation models.\\n\",\n",
    "        *[item for examplemodel in examplemodels for item in [\n",
    "            \"This example is from model '{}' \\n\".format(examplemodel),\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f'data:image/jpg;base64,{frames[examplemodel][0]}', \"detail\": \"low\"}}\n",
    "        ]],                 \n",
    "        \"The evaluation results of these examples are as follows:\\n\",\n",
    "        *map(lambda x: f\"model: {x}, evaluation result: {eval_res[x]}\\n\", examplemodels),\n",
    "        \n",
    "        \"Assuming there are videos you think should score 'x',provide your analysis and explanation in the output format as follows:\\n\",\n",
    "        *map(lambda x: f\"- {x}: should be scored x,because...\\n\", examplemodels),\n",
    "\n",
    "            ],\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "        )\n",
    "        print(response.choices[0].message.content) \n",
    "        critic_eval[str(i)] = response.choices[0].message.content.replace('\\n\\n','\\n')\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        critic_eval[str(i)] = \"An error occurred\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# # 使用 json 保存字典\n",
    "# with open(file_path, \"w\") as f:\n",
    "#     json.dump(s, f,indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
