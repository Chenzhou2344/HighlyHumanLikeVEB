{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from tool import videoreader\n",
    "# 创建一个OpenAI客户端实例\n",
    "client = OpenAI(\n",
    "    api_key=\"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\",\n",
    "    base_url=\"https://gateway.ai.cloudflare.com/v1/627f1b1f372e3a198dc32573bbc6f720/openai-gpt/openai\"  # 替换为你的自定义API域\n",
    ")\n",
    "\n",
    "## Set the API key and model name\n",
    "MODEL=\"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 'color'\n",
    "from PromptTemplate4GPTeval import Prompt4Scene\n",
    "prompt_template = Prompt4Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# data_prepath = r'D:\\Astudying\\VideoEval\\data4dimensions'\n",
    "data_prepath = \"../../data4dimensions/\"\n",
    "with open(\"./Human_anno/{}.json\".format(dimension)) as f:\n",
    "    human_anno = json.load(f)\n",
    "\n",
    "batch_stpath = '../batch_api/{}'.format(dimension)\n",
    "batch_unique_ids = []\n",
    "batch_split_ids = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_batch_onebyone(index_list,batch_id):\n",
    "    model2message = {\n",
    "    'cogvideox5b':\"12 frames from cogvideox5b\\n\",\n",
    "    'kling':\"10 frames from kling \\n \", \n",
    "    'gen3': \"10 frames from gen3 \\n\",\n",
    "    'videocrafter2':\"4 frames from videocrafter2\",\n",
    "    'pika':\"7 frames from pika \",\n",
    "    'show1':\"8 frames from show1 \",\n",
    "    'lavie':\"5 frames from lavie \",\n",
    "    }\n",
    "\n",
    "\n",
    "    with open(r\"./GPT4o_eval_results/{}/combench/{}_combench_description.json\".format(dimension,dimension)) as f:\n",
    "        description = json.load(f)\n",
    "\n",
    "    requests = []\n",
    "    for key, value in model2message.items():\n",
    "        modelname = key\n",
    "        modelmessage = value\n",
    "   \n",
    "        for i in index_list:     \n",
    "            request ={\"custom_id\": \"request-{}-{}\".format(i,modelname), \n",
    "                    \"method\": \"POST\", \n",
    "                    \"url\": \"/v1/chat/completions\",\n",
    "                    \"body\": {\"model\": MODEL,\n",
    "                                \"messages\": [],\n",
    "                                \"temperature\": 0}}\n",
    "\n",
    "            frames = videoreader.process_video(data_prepath,human_anno[i]['videos'],2 ,resize_fx=1,resize_fy=1)\n",
    "\n",
    "            prompten = human_anno[i]['prompt_en']\n",
    "            # question = human_anno[i]['question_en']\n",
    "            # subject = human_anno[i]['subject_en']\n",
    "            # scene = human_anno[i]['scene_en']\n",
    "            # objet = human_anno[i]['object']\n",
    "            messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \"content\": [\n",
    "                f\"According to the frames from generated video and your previous answer, evaluate if the text \\'{prompten}\\' is correctly portrayed in the image.\\n \\\n",
    "            Assign a score from 1 to 3 according the criteria: \\n \\\n",
    "            1. Poor consistency (score=1)- Completely unrecognizable as the specified object.The object is not discernible at all. \\n \\\n",
    "            2. Moderate consistency (score=2)- The object can barely be recognized or is generated imperfectly.The specific conditions are: \\n \\\n",
    "                - Condition 1 : A similar object with a related function or structure is generated, (e.g., a 'snowboard' instead of 'skis', a “unicycle” instead of a “bicycle,”) \\n \\\n",
    "                - Condition 2 : The object cannot be accurately recognized, (e.g. Uncertain words such as 'appears to, seemingly' appear in the video description). \\n \\\n",
    "                - Condition 3 : The object in the video is blurred and inconspicuous, making it difficult to recognize. \\n \\\n",
    "                - Condition 4 : The video focuses on only a part of the object. (e.g. generating a human hand instead of a whole person.) \\n \\\n",
    "                - Condition 5 : More than 3 frames in the video are missing the object. \\n \\\n",
    "                - Condition 6 : The appearance of the object changes significantly. (e.g., a person sometimes has facial features and sometimes does not.) \\n \\\n",
    "            3. Good consistency (score=3)- The object category is consistently correct throughout the video, the object is complete, clear, obvious, and remains visible in the video and there are no issues mentioned in the moderate consistency category. \\n \\\n",
    "     Provide your analysis and explanation in JSON format with the following keys: score (e.g., 2), explanation (within 20 words).\",\n",
    "                modelmessage,   \n",
    "                *map(lambda x: {\"type\": \"image_url\", \n",
    "                                \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, frames[modelname]),\n",
    "                                                            ],\n",
    "\n",
    "                \"The description of the video provided by your previous answer is as follows:\":description[str(i)][modelname]\n",
    "                }\n",
    "            ]\n",
    "            request['body']['messages'] = messages\n",
    "            requests.append(request)\n",
    "\n",
    "    with open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"w\") as f:\n",
    "        for entry in requests:\n",
    "            json_line = json.dumps(entry)\n",
    "            f.write(json_line + '\\n')\n",
    "    batch_split_ids.append(batch_id)\n",
    "    \n",
    "    batch_input_file = client.files.create(\n",
    "             file=open(os.path.join(batch_stpath,\"requests_{}_batch_{}.jsonl\".format(dimension,batch_id)), \"rb\"),\n",
    "              purpose=\"batch\"\n",
    "             )\n",
    "\n",
    "    batch_input_file_id = batch_input_file.id    \n",
    "\n",
    "    batch_object = client.batches.create(\n",
    "            input_file_id=batch_input_file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "            metadata={\n",
    "            \"description\": \"nightly group1 {} eval job batch {}\".format(dimension,batch_id)\n",
    "            }\n",
    "                                        )\n",
    "\n",
    "    batch_unique_ids.append(batch_object.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 = list(range(1,len(human_anno),3))\n",
    "# l2 = list(range(2,len(human_anno),3))\n",
    "# l3 = list(range(0,len(human_anno),3))\n",
    "l = list(range(0,len(human_anno)))\n",
    "ls = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import threading\n",
    "\n",
    "# batch_size = 15\n",
    "# batches = [ls[i:i + batch_size] for i in range(0, len(ls), batch_size)]\n",
    "\n",
    "\n",
    "# threads = []\n",
    "# for i, batch in enumerate(batches):\n",
    "#     thread = threading.Thread(target=eval_batch_onebyone, args=(batch, i))\n",
    "#     threads.append(thread)\n",
    "#     thread.start()\n",
    "\n",
    "# # 等待所有线程完成\n",
    "# for thread in threads:\n",
    "#     thread.join()\n",
    "\n",
    "# #保存batch信息\n",
    "# with open(\"./batch_infos/batch_info_{}_combench.json\".format(dimension), \"w\") as f:\n",
    "#     json.dump({\"batch_unique_ids\": batch_unique_ids, \"batch_split_ids\": batch_split_ids,\"videos_in_batch\":batches}, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id:batch_6734194b14b08190b74262225ce0a159 status:completed descrepition:nightly group1 color eval job batch 11\n",
      "batch batch_6734194b14b08190b74262225ce0a159 done,end index 254\n",
      "id:batch_67341f9caa808190be493ce054eef22c status:completed descrepition:nightly group1 color eval job batch 3\n",
      "batch batch_67341f9caa808190be493ce054eef22c done,end index 178\n",
      "id:batch_67341fb43d588190b569e0e5ea9d960a status:completed descrepition:nightly group1 color eval job batch 10\n",
      "batch batch_67341fb43d588190b569e0e5ea9d960a done,end index 239\n",
      "id:batch_67341fb46e5c8190a001dd543e5851a4 status:completed descrepition:nightly group1 color eval job batch 9\n",
      "batch batch_67341fb46e5c8190a001dd543e5851a4 done,end index 194\n",
      "id:batch_67341fc5e5c08190bb2fdf76c200657b status:completed descrepition:nightly group1 color eval job batch 1\n",
      "batch batch_67341fc5e5c08190bb2fdf76c200657b done,end index 88\n",
      "id:batch_67341fcb1e5881909449a47022f27726 status:completed descrepition:nightly group1 color eval job batch 7\n",
      "batch batch_67341fcb1e5881909449a47022f27726 done,end index 104\n",
      "id:batch_67341fcd6d388190ad228ec3c7f66be2 status:completed descrepition:nightly group1 color eval job batch 8\n",
      "batch batch_67341fcd6d388190ad228ec3c7f66be2 done,end index 149\n",
      "id:batch_67341fd1c9e08190a38b2a4900ac4792 status:completed descrepition:nightly group1 color eval job batch 5\n",
      "batch batch_67341fd1c9e08190a38b2a4900ac4792 done,end index 14\n",
      "id:batch_67341fd2f9bc81909aab7e35cdc0c31d status:completed descrepition:nightly group1 color eval job batch 4\n",
      "batch batch_67341fd2f9bc81909aab7e35cdc0c31d done,end index 223\n",
      "id:batch_67341fd4745c8190831b2b7ddbf48645 status:completed descrepition:nightly group1 color eval job batch 2\n",
      "batch batch_67341fd4745c8190831b2b7ddbf48645 done,end index 133\n",
      "id:batch_67341fde7ee081909f3db59f0066d03c status:completed descrepition:nightly group1 color eval job batch 0\n",
      "batch batch_67341fde7ee081909f3db59f0066d03c done,end index 43\n",
      "id:batch_6734203615d081908a26e81cf482339e status:completed descrepition:nightly group1 color eval job batch 6\n",
      "batch batch_6734203615d081908a26e81cf482339e done,end index 59\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "with open(\"./batch_infos/batch_info_{}_combench.json\".format(dimension), \"r\") as f:\n",
    "    batch_info = json.load(f)\n",
    "\n",
    "    \n",
    "batchids = batch_info[\"batch_unique_ids\"]\n",
    "for id in batchids:\n",
    "    batch_object = client.batches.retrieve(id)\n",
    "    print(\"id:{} status:{} descrepition:{}\".format(id,batch_object.status,batch_object.metadata['description']))\n",
    "    if batch_object.status != \"completed\":\n",
    "        print(\"batch {} not completed\".format(id))\n",
    "        continue\n",
    "    file_response = client.files.content(batch_object.output_file_id)\n",
    "\n",
    "    llmeval_path = \"./GPT4o_eval_results/{}/combench/{}_combench_score.json\".format(dimension,dimension)\n",
    "\n",
    "    with open(llmeval_path, \"r\") as f:\n",
    "        llmeval = json.load(f)\n",
    "    # llmeval = {}\n",
    "    for i in ls:\n",
    "        if str(i) not in llmeval:\n",
    "            llmeval[str(i)] = {}\n",
    "\n",
    "    for line in file_response.text.splitlines():\n",
    "        index = json.loads(line)[\"custom_id\"].split(\"-\")[-2]\n",
    "        model = json.loads(line)[\"custom_id\"].split(\"-\")[-1]\n",
    "        eval_res = json.loads(line)[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"].replace('\\n\\n','\\n')\n",
    "        # print(\"index:{} model:{} eval_res:{}\".format(index,model,eval_res))\n",
    "        eval_res = ''.join(eval_res.split('\\n')[1:-1])\n",
    "        try :\n",
    "            eval_res = ast.literal_eval(eval_res)\n",
    "        except:\n",
    "            print(\"index:{} model:{} eval_res:{}\".format(index,model,eval_res))\n",
    "        llmeval[index][model] = eval_res\n",
    "    with open(llmeval_path, \"w\") as f:\n",
    "        json.dump(llmeval, f, indent=4)\n",
    "\n",
    "    print(\"batch {} done,end index {}\".format(id,index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
